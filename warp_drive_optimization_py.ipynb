{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO/uYsD2DFxQIM3O5Hp74iw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/warp_drive_optimization_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Edd1aUv363az"
      },
      "outputs": [],
      "source": [
        "pip install torch numpy scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "warp_drive_optimization.py\n",
        "\n",
        "Train a neural network to predict the Alcubierre warp‐drive\n",
        "energy density proxy over 3D coordinates (x, y, z).\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Warp Metric Definition\n",
        "def warp_drive_metric(x, y, z, v=1.0, sigma=1.0):\n",
        "    \"\"\"\n",
        "    Gaussian warp‐bubble proxy: exp(–r²/σ) × v,\n",
        "    where r = sqrt(x² + y² + z²).\n",
        "    \"\"\"\n",
        "    r2 = x**2 + y**2 + z**2\n",
        "    return np.exp(-r2 / sigma) * v\n",
        "\n",
        "# 2. Neural Model\n",
        "class WarpDriveAI(nn.Module):\n",
        "    def __init__(self, input_dim=3, hidden_dim=32, output_dim=1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 3. Dataset Generation\n",
        "def generate_dataset(n_samples=15000, v=1.0, sigma=1.0):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      coords: array of shape [n_samples, 3]\n",
        "      energies: array of shape [n_samples, 1]\n",
        "    \"\"\"\n",
        "    coords = np.random.uniform(-3, 3, size=(n_samples, 3)).astype(np.float32)\n",
        "    energies = warp_drive_metric(\n",
        "        coords[:,0], coords[:,1], coords[:,2], v=v, sigma=sigma\n",
        "    ).reshape(-1, 1).astype(np.float32)\n",
        "    return coords, energies\n",
        "\n",
        "# 4. Training Loop\n",
        "def train_model(\n",
        "    model, x_train, y_train, x_val, y_val,\n",
        "    epochs=100, batch_size=256, lr=1e-3\n",
        "):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Shuffle and batch training data\n",
        "        perm = np.random.permutation(len(x_train))\n",
        "        batch_loss = []\n",
        "\n",
        "        model.train()\n",
        "        for i in range(0, len(x_train), batch_size):\n",
        "            idx = perm[i : i + batch_size]\n",
        "            xb = torch.from_numpy(x_train[idx]).to(device)\n",
        "            yb = torch.from_numpy(y_train[idx]).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            xv = torch.from_numpy(x_val).to(device)\n",
        "            yv = torch.from_numpy(y_val).to(device)\n",
        "            val_loss = criterion(model(xv), yv).item()\n",
        "\n",
        "        train_losses.append(np.mean(batch_loss))\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == 1:\n",
        "            print(\n",
        "                f\"Epoch {epoch:03d} – \"\n",
        "                f\"Train Loss: {train_losses[-1]:.6f} – \"\n",
        "                f\"Val Loss: {val_losses[-1]:.6f}\"\n",
        "            )\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# 5. Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    N_SAMPLES   = 15000\n",
        "    TEST_SIZE   = 0.2\n",
        "    HIDDEN_DIM  = 32\n",
        "    EPOCHS      = 100\n",
        "    BATCH_SIZE  = 256\n",
        "    LEARNING_RT = 1e-3\n",
        "\n",
        "    # Generate and split dataset\n",
        "    coords, energies = generate_dataset(n_samples=N_SAMPLES)\n",
        "    x_tr, x_val, y_tr, y_val = train_test_split(\n",
        "        coords, energies, test_size=TEST_SIZE, random_state=42\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    model = WarpDriveAI(input_dim=3, hidden_dim=HIDDEN_DIM, output_dim=1)\n",
        "\n",
        "    # Train and collect losses\n",
        "    train_losses, val_losses = train_model(\n",
        "        model, x_tr, y_tr, x_val, y_val,\n",
        "        epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LEARNING_RT\n",
        "    )\n",
        "\n",
        "    # Plot learning curves\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses,   label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MSE Loss\")\n",
        "    plt.title(\"WarpDriveAI Training Curve\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Evaluate on sample points\n",
        "    test_pts = np.array([[0,0,0], [1,1,1], [2,0,0]], dtype=np.float32)\n",
        "    true_vals = warp_drive_metric(\n",
        "        test_pts[:,0], test_pts[:,1], test_pts[:,2]\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        preds = model(torch.from_numpy(test_pts))\n",
        "    print(\"\\nSample Predictions vs True Values:\")\n",
        "    for pt, p, t in zip(test_pts, preds.numpy().flatten(), true_vals.flatten()):\n",
        "        print(f\"Point {pt} → Pred: {p:.4f} | True: {t:.4f}\")"
      ],
      "metadata": {
        "id": "5dPhdyxa67rm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
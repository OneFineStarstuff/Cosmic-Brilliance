{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNkoZrDiGdABZ2t3hF6WDuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/pinn_pipeline_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mWwONdYwJWY"
      },
      "outputs": [],
      "source": [
        "pip install torch numpy matplotlib scikit-learn scipy umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pinn_pipeline.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import pearsonr\n",
        "import umap\n",
        "import random\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "\n",
        "# 1. Synthetic Data Generators\n",
        "def generate_dissolution_data(n_samples=500):\n",
        "    k, C0 = 0.5, 1.0\n",
        "    t = np.linspace(0, 10, n_samples)[:, None]\n",
        "    C = C0 * np.exp(-k * t) + 0.01 * np.random.randn(*t.shape)\n",
        "    return torch.tensor(t, dtype=torch.float32), torch.tensor(C, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def generate_accumulation_data(n_samples=500):\n",
        "    k, M0 = 0.3, 0.5\n",
        "    t = np.linspace(0, 10, n_samples)[:, None]\n",
        "    M = M0 * np.exp(k * t) + 0.01 * np.random.randn(*t.shape)\n",
        "    return torch.tensor(t, dtype=torch.float32), torch.tensor(M, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# 2. PINN Model\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(1, 64), nn.Tanh(),\n",
        "            nn.Linear(64, 64), nn.Tanh(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# 3. Physics Residuals\n",
        "def residual_dissolution(model, t):\n",
        "    t.requires_grad_(True)\n",
        "    C_pred = model(t)\n",
        "    dC_dt = torch.autograd.grad(C_pred.sum(), t, create_graph=True)[0]\n",
        "    return dC_dt + 0.5 * C_pred\n",
        "\n",
        "\n",
        "def residual_accumulation(model, t):\n",
        "    t.requires_grad_(True)\n",
        "    M_pred = model(t)\n",
        "    dM_dt = torch.autograd.grad(M_pred.sum(), t, create_graph=True)[0]\n",
        "    return dM_dt - 0.3 * M_pred\n",
        "\n",
        "\n",
        "# 4. Training Function\n",
        "def train(model, loader, res_fn, epochs=100, phy_lambda=1.0, lr=1e-3, name=\"Model\"):\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    mse = nn.MSELoss()\n",
        "    for ep in range(1, epochs + 1):\n",
        "        dl, pl = 0.0, 0.0\n",
        "        for t_b, y_b in loader:\n",
        "            opt.zero_grad()\n",
        "            y_pred = model(t_b)\n",
        "            ld = mse(y_pred, y_b)\n",
        "            res = res_fn(model, t_b)\n",
        "            lp = mse(res, torch.zeros_like(res))\n",
        "            (ld + phy_lambda * lp).backward()\n",
        "            opt.step()\n",
        "            dl += ld.item()\n",
        "            pl += lp.item()\n",
        "        print(f\"[{name}] Epoch {ep:3d}/{epochs} â€” Data: {dl/len(loader):.4f}, Phy: {pl/len(loader):.4f}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# 5. MC-Dropout Prediction\n",
        "def mc_predict(model, t, n_samples=50):\n",
        "    model.train()\n",
        "    preds = np.stack([model(t).detach().cpu().numpy() for _ in range(n_samples)], axis=0)\n",
        "    return preds.mean(axis=0).flatten(), preds.std(axis=0).flatten()\n",
        "\n",
        "\n",
        "# 6. Main Pipeline\n",
        "def main():\n",
        "    # Data\n",
        "    t_d, C = generate_dissolution_data()\n",
        "    t_a, M = generate_accumulation_data()\n",
        "    loader_d = DataLoader(TensorDataset(t_d, C), batch_size=128, shuffle=True)\n",
        "    loader_a = DataLoader(TensorDataset(t_a, M), batch_size=128, shuffle=True)\n",
        "\n",
        "    # Train\n",
        "    md = train(PINN(), loader_d, residual_dissolution, name=\"DissolutionAI\")\n",
        "    ma = train(PINN(), loader_a, residual_accumulation, name=\"PreComputationalAI\")\n",
        "\n",
        "    # Inference\n",
        "    t_full = torch.linspace(0, 10, 500)[:, None]\n",
        "    mean_d, std_d = mc_predict(md, t_full)\n",
        "    mean_a, std_a = mc_predict(ma, t_full)\n",
        "    print(\"Mean/Std shapes:\", mean_d.shape, std_d.shape, mean_a.shape, std_a.shape)\n",
        "\n",
        "    # Features & UMAP\n",
        "    def get_feats(m, t):\n",
        "        x = m.net[0](t); x = torch.tanh(x)\n",
        "        x = m.net[2](x); x = torch.tanh(x)\n",
        "        return x.detach().cpu().numpy()\n",
        "\n",
        "    f_d, f_a = get_feats(md, t_full), get_feats(ma, t_full)\n",
        "    feats = np.vstack([f_d, f_a])\n",
        "    emb = umap.UMAP(n_components=2, random_state=SEED).fit_transform(feats)\n",
        "    print(\"UMAP shape:\", emb.shape)\n",
        "\n",
        "    # Visualization\n",
        "    std_all = np.concatenate([std_d, std_a])\n",
        "    labels = np.array([0]*len(std_d) + [1]*len(std_a))\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.scatter(emb[:500,0], emb[:500,1], c='C0', label='Dissolution', alpha=0.6)\n",
        "    plt.scatter(emb[500:,0], emb[500:,1], c='C1', label='Accumulation', alpha=0.6)\n",
        "    plt.legend(); plt.title('UMAP Projection'); plt.show()\n",
        "\n",
        "    # Clustering\n",
        "    km = KMeans(n_clusters=2, random_state=SEED).fit(emb)\n",
        "    sil = silhouette_score(emb, km.labels_)\n",
        "    print(\"Silhouette:\", sil)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.scatter(emb[:,0], emb[:,1], c=km.labels_, cmap='tab10', alpha=0.6)\n",
        "    plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], c='k', marker='X')\n",
        "    plt.title('KMeans Clusters'); plt.show()\n",
        "\n",
        "    # Classification\n",
        "    clf = LogisticRegression().fit(emb, labels)\n",
        "    print(\"Classification acc:\", clf.score(emb, labels))\n",
        "\n",
        "    # Uncertainty vs Distance\n",
        "    dists = np.linalg.norm(emb - km.cluster_centers_[km.labels_], axis=1)\n",
        "    r, p = pearsonr(dists, std_all)\n",
        "    print(\"Unc vs Dist r:\", r, \"p:\", p)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.scatter(dists, std_all, alpha=0.6)\n",
        "    plt.xlabel('Dist to center'); plt.ylabel('Std'); plt.title('Uncertainty vs Dist')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "mgOfcEOxwSU2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
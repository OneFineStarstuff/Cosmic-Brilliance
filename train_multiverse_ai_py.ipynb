{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMe/eTsvY0mgePVOxlJBuKU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_multiverse_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEevBa56xX0K"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_multiverse_ai.py\n",
        "\n",
        "Physics-informed AI pipeline for MultiverseAI:\n",
        "\n",
        "1. Synthetic dataset of 6 “multiverse” parameters → 3 target metrics\n",
        "2. 1D normalization (float32)\n",
        "3. Physics-informed residual enforcing toy domain laws in normalized space\n",
        "4. MLP with LayerNorm & Dropout for robustness\n",
        "5. MC-Dropout inference for uncertainty quantification\n",
        "6. Training loop with AdamW, ReduceLROnPlateau, gradient clipping, early stopping\n",
        "7. Visualizations: loss curves, scatter plots, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Multiverse Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class MultiverseDataset(Dataset):\n",
        "    def __init__(self, n_samples=6000, seed=0):\n",
        "        np.random.seed(seed)\n",
        "        # Features: quantum vacuum fluctuation (QVF), entropy variation (EV),\n",
        "        # dark energy level (DE), coupling constant (CC),\n",
        "        # cosmic string density (CSD), inflation rate (IR)\n",
        "        QVF = np.random.uniform(0.1, 1.0, (n_samples,1))\n",
        "        EV  = np.random.uniform(0.0, 0.5, (n_samples,1))\n",
        "        DE  = np.random.uniform(0.1, 2.0, (n_samples,1))\n",
        "        CC  = np.random.uniform(0.01, 1.0, (n_samples,1))\n",
        "        CSD = np.random.uniform(0.0, 0.2, (n_samples,1))\n",
        "        IR  = np.random.uniform(1.0, 10.0, (n_samples,1))\n",
        "\n",
        "        X_raw = np.hstack([QVF, EV, DE, CC, CSD, IR]).astype(np.float32)\n",
        "\n",
        "        # Domain formulas for targets:\n",
        "        # 1. stability = QVF * CC / (DE + ε)\n",
        "        eps = 1e-6\n",
        "        stability = QVF * CC / (DE + eps)\n",
        "\n",
        "        # 2. emergence_prob = exp(-EV * IR)\n",
        "        emergence_prob = np.exp(-EV * IR)\n",
        "\n",
        "        # 3. interaction_effect = CSD * CC * DE\n",
        "        interaction_effect = CSD * CC * DE\n",
        "\n",
        "        Y_raw = np.hstack([\n",
        "            stability, emergence_prob, interaction_effect\n",
        "        ]).astype(np.float32)\n",
        "\n",
        "        # Add small relative noise\n",
        "        Y_raw += 0.01 * Y_raw.std(axis=0) * np.random.randn(*Y_raw.shape).astype(np.float32)\n",
        "\n",
        "        # Compute 1D normalization stats\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0) + 1e-6\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0) + 1e-6\n",
        "\n",
        "        # Normalize\n",
        "        self.X = ((X_raw - self.X_mean) / self.X_std).astype(np.float32)\n",
        "        self.Y = ((Y_raw - self.Y_mean) / self.Y_std).astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.from_numpy(self.X[idx]),\n",
        "            torch.from_numpy(self.Y[idx])\n",
        "        )\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model Definition\n",
        "# ------------------------------------------------------------------------------\n",
        "class MultiverseAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dim=64, output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p_drop),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p_drop),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Residual Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, X, stats):\n",
        "    # Denormalize inputs\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    QVF, EV, DE, CC, CSD, IR = X_den.t()\n",
        "\n",
        "    # Compute true targets\n",
        "    eps = 1e-6\n",
        "    stability_t = QVF * CC / (DE + eps)\n",
        "    emergence_t = torch.exp(-EV * IR)\n",
        "    interaction_t = CSD * CC * DE\n",
        "\n",
        "    Y_t = torch.stack([stability_t, emergence_t, interaction_t], dim=1)\n",
        "\n",
        "    # Normalize true targets\n",
        "    Y_t_norm = (Y_t - stats['Y_mean']) / stats['Y_std']\n",
        "\n",
        "    # Compute MSE residual in normalized space\n",
        "    return nn.MSELoss()(pred, Y_t_norm)\n",
        "\n",
        "def total_loss(pred, true, X, stats, lam=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, X, stats)\n",
        "    return mse + lam * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout for Uncertainty Quantification\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    stacked = torch.stack(preds, dim=0)\n",
        "    return stacked.mean(0), stacked.std(0)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-3, wd=1e-5, lam=1.0, epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train_loss': [], 'val_loss': []}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_train = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred    = model(xb)\n",
        "            loss, mse, phys = total_loss(pred, yb, xb, stats, lam)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train += loss.item() * xb.size(0)\n",
        "        train_loss = total_train / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred, = (model(xb),)  # just forward\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, lam)\n",
        "                total_val += loss.item() * xb.size(0)\n",
        "        val_loss = total_val / len(val_loader.dataset)\n",
        "\n",
        "        # Scheduler & logging\n",
        "        scheduler.step(val_loss)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        print(f\"Epoch {ep:03d} | Train {train_loss:.4e} | Val {val_loss:.4e}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val, wait = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_multiverse_ai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    # Load best if available\n",
        "    if os.path.exists(\"best_multiverse_ai.pth\"):\n",
        "        model.load_state_dict(torch.load(\"best_multiverse_ai.pth\"))\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_history(hist):\n",
        "    plt.figure()\n",
        "    plt.plot(hist['train_loss'], label='Train')\n",
        "    plt.plot(hist['val_loss'],   label='Val')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_scatter(y_true, y_pred, title):\n",
        "    plt.figure()\n",
        "    plt.scatter(y_true, y_pred, s=5, alpha=0.6)\n",
        "    m, M = y_true.min(), y_true.max()\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Pred\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_uncertainty(model, stats, device):\n",
        "    # Vary QVF vs DE for stability uncertainty\n",
        "    QVF_vals = np.linspace(0.1, 1.0, 100, dtype=np.float32)\n",
        "    DE_vals  = np.linspace(0.1, 2.0, 100, dtype=np.float32)\n",
        "    Qg, Dg   = np.meshgrid(QVF_vals, DE_vals)\n",
        "    pts = Qg.size\n",
        "\n",
        "    # Build tensor grid on device\n",
        "    grid = torch.zeros((pts, 6), device=device, dtype=torch.float32)\n",
        "    grid[:, 0] = torch.from_numpy(Qg.ravel()).to(device)\n",
        "    grid[:, 2] = torch.from_numpy(Dg.ravel()).to(device)\n",
        "    # fix other features at mean\n",
        "    for i in (1, 3, 4, 5):\n",
        "        grid[:, i] = stats['X_mean'][i]\n",
        "\n",
        "    # normalize\n",
        "    Xn = (grid - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout_predict(model, Xn, T=100)\n",
        "    U = std[:, 0].cpu().numpy().reshape(Qg.shape)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.pcolormesh(Qg, Dg, U, cmap='viridis', shading='auto')\n",
        "    plt.colorbar(label=\"Std Stability\")\n",
        "    plt.xlabel(\"QVF\")\n",
        "    plt.ylabel(\"DE\")\n",
        "    plt.title(\"Uncertainty Heatmap: Stability\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare dataset and stats\n",
        "    ds = MultiverseDataset(n_samples=6000)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, device=device, dtype=torch.float32),\n",
        "        'X_std':  torch.tensor(ds.X_std,  device=device, dtype=torch.float32),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, device=device, dtype=torch.float32),\n",
        "        'Y_std':  torch.tensor(ds.Y_std,  device=device, dtype=torch.float32),\n",
        "    }\n",
        "\n",
        "    # Split and DataLoaders\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    train_ds, val_ds = random_split(ds, [len(ds)-n_val, n_val])\n",
        "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=256)\n",
        "\n",
        "    # Initialize, train, and visualize\n",
        "    model = MultiverseAI().to(device)\n",
        "    history = train(\n",
        "        model, train_loader, val_loader,\n",
        "        stats, device,\n",
        "        lr=1e-3, wd=1e-5, lam=1.0,\n",
        "        epochs=100, patience=10\n",
        "    )\n",
        "\n",
        "    plot_history(history)\n",
        "\n",
        "    # Scatter true vs predicted (denormalized)\n",
        "    with torch.no_grad():\n",
        "        X_all = torch.from_numpy(ds.X).to(device)\n",
        "        Yp_n  = model(X_all).cpu().numpy()\n",
        "    Yp = Yp_n * ds.Y_std + ds.Y_mean\n",
        "    Yt = ds.Y * ds.Y_std + ds.Y_mean\n",
        "    names = [\"Stability\",\"Emergence Prob\",\"Interaction Eff\"]\n",
        "    for i, nm in enumerate(names):\n",
        "        plot_scatter(Yt[:,i], Yp[:,i], nm)\n",
        "\n",
        "    # Uncertainty heatmap for stability\n",
        "    plot_uncertainty(model, stats, device)"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOKTK9P9a+l2vudAtjEytKN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/final_analysis_undefined_presence_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSF6dSW2-Enu"
      },
      "outputs": [],
      "source": [
        "pip install torch numpy matplotlib seaborn umap-learn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "final_analysis_undefined_presence_ai.py\n",
        "\n",
        "1. Synthetic dataset (6 → 3)\n",
        "2. MC‐Dropout model\n",
        "3. Physics‐ and ODE‐informed residual losses\n",
        "4. AdamW training with scheduler, clipping, early stop\n",
        "5. Track per‐component losses\n",
        "6. MC‐Dropout inference (mean/std)\n",
        "7. Loss curves + per‐component loss curves\n",
        "8. OOD detection AUROC + uncertainty plots\n",
        "9. Reliability diagram\n",
        "10. UMAP embedding colored by true presence\n",
        "11. Physics residual histogram\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.autograd import grad\n",
        "import umap\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 1. Reproducibility & Device\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. Dataset\n",
        "class UndefinedPresenceDataset(Dataset):\n",
        "    def __init__(self, n=5000):\n",
        "        u = np.random.uniform(-1,1,(n,1))\n",
        "        v = np.random.uniform(0,2,(n,1))\n",
        "        w = np.random.uniform(-2,2,(n,1))\n",
        "        x = np.random.uniform(0,5,(n,1))\n",
        "        y = np.random.uniform(-1,1,(n,1))\n",
        "        z = np.random.uniform(0,1,(n,1))\n",
        "        X = np.hstack([u,v,w,x,y,z]).astype(np.float32)\n",
        "\n",
        "        presence = np.sin(u)*v + np.cos(w)\n",
        "        dissolution = np.exp(-x*y)\n",
        "        transcendence = z*(presence + dissolution)\n",
        "        Y = np.hstack([presence,dissolution,transcendence]).astype(np.float32)\n",
        "        Y += 0.01 * Y.std(axis=0) * np.random.randn(*Y.shape).astype(np.float32)\n",
        "\n",
        "        self.X_mean, self.X_std = X.mean(0), X.std(0) + 1e-8\n",
        "        self.Y_mean, self.Y_std = Y.mean(0), Y.std(0) + 1e-8\n",
        "\n",
        "        self.X = ((X - self.X_mean)/self.X_std).astype(np.float32)\n",
        "        self.Y = ((Y - self.Y_mean)/self.Y_std).astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return torch.from_numpy(self.X[i]), torch.from_numpy(self.Y[i])\n",
        "\n",
        "# 3. MC‐Dropout Model\n",
        "class UndefinedPresenceAI(nn.Module):\n",
        "    def __init__(self, inp=6, hid=32, out=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(inp,hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p_drop),\n",
        "            nn.Linear(hid,out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 4a. Physics residual\n",
        "def physics_residual(pred, X, stats):\n",
        "    Xd = X*stats['X_std'] + stats['X_mean']\n",
        "    u,v,w,x,y,z = Xd.T\n",
        "    pres = torch.sin(u)*v + torch.cos(w)\n",
        "    dis  = torch.exp(-x*y)\n",
        "    tr   = z*(pres+dis)\n",
        "    Y_phys = torch.stack([pres,dis,tr],dim=1)\n",
        "    Yn = (Y_phys - stats['Y_mean'])/stats['Y_std']\n",
        "    return nn.MSELoss()(pred, Yn)\n",
        "\n",
        "# 4b. ODE residual: ∂presence/∂u ≈ v⋅cos(u)\n",
        "def ode_residual(pred, X, stats):\n",
        "    # denormalize pred\n",
        "    pred_den = pred*stats['Y_std'] + stats['Y_mean']\n",
        "    pres = pred_den[:,0]\n",
        "    grads = grad(pres.sum(), X, create_graph=True)[0]\n",
        "    dp_du = grads[:,0]\n",
        "    Xd = X*stats['X_std'] + stats['X_mean']\n",
        "    u,v = Xd[:,0], Xd[:,1]\n",
        "    target = v*torch.cos(u)\n",
        "    return nn.MSELoss()(dp_du, target)\n",
        "\n",
        "# 4c. Combined loss\n",
        "def total_loss(pred, y_true, X, stats, lam_phys=1.0, lam_ode=0.5):\n",
        "    mse  = nn.MSELoss()(pred, y_true)\n",
        "    phys = physics_residual(pred, X, stats)\n",
        "    ode  = ode_residual(pred, X, stats)\n",
        "    return mse + lam_phys*phys + lam_ode*ode, mse.item(), phys.item(), ode.item()\n",
        "\n",
        "# 5. MC‐Dropout prediction\n",
        "def mc_predict(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    S = torch.stack(preds)\n",
        "    return S.mean(0), S.std(0)\n",
        "\n",
        "# 6. Training with per‐component loss tracking\n",
        "def train(model, dl_tr, dl_va, stats,\n",
        "          epochs=100, lr=1e-3, wd=1e-5, patience=10):\n",
        "    model.to(DEVICE)\n",
        "    opt = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sch = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, patience=5)\n",
        "    best_val = float('inf'); wait = 0\n",
        "\n",
        "    history = {k:[] for k in [\n",
        "        'train_total','train_mse','train_phys','train_ode',\n",
        "        'val_total','val_mse','val_phys','val_ode'\n",
        "    ]}\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # — Training —\n",
        "        model.train()\n",
        "        accum = np.zeros(4); count = 0\n",
        "        for Xb, Yb in dl_tr:\n",
        "            Xb = Xb.to(DEVICE).requires_grad_(True)\n",
        "            Yb = Yb.to(DEVICE)\n",
        "            pred = model(Xb)\n",
        "            loss, m, p, o = total_loss(pred, Yb, Xb, stats)\n",
        "            opt.zero_grad(); loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "            opt.step()\n",
        "            b = Xb.size(0)\n",
        "            accum += np.array([loss.item(),m,p,o])*b\n",
        "            count += b\n",
        "\n",
        "        # store train losses\n",
        "        history['train_total'].append(accum[0]/count)\n",
        "        history['train_mse'].append(  accum[1]/count)\n",
        "        history['train_phys'].append(accum[2]/count)\n",
        "        history['train_ode'].append(  accum[3]/count)\n",
        "\n",
        "        # — Validation (no torch.no_grad, we need grad for ODE) —\n",
        "        model.eval()\n",
        "        accum = np.zeros(4); count = 0\n",
        "        for Xv, Yv in dl_va:\n",
        "            Xv = Xv.to(DEVICE).requires_grad_(True)\n",
        "            Yv = Yv.to(DEVICE)\n",
        "            pred = model(Xv)\n",
        "            loss, m, p, o = total_loss(pred, Yv, Xv, stats)\n",
        "            b = Xv.size(0)\n",
        "            accum += np.array([loss.item(),m,p,o])*b\n",
        "            count += b\n",
        "\n",
        "        history['val_total'].append(accum[0]/count)\n",
        "        history['val_mse'].append(  accum[1]/count)\n",
        "        history['val_phys'].append(accum[2]/count)\n",
        "        history['val_ode'].append(  accum[3]/count)\n",
        "\n",
        "        sch.step(history['val_total'][-1])\n",
        "        print(f\"Epoch {epoch:3d} | \"\n",
        "              f\"Train {history['train_total'][-1]:.4f} | \"\n",
        "              f\"Val   {history['val_total'][-1]:.4f}\")\n",
        "\n",
        "        if history['val_total'][-1] < best_val - 1e-6:\n",
        "            best_val, wait = history['val_total'][-1], 0\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "    return history, model\n",
        "\n",
        "# 7. Main & Analysis\n",
        "if __name__ == \"__main__\":\n",
        "    # Prepare data\n",
        "    ds = UndefinedPresenceDataset()\n",
        "    n_val = int(0.2*len(ds))\n",
        "    ds_tr, ds_va = random_split(ds, [len(ds)-n_val, n_val])\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=128, shuffle=True)\n",
        "    dl_va = DataLoader(ds_va, batch_size=256)\n",
        "\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, device=DEVICE),\n",
        "        'X_std':  torch.tensor(ds.X_std,  device=DEVICE),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, device=DEVICE),\n",
        "        'Y_std':  torch.tensor(ds.Y_std,  device=DEVICE),\n",
        "    }\n",
        "\n",
        "    # Train\n",
        "    model = UndefinedPresenceAI().to(DEVICE)\n",
        "    history, model = train(model, dl_tr, dl_va, stats)\n",
        "    np.savez(\"history.npz\", **history)\n",
        "\n",
        "    # MC‐Dropout on in‐distribution\n",
        "    X_all = torch.from_numpy(ds.X).to(DEVICE)\n",
        "    mean_pred, std_pred = mc_predict(model, X_all)\n",
        "\n",
        "    # Setup plots folder\n",
        "    os.makedirs(\"plots\", exist_ok=True)\n",
        "    epochs = range(1, len(history['train_total'])+1)\n",
        "\n",
        "    # 8. Plot: total loss curves\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, history['train_total'], '--', label=\"Train Total\")\n",
        "    plt.plot(epochs, history['val_total'],   '-',  label=\"Val   Total\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Total Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"plots/loss_curves.png\", dpi=150)\n",
        "\n",
        "    # 9. Per‐component loss curves\n",
        "    plt.figure()\n",
        "    for comp in ['mse','phys','ode']:\n",
        "        plt.plot(epochs, history[f\"train_{comp}\"], '--', label=f\"Train {comp.upper()}\")\n",
        "        plt.plot(epochs, history[f\"val_{comp}\"],   '-',  label=f\"Val   {comp.upper()}\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Per‐Component Loss Curves\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"plots/per_component_losses.png\", dpi=150)\n",
        "\n",
        "    # 10. OOD detection AUROC\n",
        "    def sample_ood(n=2000):\n",
        "        u = np.random.uniform(-2,2,(n,1))\n",
        "        v = np.random.uniform(0,2,(n,1))\n",
        "        w = np.random.uniform(-2,2,(n,1))\n",
        "        x = np.random.uniform(0,5,(n,1))\n",
        "        y = np.random.uniform(-1,1,(n,1))\n",
        "        z = np.random.uniform(0,1,(n,1))\n",
        "        X = np.hstack([u,v,w,x,y,z]).astype(np.float32)\n",
        "        X_std = (X - ds.X_mean)/ds.X_std\n",
        "        return torch.from_numpy(X_std).to(DEVICE)\n",
        "\n",
        "    X_ood = sample_ood()\n",
        "    _, std_ood = mc_predict(model, X_ood)\n",
        "\n",
        "    labels = np.concatenate([np.zeros(std_pred.size(0)), np.ones(std_ood.size(0))])\n",
        "    print(\"\\nOOD Detection AUROC:\")\n",
        "    for i,name in enumerate(['Presence','Dissolution','Transcendence']):\n",
        "        scores = np.concatenate([std_pred[:,i].cpu().numpy(),\n",
        "                                 std_ood[:,i].cpu().numpy()])\n",
        "        auc = roc_auc_score(labels, scores)\n",
        "        print(f\"  {name:13s}: {auc:.4f}\")\n",
        "\n",
        "    # Plot ID vs OOD uncertainty\n",
        "    plt.figure()\n",
        "    for i,name in enumerate(['Presence','Dissolution','Transcendence']):\n",
        "        sns.kdeplot(std_pred[:,i].cpu(), label=f\"ID {name}\")\n",
        "        sns.kdeplot(std_ood[:,i].cpu(), label=f\"OOD {name}\")\n",
        "    plt.title(\"ID vs OOD Uncertainty Distributions\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"plots/ood_detection.png\", dpi=150)\n",
        "\n",
        "    # 11. Reliability diagram\n",
        "    errors = (mean_pred - torch.from_numpy(ds.Y).to(DEVICE)).abs().cpu().numpy()\n",
        "    stds   = std_pred.cpu().numpy()\n",
        "    plt.figure()\n",
        "    for i,name in enumerate(['Presence','Dissolution','Transcendence']):\n",
        "        bins = np.linspace(stds[:,i].min(), stds[:,i].max(), 10)\n",
        "        idx = np.digitize(stds[:,i], bins)-1\n",
        "        avg_err, avg_std = [], []\n",
        "        for b in range(len(bins)):\n",
        "            mask = idx==b\n",
        "            if mask.sum()>0:\n",
        "                avg_err.append(errors[mask,i].mean())\n",
        "                avg_std.append(stds[mask,i].mean())\n",
        "        plt.plot(avg_std, avg_err, '-o', label=name)\n",
        "    plt.xlabel(\"Avg Pred STD\"); plt.ylabel(\"Avg Abs Error\")\n",
        "    plt.title(\"Reliability Diagram\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"plots/reliability.png\", dpi=150)\n",
        "\n",
        "    # 12. UMAP embedding colored by true presence\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        feats = model.net[0](X_all).cpu().numpy()\n",
        "    emb = umap.UMAP(n_components=2, random_state=SEED).fit_transform(feats)\n",
        "    raw = ds.X*ds.X_std + ds.X_mean\n",
        "    u,v,w = raw[:,0], raw[:,1], raw[:,2]\n",
        "    true_pres = np.sin(u)*v + np.cos(w)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sc = plt.scatter(emb[:,0], emb[:,1], c=true_pres, cmap=\"coolwarm\", s=4)\n",
        "    plt.colorbar(sc, label=\"True Presence\")\n",
        "    plt.title(\"UMAP of Hidden Features\")\n",
        "    plt.savefig(\"plots/umap_presence.png\", dpi=150)\n",
        "\n",
        "    # 13. Physics residual histogram\n",
        "    with torch.no_grad():\n",
        "        Xd = X_all*stats['X_std'] + stats['X_mean']\n",
        "        u,v,w,x,y,z = Xd.T\n",
        "        pres = torch.sin(u)*v + torch.cos(w)\n",
        "        dis  = torch.exp(-x*y)\n",
        "        tr   = z*(pres+dis)\n",
        "        Y_phys = torch.stack([pres,dis,tr],dim=1).cpu().numpy()\n",
        "    pred_den = mean_pred.cpu().numpy()*ds.Y_std + ds.Y_mean\n",
        "    residuals = ((pred_den - Y_phys)**2).mean(axis=1)\n",
        "    plt.figure()\n",
        "    sns.histplot(residuals, bins=50, kde=True)\n",
        "    plt.title(\"Physics Residual (MSE) Histogram\")\n",
        "    plt.xlabel(\"Residual\"); plt.ylabel(\"Count\")\n",
        "    plt.savefig(\"plots/physics_residual_hist.png\", dpi=150)\n",
        "\n",
        "    print(\"\\nDone. All plots in ./plots/ and history saved to history.npz\")"
      ],
      "metadata": {
        "id": "GfjM80Va-Tqt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
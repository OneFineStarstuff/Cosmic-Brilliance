{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOi9Y3RrdsGLdJtdUFOvQkB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/rge_validator_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyG3ojD5MlLt"
      },
      "outputs": [],
      "source": [
        "# rge/validator.py\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Callable, Iterable, Optional, Dict, Any, List, Tuple, Protocol, Union\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "\n",
        "Array = np.ndarray\n",
        "\n",
        "class SimOutput(Protocol):\n",
        "    t: Array            # shape (T,)\n",
        "    y: Array            # shape (S, T)\n",
        "    states: Iterable[str]  # e.g., ['x', 'y']\n",
        "\n",
        "Token = str\n",
        "\n",
        "def _to_tokens(eq: Any) -> List[Token]:\n",
        "    # SymPy-safe: fall back to string if no .args\n",
        "    s = str(eq)\n",
        "    # Simple tokenizer: identifiers, numbers, operators\n",
        "    return [tok for tok in re.findall(r\"[A-Za-z_]+|\\d+\\.\\d+|\\d+|[+\\-*/^=()]\", s) if tok.strip()]\n",
        "\n",
        "def _description_length(equations: Iterable[Any]) -> int:\n",
        "    # Weighted token count for MDL-like measure\n",
        "    weights = {\n",
        "        \"+\": 1, \"-\": 1, \"*\": 1, \"/\": 2, \"^\": 2, \"=\": 0,\n",
        "        \"sin\": 3, \"cos\": 3, \"exp\": 3, \"log\": 3\n",
        "    }\n",
        "    total = 0\n",
        "    for eq in equations:\n",
        "        for tok in _to_tokens(eq):\n",
        "            total += weights.get(tok, 1)  # default weight\n",
        "    return total\n",
        "\n",
        "def _simplicity_score(desc_len: int, lam: float = 0.03) -> float:\n",
        "    # Smoothly decreasing in description length, bounded in (0,1]\n",
        "    return float(np.exp(-lam * max(desc_len, 0)))\n",
        "\n",
        "def _masked_var(y_true: Array, axis=None) -> float:\n",
        "    mask = ~np.isnan(y_true)\n",
        "    if not np.any(mask):\n",
        "        return 0.0\n",
        "    centered = y_true[mask] - np.nanmean(y_true)\n",
        "    v = float(np.mean(centered**2))\n",
        "    return v\n",
        "\n",
        "def _accuracy_with_gt(y_pred: Array, y_true: Array) -> Tuple[float, Dict[str, Any]]:\n",
        "    if y_pred.shape != y_true.shape:\n",
        "        raise ValueError(f\"Shape mismatch: pred {y_pred.shape} vs gt {y_true.shape}\")\n",
        "    mask = ~np.isnan(y_true)\n",
        "    if not np.any(mask):\n",
        "        return 0.0, {\"mse\": None, \"var\": None, \"masked_fraction\": 0.0}\n",
        "\n",
        "    diff = (y_pred - y_true)[mask]\n",
        "    mse = float(np.mean(diff**2))\n",
        "    var = _masked_var(y_true)\n",
        "    # Variance-normalized error; fall back if var≈0\n",
        "    if var > 0:\n",
        "        err = mse / var\n",
        "    else:\n",
        "        # Scale by squared amplitude to avoid division by ~0\n",
        "        amp = float(np.nanmax(np.abs(y_true)) or 1.0)\n",
        "        err = mse / (amp**2 if amp > 0 else 1.0)\n",
        "    acc = float(np.exp(-err))\n",
        "    return acc, {\"mse\": mse, \"var\": var, \"norm_err\": err}\n",
        "\n",
        "def _finite_diff(y: Array, t: Array) -> Array:\n",
        "    # Central differences in time; shape (S, T)\n",
        "    dt = np.diff(t)\n",
        "    if np.any(dt <= 0):\n",
        "        raise ValueError(\"Time vector must be strictly increasing\")\n",
        "    S, T = y.shape\n",
        "    dy = np.empty_like(y)\n",
        "    # Forward/backward at ends\n",
        "    dy[:, 0] = (y[:, 1] - y[:, 0]) / dt[0]\n",
        "    dy[:, -1] = (y[:, -1] - y[:, -2]) / dt[-1]\n",
        "    # Central for interior\n",
        "    mid_dt = (t[2:] - t[:-2]) / 2.0\n",
        "    dy[:, 1:-1] = (y[:, 2:] - y[:, :-2]) / mid_dt\n",
        "    return dy\n",
        "\n",
        "def _smoothness_score(y: Array, t: Array) -> float:\n",
        "    # Penalize high curvature relative to scale\n",
        "    dy = _finite_diff(y, t)\n",
        "    d2y = _finite_diff(dy, t)\n",
        "    num = np.nanmean(d2y**2)\n",
        "    denom = (np.nanmean(y**2) or 1.0)\n",
        "    ratio = float(num / denom)\n",
        "    return float(np.exp(-0.1 * ratio))\n",
        "\n",
        "def _reversibility_score(y: Array, t: Array) -> float:\n",
        "    # Time-reversal invariance proxy: compare y with reversed time interpolation\n",
        "    # Simple proxy: correlation between forward and reversed sequences\n",
        "    y_f = (y - np.nanmean(y, axis=1, keepdims=True)) / (np.nanstd(y, axis=1, keepdims=True) + 1e-12)\n",
        "    y_r = np.flip(y_f, axis=1)\n",
        "    # Mean absolute correlation across states\n",
        "    corr = np.mean([np.abs(np.corrcoef(y_f[i], y_r[i])[0,1]) for i in range(y.shape[0]) if y.shape[1] > 3])\n",
        "    if np.isnan(corr):\n",
        "        corr = 0.0\n",
        "    return float(0.5 + 0.5 * corr)  # map [-1,1]→[0,1]\n",
        "\n",
        "def _energy_drift_score(\n",
        "    y: Array, t: Array, energy_fn: Optional[Callable[[Array], Array]] = None\n",
        ") -> Tuple[float, Optional[float]]:\n",
        "    if energy_fn is None:\n",
        "        return 0.5, None  # neutral if no energy provided\n",
        "    E = energy_fn(y)  # expects shape (T,)\n",
        "    if E is None or np.all(np.isnan(E)):\n",
        "        return 0.5, None\n",
        "    # Drift relative to median energy\n",
        "    drift = float(np.nanmax(np.abs(E - np.nanmedian(E))) / (np.nanmedian(np.abs(E)) + 1e-9))\n",
        "    score = float(np.exp(-0.2 * drift))\n",
        "    return score, drift\n",
        "\n",
        "def _kl_divergence(p: Array, q: Array) -> float:\n",
        "    eps = 1e-12\n",
        "    p = p + eps\n",
        "    q = q + eps\n",
        "    p = p / p.sum()\n",
        "    q = q / q.sum()\n",
        "    return float(np.sum(p * np.log(p / q)))\n",
        "\n",
        "def _token_hist(tokens: List[Token], vocab: List[Token]) -> Array:\n",
        "    idx = {tok: i for i, tok in enumerate(vocab)}\n",
        "    counts = np.zeros(len(vocab), dtype=float)\n",
        "    for t in tokens:\n",
        "        if t in idx:\n",
        "            counts[idx[t]] += 1\n",
        "    if counts.sum() == 0:\n",
        "        counts += 1.0  # uniform if empty\n",
        "    return counts\n",
        "\n",
        "def _novelty_score(\n",
        "    equations: Iterable[Any],\n",
        "    prior_vocab: List[Token],\n",
        "    prior_freq: Array,\n",
        "    beta: float = 0.6\n",
        ") -> Tuple[float, Dict[str, Any]]:\n",
        "    # Build empirical distribution from equations\n",
        "    toks: List[Token] = []\n",
        "    for eq in equations:\n",
        "        toks.extend(_to_tokens(eq))\n",
        "    p_hist = _token_hist(toks, prior_vocab)\n",
        "    kl = _kl_divergence(p_hist, prior_freq)\n",
        "    # Map KL (0..∞) to (0,1]: higher KL ⇒ higher novelty\n",
        "    score = float(1.0 - np.exp(-beta * kl))\n",
        "    return score, {\"kl\": kl, \"token_count\": int(p_hist.sum())}\n",
        "\n",
        "@dataclass\n",
        "class ScoreReport:\n",
        "    total: float\n",
        "    passed: bool\n",
        "    components: Dict[str, float]\n",
        "    details: Dict[str, Any]\n",
        "    threshold: float\n",
        "    version: str = \"meta-validator/1.0.0\"\n",
        "    timestamp: float = time.time()\n",
        "\n",
        "    def to_json(self) -> str:\n",
        "        return json.dumps({\n",
        "            **asdict(self),\n",
        "        }, indent=2, sort_keys=True)\n",
        "\n",
        "class MetaValidator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        threshold: float = 0.75,\n",
        "        alpha: Tuple[float, float, float] = (0.5, 0.3, 0.2),\n",
        "        prior_vocab: Optional[List[Token]] = None,\n",
        "        prior_freq: Optional[Array] = None,\n",
        "        seed: Optional[int] = 42,\n",
        "    ):\n",
        "        self.threshold = float(threshold)\n",
        "        self.w_acc, self.w_simp, self.w_nov = alpha\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        # Default prior: minimal symbolic vocabulary\n",
        "        default_vocab = [\"x\",\"y\",\"z\",\"t\",\"+\",\"-\",\"*\",\"/\",\"^\",\"=\",\"sin\",\"cos\",\"exp\",\"log\",\"1\",\"2\",\"0\"]\n",
        "        self.prior_vocab = prior_vocab or default_vocab\n",
        "        if prior_freq is None:\n",
        "            # Smooth/heavy-tailed prior\n",
        "            self.prior_freq = np.array([3,3,1,2,5,4,5,3,2,0,1,1,1,1,2,1,2], dtype=float)\n",
        "        else:\n",
        "            self.prior_freq = np.array(prior_freq, dtype=float)\n",
        "        if len(self.prior_vocab) != len(self.prior_freq):\n",
        "            raise ValueError(\"prior_vocab and prior_freq must align\")\n",
        "\n",
        "    def score(\n",
        "        self,\n",
        "        theory: Dict[str, Any],\n",
        "        sim_output: SimOutput,\n",
        "        ground_truth: Optional[Array] = None,\n",
        "        energy_fn: Optional[Callable[[Array], Array]] = None,\n",
        "    ) -> ScoreReport:\n",
        "        \"\"\"\n",
        "        Compute a composite score:\n",
        "        S = w_acc * acc + w_simp * simp + w_nov * nov\n",
        "\n",
        "        Args:\n",
        "          theory: dict with at least {\"equations\": Iterable[Any]}\n",
        "          sim_output: provides .t (T,), .y (S,T), .states (Iterable[str])\n",
        "          ground_truth: optional array shaped like sim_output.y\n",
        "          energy_fn: optional function mapping y (S,T) -> energy (T,)\n",
        "        \"\"\"\n",
        "        # Validate sim_output\n",
        "        t = np.asarray(sim_output.t)\n",
        "        y = np.asarray(sim_output.y)\n",
        "        if y.ndim != 2:\n",
        "            raise ValueError(f\"sim_output.y must be 2D (S,T), got {y.shape}\")\n",
        "        if t.ndim != 1 or t.shape[0] != y.shape[1]:\n",
        "            raise ValueError(\"Time vector length must match y's time dimension\")\n",
        "        equations = theory.get(\"equations\", [])\n",
        "        if not isinstance(equations, (list, tuple)) or len(equations) == 0:\n",
        "            raise ValueError(\"theory['equations'] must be a non-empty list\")\n",
        "\n",
        "        # 1) Accuracy\n",
        "        if ground_truth is not None:\n",
        "            acc, acc_det = _accuracy_with_gt(y, np.asarray(ground_truth))\n",
        "        else:\n",
        "            # Proxy blend\n",
        "            rev = _reversibility_score(y, t)\n",
        "            smo = _smoothness_score(y, t)\n",
        "            eng, drift = _energy_drift_score(y, t, energy_fn)\n",
        "            acc = float(0.5 * rev + 0.3 * smo + 0.2 * eng)\n",
        "            acc_det = {\"proxy\": True, \"reversibility\": rev, \"smoothness\": smo, \"energy\": eng, \"energy_drift\": drift}\n",
        "\n",
        "        # 2) Simplicity\n",
        "        desc_len = _description_length(equations)\n",
        "        simp = _simplicity_score(desc_len)\n",
        "        simp_det = {\"description_length\": desc_len}\n",
        "\n",
        "        # 3) Novelty\n",
        "        nov, nov_det = _novelty_score(equations, self.prior_vocab, self.prior_freq)\n",
        "\n",
        "        total = float(self.w_acc * acc + self.w_simp * simp + self.w_nov * nov)\n",
        "        passed = bool(total >= self.threshold)\n",
        "\n",
        "        details = {\n",
        "            \"accuracy\": acc_det,\n",
        "            \"simplicity\": simp_det,\n",
        "            \"novelty\": nov_det,\n",
        "            \"weights\": {\"acc\": self.w_acc, \"simp\": self.w_simp, \"nov\": self.w_nov},\n",
        "        }\n",
        "        return ScoreReport(\n",
        "            total=total,\n",
        "            passed=passed,\n",
        "            components={\"accuracy\": acc, \"simplicity\": simp, \"novelty\": nov},\n",
        "            details=details,\n",
        "            threshold=self.threshold,\n",
        "        )\n",
        "\n",
        "    def calibrate_weights(\n",
        "        self,\n",
        "        labeled_samples: List[Dict[str, Any]],\n",
        "        method: str = \"grid\",\n",
        "    ) -> Tuple[Tuple[float,float,float], Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Fit alpha weights to best separate accepted vs rejected samples.\n",
        "        labeled_samples: list of {\"components\": {\"accuracy\":a,\"simplicity\":s,\"novelty\":n}, \"label\": {0,1}}\n",
        "        Returns (w_acc, w_simp, w_nov), diagnostics\n",
        "        \"\"\"\n",
        "        comps = np.array([[d[\"components\"][\"accuracy\"], d[\"components\"][\"simplicity\"], d[\"components\"][\"novelty\"]] for d in labeled_samples])\n",
        "        labels = np.array([d[\"label\"] for d in labeled_samples], dtype=int)\n",
        "        if method == \"grid\":\n",
        "            grid = np.linspace(0.0, 1.0, 11)\n",
        "            best_w, best_score = (0.5,0.3,0.2), -1.0\n",
        "            for wa in grid:\n",
        "                for ws in grid:\n",
        "                    wn = 1.0 - wa - ws\n",
        "                    if wn < 0 or wn > 1:\n",
        "                        continue\n",
        "                    scores = comps @ np.array([wa, ws, wn])\n",
        "                    preds = (scores >= self.threshold).astype(int)\n",
        "                    f1 = self._f1(labels, preds)\n",
        "                    if f1 > best_score:\n",
        "                        best_score = f1\n",
        "                        best_w = (float(wa), float(ws), float(wn))\n",
        "            self.w_acc, self.w_simp, self.w_nov = best_w\n",
        "            return best_w, {\"f1\": best_score, \"method\": method}\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only 'grid' method is provided for now.\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _f1(y_true: Array, y_pred: Array) -> float:\n",
        "        tp = np.sum((y_true==1) & (y_pred==1))\n",
        "        fp = np.sum((y_true==0) & (y_pred==1))\n",
        "        fn = np.sum((y_true==1) & (y_pred==0))\n",
        "        prec = tp / (tp + fp + 1e-12)\n",
        "        rec  = tp / (tp + fn + 1e-12)\n",
        "        if prec + rec == 0:\n",
        "            return 0.0\n",
        "        return 2 * prec * rec / (prec + rec)"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOrKux4SefbDzROtt1lvgMh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/mck_agent_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S31qn5QmRmnq"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "MCK-style agent loop with human-review decorator fixed to forward *args, **kwargs.\n",
        "\n",
        "Focus:\n",
        "- requires_human_review decorator accepts arbitrary kwargs (e.g., feedback).\n",
        "- Agent.revise() calls mmr.adapt(..., feedback=feedback) without crashing.\n",
        "- Lightweight, auditable prints to trace decisions and state transitions.\n",
        "\n",
        "Run:\n",
        "    python mck_agent.py\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from functools import wraps\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Decorators\n",
        "# -------------------------------\n",
        "\n",
        "def requires_human_review(if_score_below: float):\n",
        "    \"\"\"\n",
        "    Decorator for gating adaptation behind a human-review notice when score is low.\n",
        "    Crucially: forwards *args, **kwargs so unexpected kwargs (like feedback) won't crash.\n",
        "    \"\"\"\n",
        "    def deco(fn):\n",
        "        @wraps(fn)\n",
        "        def wrapped(self, kernel, reason, *args, **kwargs):\n",
        "            if reason < if_score_below:\n",
        "                print(f\"[HUMAN-REVIEW] score={reason:.3f} < threshold={if_score_below:.3f} — flagging before adapt()\")\n",
        "            return fn(self, kernel, reason, *args, **kwargs)\n",
        "        return wrapped\n",
        "    return deco\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Data structures\n",
        "# -------------------------------\n",
        "\n",
        "@dataclass\n",
        "class Feedback:\n",
        "    \"\"\"Peer feedback artifact that can be logged, audited, and consumed by adaptation.\"\"\"\n",
        "    from_peer: str\n",
        "    t: int\n",
        "    comment: str\n",
        "    delta_hint: Optional[str] = None\n",
        "    weight: float = 1.0\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Engines and components\n",
        "# -------------------------------\n",
        "\n",
        "class SimilarityEngine:\n",
        "    \"\"\"\n",
        "    Simple similarity proxy:\n",
        "    - Tokenize by whitespace\n",
        "    - Compute Jaccard similarity between theory and gt token sets\n",
        "    \"\"\"\n",
        "    def test(self, theory: str, gt: str) -> Dict[str, Any]:\n",
        "        tset = set(theory.lower().split())\n",
        "        gset = set(gt.lower().split())\n",
        "        inter = len(tset & gset)\n",
        "        union = max(1, len(tset | gset))\n",
        "        jacc = inter / union\n",
        "        return {\n",
        "            \"tokens_theory\": len(tset),\n",
        "            \"tokens_gt\": len(gset),\n",
        "            \"jaccard\": jacc,\n",
        "            \"overlap\": inter,\n",
        "            \"union\": union,\n",
        "        }\n",
        "\n",
        "\n",
        "class ScoringEngine:\n",
        "    \"\"\"\n",
        "    Turns similarity signals into a scalar score [0,1].\n",
        "    Here: just return Jaccard. Could blend multiple signals with weights.\n",
        "    \"\"\"\n",
        "    def evaluate(self, theory: str, sim_res: Dict[str, Any], gt: str) -> float:\n",
        "        return float(sim_res.get(\"jaccard\", 0.0))\n",
        "\n",
        "\n",
        "class TheoryGenerator:\n",
        "    \"\"\"\n",
        "    Generates a new theory string based on an 'abstraction' that encodes current strategy.\n",
        "    - temperature: exploration intensity\n",
        "    - nudge: a hint or token to incorporate from feedback\n",
        "    \"\"\"\n",
        "    def __init__(self, vocabulary: Optional[List[str]] = None):\n",
        "        self.vocab = vocabulary or [\n",
        "            \"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"lazy\", \"dog\",\n",
        "            \"smart\", \"agile\", \"beyond\", \"robust\", \"audit\", \"traceable\", \"reliable\",\n",
        "            \"policy\", \"signal\", \"contract\", \"governed\", \"reviewed\", \"clear\"\n",
        "        ]\n",
        "\n",
        "    def generate(self, abstraction: Dict[str, Any]) -> str:\n",
        "        temperature = float(abstraction.get(\"temperature\", 0.2))\n",
        "        nudge = abstraction.get(\"nudge\")\n",
        "\n",
        "        k = min(9, max(3, int(3 + temperature * 6)))\n",
        "        tokens = random.sample(self.vocab, k=k)\n",
        "\n",
        "        if isinstance(nudge, str) and nudge:\n",
        "            # Bias by ensuring the nudge appears\n",
        "            tokens = [nudge] + [tok for tok in tokens if tok != nudge]\n",
        "        # Always ensure some core structure appears for scoring realism\n",
        "        core = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
        "        # Mix core and sampled tokens with a simple heuristic\n",
        "        mix = []\n",
        "        for i, tok in enumerate(core):\n",
        "            mix.append(tok)\n",
        "            if i % 2 == 1 and tokens:\n",
        "                mix.append(tokens.pop(0))\n",
        "        # Deduplicate while preserving order\n",
        "        seen = set()\n",
        "        ordered = []\n",
        "        for tok in mix:\n",
        "            if tok not in seen:\n",
        "                seen.add(tok)\n",
        "                ordered.append(tok)\n",
        "        return \" \".join(ordered)\n",
        "\n",
        "\n",
        "class MemoryModelReviser:\n",
        "    \"\"\"\n",
        "    Adapts the kernel (agent) state based on a score and optional feedback.\n",
        "    This is where we translate signals into generator abstractions.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.history: List[Dict[str, Any]] = []\n",
        "\n",
        "    @requires_human_review(if_score_below=0.20)\n",
        "    def adapt(self, kernel: \"Agent\", reason: float, feedback: Optional[Feedback] = None) -> None:\n",
        "        # Translate score to exploration temperature (lower score => explore more)\n",
        "        temperature = max(0.05, min(1.0, 1.0 - reason))\n",
        "        nudge = feedback.delta_hint if feedback and feedback.delta_hint else None\n",
        "\n",
        "        kernel.last_abstraction = {\n",
        "            \"temperature\": temperature,\n",
        "            \"nudge\": nudge,\n",
        "            \"last_score\": reason,\n",
        "            \"last_feedback_peer\": getattr(feedback, \"from_peer\", None),\n",
        "            \"t\": getattr(feedback, \"t\", None),\n",
        "        }\n",
        "\n",
        "        record = {\n",
        "            \"ts\": time.time(),\n",
        "            \"score\": reason,\n",
        "            \"temperature\": temperature,\n",
        "            \"nudge\": nudge,\n",
        "            \"peer\": getattr(feedback, \"from_peer\", None),\n",
        "            \"t\": getattr(feedback, \"t\", None),\n",
        "        }\n",
        "        self.history.append(record)\n",
        "\n",
        "        print(f\"[ADAPT] score={reason:.3f} -> temperature={temperature:.2f} \"\n",
        "              f\"nudge={repr(nudge)} peer={record['peer']} t={record['t']}\")\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Agent\n",
        "# -------------------------------\n",
        "\n",
        "class Agent:\n",
        "    \"\"\"\n",
        "    Orchestrates revise cycle:\n",
        "      1) similarity signals\n",
        "      2) scoring\n",
        "      3) mmr.adapt(..., feedback=feedback) [decorator handles human-review notice]\n",
        "      4) regenerate theory using latest abstraction\n",
        "    \"\"\"\n",
        "    def __init__(self, tg: TheoryGenerator, simi: SimilarityEngine, ste: ScoringEngine,\n",
        "                 mmr: MemoryModelReviser, gt: str) -> None:\n",
        "        self.tg = tg\n",
        "        self.simi = simi\n",
        "        self.ste = ste\n",
        "        self.mmr = mmr\n",
        "        self.gt = gt\n",
        "        self.last_abstraction: Optional[Dict[str, Any]] = None\n",
        "\n",
        "    def revise(self, theory: str, feedback: Optional[Feedback]) -> Tuple[str, float, Dict[str, Any]]:\n",
        "        sim_res = self.simi.test(theory, self.gt)\n",
        "        score = self.ste.evaluate(theory, sim_res, self.gt)\n",
        "        # The original failing call site, now safe because decorator forwards kwargs:\n",
        "        self.mmr.adapt(self, reason=score, feedback=feedback)\n",
        "        new_theory = self.tg.generate(self.last_abstraction or {})\n",
        "        audit = {\n",
        "            \"sim_res\": sim_res,\n",
        "            \"last_abstraction\": self.last_abstraction,\n",
        "            \"old_theory\": theory,\n",
        "            \"new_theory\": new_theory,\n",
        "        }\n",
        "        return new_theory, score, audit\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Peer validation\n",
        "# -------------------------------\n",
        "\n",
        "def peer_validate(peer: str, theory: str, gt: str, t: int) -> Optional[Feedback]:\n",
        "    \"\"\"\n",
        "    Simple validator:\n",
        "    - If theory lacks any core tokens from gt, suggest nudging one missing token.\n",
        "    - Weight feedback higher early on, then taper.\n",
        "    \"\"\"\n",
        "    gt_tokens = gt.lower().split()\n",
        "    thy_tokens = set(theory.lower().split())\n",
        "\n",
        "    missing = [tok for tok in gt_tokens if tok not in thy_tokens]\n",
        "    if not missing:\n",
        "        return Feedback(\n",
        "            from_peer=peer,\n",
        "            t=t,\n",
        "            comment=\"Looks aligned; keep consolidating.\",\n",
        "            delta_hint=None,\n",
        "            weight=0.8\n",
        "        )\n",
        "\n",
        "    # Heuristic: select a salient missing token to nudge towards\n",
        "    candidate = None\n",
        "    for tok in [\"quick\", \"brown\", \"fox\", \"jumps\", \"lazy\", \"dog\"]:\n",
        "        if tok in missing:\n",
        "            candidate = tok\n",
        "            break\n",
        "    candidate = candidate or random.choice(missing)\n",
        "\n",
        "    weight = max(0.4, 1.2 - 0.1 * t)\n",
        "    return Feedback(\n",
        "        from_peer=peer,\n",
        "        t=t,\n",
        "        comment=f\"Missing token '{candidate}'. Consider incorporating it.\",\n",
        "        delta_hint=candidate,\n",
        "        weight=weight\n",
        "    )\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Main loop\n",
        "# -------------------------------\n",
        "\n",
        "def main():\n",
        "    random.seed(42)\n",
        "\n",
        "    # Ground truth reference\n",
        "    X_true = \"the quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "    # Components\n",
        "    tg = TheoryGenerator()\n",
        "    simi = SimilarityEngine()\n",
        "    ste = ScoringEngine()\n",
        "    mmr = MemoryModelReviser()\n",
        "    agent = Agent(tg=tg, simi=simi, ste=ste, mmr=mmr, gt=X_true)\n",
        "\n",
        "    # Initial theory is intentionally incomplete\n",
        "    theory = \"brown fox jumps beyond policy\"\n",
        "    peers = [\"alpha\", \"beta\", \"gamma\"]\n",
        "\n",
        "    print(\"[INIT] gt:\", X_true)\n",
        "    print(\"[INIT] theory0:\", theory)\n",
        "    print(\"-\" * 72)\n",
        "\n",
        "    T = 5  # time steps\n",
        "    for t in range(1, T + 1):\n",
        "        print(f\"\\n[STEP] t={t}\")\n",
        "        # Step 2: peer validation + revision\n",
        "        for peer in peers:\n",
        "            fb = peer_validate(peer, theory, gt=X_true, t=t)\n",
        "            if not fb:\n",
        "                print(f\"[PEER] {peer}: no feedback\")\n",
        "                continue\n",
        "\n",
        "            print(f\"[PEER] {peer}: {fb.comment} (weight={fb.weight:.2f}, t={fb.t}, hint={repr(fb.delta_hint)})\")\n",
        "            theory, score, audit = agent.revise(theory, fb)\n",
        "\n",
        "            sim = audit[\"sim_res\"]\n",
        "            print(f\"[SCORE] jaccard={sim['jaccard']:.3f} overlap={sim['overlap']}/{sim['union']} -> new theory:\")\n",
        "            print(\"        \", theory)\n",
        "\n",
        "        # Step 3: novelty and broadcast (optional exploration step per time slice)\n",
        "        agent.last_abstraction = {\n",
        "            **(agent.last_abstraction or {}),\n",
        "            \"temperature\": min(1.0, (agent.last_abstraction or {}).get(\"temperature\", 0.2) + 0.05),\n",
        "        }\n",
        "        theory = agent.tg.generate(agent.last_abstraction or {})\n",
        "        print(f\"[NOVELTY] t={t} broadcast theory:\")\n",
        "        print(\"          \", theory)\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 72)\n",
        "    print(\"[DONE] Final theory:\", theory)\n",
        "    print(\"[HISTORY] adapt events:\", len(mmr.history))\n",
        "    if mmr.history:\n",
        "        last = mmr.history[-1]\n",
        "        print(f\"         last: score={last['score']:.3f} temp={last['temperature']:.2f} nudge={repr(last['nudge'])}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "MCK-style agent loop with:\n",
        "1) requires_human_review decorator that forwards *args, **kwargs\n",
        "2) Lock-in mechanism: when theory fully matches GT, exploration is frozen\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from functools import wraps\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "import random\n",
        "import time\n",
        "\n",
        "# -------------------------------\n",
        "# Decorators\n",
        "# -------------------------------\n",
        "\n",
        "def requires_human_review(if_score_below: float):\n",
        "    \"\"\"Decorator that prints a review notice for low scores, forwarding all args/kwargs.\"\"\"\n",
        "    def deco(fn):\n",
        "        @wraps(fn)\n",
        "        def wrapped(self, kernel, reason, *args, **kwargs):\n",
        "            if reason < if_score_below:\n",
        "                print(f\"[HUMAN-REVIEW] score={reason:.3f} < threshold={if_score_below:.3f} — flagging before adapt()\")\n",
        "            return fn(self, kernel, reason, *args, **kwargs)\n",
        "        return wrapped\n",
        "    return deco\n",
        "\n",
        "# -------------------------------\n",
        "# Data structures\n",
        "# -------------------------------\n",
        "\n",
        "@dataclass\n",
        "class Feedback:\n",
        "    from_peer: str\n",
        "    t: int\n",
        "    comment: str\n",
        "    delta_hint: Optional[str] = None\n",
        "    weight: float = 1.0\n",
        "\n",
        "# -------------------------------\n",
        "# Engines and components\n",
        "# -------------------------------\n",
        "\n",
        "class SimilarityEngine:\n",
        "    def test(self, theory: str, gt: str) -> Dict[str, Any]:\n",
        "        tset = set(theory.lower().split())\n",
        "        gset = set(gt.lower().split())\n",
        "        inter = len(tset & gset)\n",
        "        union = max(1, len(tset | gset))\n",
        "        return {\n",
        "            \"tokens_theory\": len(tset),\n",
        "            \"tokens_gt\": len(gset),\n",
        "            \"jaccard\": inter / union,\n",
        "            \"overlap\": inter,\n",
        "            \"union\": union,\n",
        "        }\n",
        "\n",
        "class ScoringEngine:\n",
        "    def evaluate(self, theory: str, sim_res: Dict[str, Any], gt: str) -> float:\n",
        "        return float(sim_res.get(\"jaccard\", 0.0))\n",
        "\n",
        "class TheoryGenerator:\n",
        "    def __init__(self, vocabulary: Optional[List[str]] = None):\n",
        "        self.vocab = vocabulary or [\n",
        "            \"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"lazy\", \"dog\",\n",
        "            \"smart\", \"agile\", \"beyond\", \"robust\", \"audit\", \"traceable\", \"reliable\",\n",
        "            \"policy\", \"signal\", \"contract\", \"governed\", \"reviewed\", \"clear\"\n",
        "        ]\n",
        "\n",
        "    def generate(self, abstraction: Dict[str, Any]) -> str:\n",
        "        temperature = float(abstraction.get(\"temperature\", 0.2))\n",
        "        nudge = abstraction.get(\"nudge\")\n",
        "\n",
        "        k = min(9, max(3, int(3 + temperature * 6)))\n",
        "        tokens = random.sample(self.vocab, k=k)\n",
        "        if isinstance(nudge, str) and nudge:\n",
        "            tokens = [nudge] + [tok for tok in tokens if tok != nudge]\n",
        "\n",
        "        core = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
        "        mix = []\n",
        "        for i, tok in enumerate(core):\n",
        "            mix.append(tok)\n",
        "            if i % 2 == 1 and tokens:\n",
        "                mix.append(tokens.pop(0))\n",
        "\n",
        "        seen, ordered = set(), []\n",
        "        for tok in mix:\n",
        "            if tok not in seen:\n",
        "                seen.add(tok)\n",
        "                ordered.append(tok)\n",
        "        return \" \".join(ordered)\n",
        "\n",
        "class MemoryModelReviser:\n",
        "    def __init__(self):\n",
        "        self.history: List[Dict[str, Any]] = []\n",
        "\n",
        "    @requires_human_review(if_score_below=0.20)\n",
        "    def adapt(self, kernel: \"Agent\", reason: float, feedback: Optional[Feedback] = None) -> None:\n",
        "        temperature = max(0.05, min(1.0, 1.0 - reason))\n",
        "        nudge = feedback.delta_hint if feedback and feedback.delta_hint else None\n",
        "\n",
        "        kernel.last_abstraction = {\n",
        "            \"temperature\": temperature,\n",
        "            \"nudge\": nudge,\n",
        "            \"last_score\": reason,\n",
        "            \"last_feedback_peer\": getattr(feedback, \"from_peer\", None),\n",
        "            \"t\": getattr(feedback, \"t\", None),\n",
        "        }\n",
        "\n",
        "        self.history.append({\n",
        "            \"ts\": time.time(),\n",
        "            \"score\": reason,\n",
        "            \"temperature\": temperature,\n",
        "            \"nudge\": nudge,\n",
        "            \"peer\": getattr(feedback, \"from_peer\", None),\n",
        "            \"t\": getattr(feedback, \"t\", None),\n",
        "        })\n",
        "\n",
        "        print(f\"[ADAPT] score={reason:.3f} -> temp={temperature:.2f} nudge={repr(nudge)} \"\n",
        "              f\"peer={getattr(feedback, 'from_peer', None)} t={getattr(feedback, 't', None)}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Agent\n",
        "# -------------------------------\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, tg: TheoryGenerator, simi: SimilarityEngine, ste: ScoringEngine,\n",
        "                 mmr: MemoryModelReviser, gt: str) -> None:\n",
        "        self.tg = tg\n",
        "        self.simi = simi\n",
        "        self.ste = ste\n",
        "        self.mmr = mmr\n",
        "        self.gt = gt\n",
        "        self.last_abstraction: Optional[Dict[str, Any]] = None\n",
        "\n",
        "    def revise(self, theory: str, feedback: Optional[Feedback]) -> Tuple[str, float, Dict[str, Any]]:\n",
        "        sim_res = self.simi.test(theory, self.gt)\n",
        "        score = self.ste.evaluate(theory, sim_res, self.gt)\n",
        "\n",
        "        # Lock-in: if the theory exactly matches GT, freeze exploration and keep theory unchanged\n",
        "        if theory.strip().lower() == self.gt.strip().lower():\n",
        "            self.last_abstraction = {\"temperature\": 0.01, \"nudge\": None, \"last_score\": score}\n",
        "            print(\"[LOCK-IN] Perfect match detected — freezing exploration.\")\n",
        "            return theory, score, {\"sim_res\": sim_res, \"locked_in\": True}\n",
        "\n",
        "        self.mmr.adapt(self, reason=score, feedback=feedback)\n",
        "        new_theory = self.tg.generate(self.last_abstraction or {})\n",
        "        return new_theory, score, {\"sim_res\": sim_res, \"locked_in\": False}\n",
        "\n",
        "# -------------------------------\n",
        "# Peer validation\n",
        "# -------------------------------\n",
        "\n",
        "def peer_validate(peer: str, theory: str, gt: str, t: int) -> Optional[Feedback]:\n",
        "    gt_tokens = gt.lower().split()\n",
        "    thy_tokens = set(theory.lower().split())\n",
        "    missing = [tok for tok in gt_tokens if tok not in thy_tokens]\n",
        "    if not missing:\n",
        "        return Feedback(peer, t, \"Looks aligned; keep consolidating.\", None, 0.8)\n",
        "\n",
        "    candidate = None\n",
        "    for tok in [\"quick\", \"brown\", \"fox\", \"jumps\", \"lazy\", \"dog\"]:\n",
        "        if tok in missing:\n",
        "            candidate = tok\n",
        "            break\n",
        "    candidate = candidate or random.choice(missing)\n",
        "    weight = max(0.4, 1.2 - 0.1 * t)\n",
        "    return Feedback(peer, t, f\"Missing token '{candidate}'. Consider incorporating it.\", candidate, weight)\n",
        "\n",
        "# -------------------------------\n",
        "# Main loop\n",
        "# -------------------------------\n",
        "\n",
        "def main():\n",
        "    random.seed(42)\n",
        "    X_true = \"the quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "    tg = TheoryGenerator()\n",
        "    simi = SimilarityEngine()\n",
        "    ste = ScoringEngine()\n",
        "    mmr = MemoryModelReviser()\n",
        "    agent = Agent(tg=tg, simi=simi, ste=ste, mmr=mmr, gt=X_true)\n",
        "\n",
        "    theory = \"brown fox jumps beyond policy\"\n",
        "    peers = [\"alpha\", \"beta\", \"gamma\"]\n",
        "\n",
        "    print(\"[INIT] gt:\", X_true)\n",
        "    print(\"[INIT] theory0:\", theory)\n",
        "    print(\"-\" * 72)\n",
        "\n",
        "    T = 5\n",
        "    for t in range(1, T + 1):\n",
        "        print(f\"\\n[STEP] t={t}\")\n",
        "        for peer in peers:\n",
        "            fb = peer_validate(peer, theory, X_true, t)\n",
        "            if not fb:\n",
        "                print(f\"[PEER] {peer}: no feedback\")\n",
        "                continue\n",
        "\n",
        "            print(f\"[PEER] {peer}: {fb.comment} (w={fb.weight:.2f}, t={fb.t}, hint={repr(fb.delta_hint)})\")\n",
        "            theory, score, audit = agent.revise(theory, fb)\n",
        "            sim = audit[\"sim_res\"]\n",
        "            print(f\"[SCORE] jaccard={sim['jaccard']:.3f} overlap={sim['overlap']}/{sim['union']} theory:\")\n",
        "            print(\"        \", theory)\n",
        "\n",
        "        # If we hit exact match, skip novelty to preserve lock-in\n",
        "        if theory.strip().lower() == X_true.strip().lower():\n",
        "            print(\"[LOCK-IN] Skipping novelty injection — theory matches GT.\")\n",
        "            continue\n",
        "\n",
        "        # Optional novelty/broadcast step between rounds\n",
        "        agent.last_abstraction = {\n",
        "            **(agent.last_abstraction or {}),\n",
        "            \"temperature\": min(1.0, (agent.last_abstraction or {}).get(\"temperature\", 0.2) + 0.05),\n",
        "        }\n",
        "        theory = agent.tg.generate(agent.last_abstraction or {})\n",
        "        print(f\"[NOVELTY] t={t} broadcast theory:\\n          \", theory)\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 72)\n",
        "    print(\"[DONE] Final theory:\", theory)\n",
        "    print(\"[HISTORY] adapt events:\", len(mmr.history))\n",
        "    if mmr.history:\n",
        "        last = mmr.history[-1]\n",
        "        print(f\"         last: score={last['score']:.3f} temp={last['temperature']:.2f} nudge={repr(last['nudge'])}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "w7_rHM-l6fur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "End-to-end MCK-style agent with:\n",
        "- requires_human_review decorator that forwards *args, **kwargs\n",
        "- Adaptive temperature based on score\n",
        "- Lock-in: once ground truth (GT) is matched (or fully covered at high score),\n",
        "  the agent snaps to canonical GT and freezes exploration (no novelty, no further changes)\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from functools import wraps\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "import random\n",
        "import time\n",
        "\n",
        "# -------------------------------\n",
        "# Decorators\n",
        "# -------------------------------\n",
        "\n",
        "def requires_human_review(if_score_below: float):\n",
        "    \"\"\"Decorator that prints a review notice for low scores, forwarding all args/kwargs.\"\"\"\n",
        "    def deco(fn):\n",
        "        @wraps(fn)\n",
        "        def wrapped(self, kernel, reason, *args, **kwargs):\n",
        "            if reason < if_score_below:\n",
        "                print(f\"[HUMAN-REVIEW] score={reason:.3f} < threshold={if_score_below:.3f} — flagging before adapt()\")\n",
        "            return fn(self, kernel, reason, *args, **kwargs)\n",
        "        return wrapped\n",
        "    return deco\n",
        "\n",
        "# -------------------------------\n",
        "# Data structures\n",
        "# -------------------------------\n",
        "\n",
        "@dataclass\n",
        "class Feedback:\n",
        "    from_peer: str\n",
        "    t: int\n",
        "    comment: str\n",
        "    delta_hint: Optional[str] = None\n",
        "    weight: float = 1.0\n",
        "\n",
        "# -------------------------------\n",
        "# Engines and components\n",
        "# -------------------------------\n",
        "\n",
        "class SimilarityEngine:\n",
        "    \"\"\"\n",
        "    Set-based Jaccard similarity:\n",
        "      - Tokens are whitespace-lowered unique sets (so duplicate 'the' collapses to one)\n",
        "      - overlap = |T ∩ G|\n",
        "      - union   = |T ∪ G|\n",
        "      - jaccard = overlap / union\n",
        "    \"\"\"\n",
        "    def test(self, theory: str, gt: str) -> Dict[str, Any]:\n",
        "        tset = set(theory.lower().split())\n",
        "        gset = set(gt.lower().split())\n",
        "        inter = len(tset & gset)\n",
        "        union = max(1, len(tset | gset))\n",
        "        return {\n",
        "            \"tokens_theory\": len(tset),\n",
        "            \"tokens_gt\": len(gset),\n",
        "            \"jaccard\": inter / union,\n",
        "            \"overlap\": inter,\n",
        "            \"union\": union,\n",
        "        }\n",
        "\n",
        "class ScoringEngine:\n",
        "    def evaluate(self, theory: str, sim_res: Dict[str, Any], gt: str) -> float:\n",
        "        return float(sim_res.get(\"jaccard\", 0.0))\n",
        "\n",
        "class TheoryGenerator:\n",
        "    \"\"\"\n",
        "    Token-level generator that interleaves a fixed 'core' with sampled vocabulary.\n",
        "    To preserve the chance of exact-GT, we DO NOT deduplicate tokens; we keep\n",
        "    both 'the' occurrences from core.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocabulary: Optional[List[str]] = None):\n",
        "        self.vocab = vocabulary or [\n",
        "            \"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"lazy\", \"dog\",\n",
        "            \"smart\", \"agile\", \"beyond\", \"robust\", \"audit\", \"traceable\", \"reliable\",\n",
        "            \"policy\", \"signal\", \"contract\", \"governed\", \"reviewed\", \"clear\"\n",
        "        ]\n",
        "\n",
        "    def generate(self, abstraction: Dict[str, Any]) -> str:\n",
        "        # Snap-to-GT if requested by upstream logic\n",
        "        force_gt = abstraction.get(\"force_gt\")\n",
        "        if isinstance(force_gt, str) and force_gt:\n",
        "            return force_gt\n",
        "\n",
        "        temperature = float(abstraction.get(\"temperature\", 0.2))\n",
        "        nudge = abstraction.get(\"nudge\")\n",
        "\n",
        "        k = min(9, max(3, int(3 + temperature * 6)))\n",
        "        tokens = random.sample(self.vocab, k=k)\n",
        "        if isinstance(nudge, str) and nudge:\n",
        "            # Bias by ensuring the nudge is included at the front of the sampled tokens\n",
        "            tokens = [nudge] + [tok for tok in tokens if tok != nudge]\n",
        "\n",
        "        # Two 'the' occurrences are intentionally kept to allow exact GT\n",
        "        core = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
        "\n",
        "        # Interleave: after every second core token, insert one sampled token if available\n",
        "        mix: List[str] = []\n",
        "        token_idx = 0\n",
        "        for i, tok in enumerate(core):\n",
        "            mix.append(tok)\n",
        "            if i % 2 == 1 and token_idx < len(tokens):\n",
        "                mix.append(tokens[token_idx])\n",
        "                token_idx += 1\n",
        "\n",
        "        return \" \".join(mix)\n",
        "\n",
        "class MemoryModelReviser:\n",
        "    \"\"\"\n",
        "    Translates scores + feedback into generator abstraction changes.\n",
        "    Logs every adaptation and lock-in for auditability.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.history: List[Dict[str, Any]] = []\n",
        "\n",
        "    @requires_human_review(if_score_below=0.20)\n",
        "    def adapt(self, kernel: \"Agent\", reason: float, feedback: Optional[Feedback] = None) -> None:\n",
        "        temperature = max(0.01, min(1.0, 1.0 - reason))\n",
        "        nudge = feedback.delta_hint if feedback and feedback.delta_hint else None\n",
        "\n",
        "        kernel.last_abstraction = {\n",
        "            \"temperature\": temperature,\n",
        "            \"nudge\": nudge,\n",
        "            \"last_score\": reason,\n",
        "            \"last_feedback_peer\": getattr(feedback, \"from_peer\", None),\n",
        "            \"t\": getattr(feedback, \"t\", None),\n",
        "        }\n",
        "\n",
        "        self.history.append({\n",
        "            \"event\": \"adapt\",\n",
        "            \"ts\": time.time(),\n",
        "            \"score\": reason,\n",
        "            \"temperature\": temperature,\n",
        "            \"nudge\": nudge,\n",
        "            \"peer\": getattr(feedback, \"from_peer\", None),\n",
        "            \"t\": getattr(feedback, \"t\", None),\n",
        "        })\n",
        "\n",
        "        print(f\"[ADAPT] score={reason:.3f} -> temp={temperature:.2f} nudge={repr(nudge)} \"\n",
        "              f\"peer={getattr(feedback, 'from_peer', None)} t={getattr(feedback, 't', None)}\")\n",
        "\n",
        "    def record_lock_in(self, theory: str, gt: str) -> None:\n",
        "        self.history.append({\n",
        "            \"event\": \"lock_in\",\n",
        "            \"ts\": time.time(),\n",
        "            \"score\": 1.0 if theory.strip().lower() == gt.strip().lower() else None,\n",
        "            \"note\": \"Snapped to canonical GT and froze exploration.\"\n",
        "        })\n",
        "\n",
        "# -------------------------------\n",
        "# Agent\n",
        "# -------------------------------\n",
        "\n",
        "class Agent:\n",
        "    \"\"\"\n",
        "    Agent orchestrating:\n",
        "      - similarity → score\n",
        "      - adapt with feedback\n",
        "      - generate new theory\n",
        "      - lock-in once GT is achieved (exact or high-confidence full token coverage)\n",
        "    \"\"\"\n",
        "    def __init__(self, tg: TheoryGenerator, simi: SimilarityEngine, ste: ScoringEngine,\n",
        "                 mmr: MemoryModelReviser, gt: str) -> None:\n",
        "        self.tg = tg\n",
        "        self.simi = simi\n",
        "        self.ste = ste\n",
        "        self.mmr = mmr\n",
        "        self.gt = gt\n",
        "        self.last_abstraction: Optional[Dict[str, Any]] = None\n",
        "        self.locked: bool = False\n",
        "\n",
        "    def _snap_to_gt_and_lock(self) -> None:\n",
        "        self.locked = True\n",
        "        self.last_abstraction = {\"temperature\": 0.01, \"nudge\": None, \"force_gt\": self.gt, \"last_score\": 1.0}\n",
        "        self.mmr.record_lock_in(self.gt, self.gt)\n",
        "        print(\"[LOCK-IN] Snapping to canonical GT and freezing exploration.\")\n",
        "\n",
        "    def revise(self, theory: str, feedback: Optional[Feedback]) -> Tuple[str, float, Dict[str, Any]]:\n",
        "        # If locked, keep returning the canonical GT without any further changes\n",
        "        if self.locked:\n",
        "            sim_res = self.simi.test(theory, self.gt)\n",
        "            return self.gt, 1.0 if theory.strip().lower() == self.gt.strip().lower() else self.ste.evaluate(theory, sim_res, self.gt), {\n",
        "                \"sim_res\": sim_res,\n",
        "                \"locked_in\": True\n",
        "            }\n",
        "\n",
        "        sim_res = self.simi.test(theory, self.gt)\n",
        "        score = self.ste.evaluate(theory, sim_res, self.gt)\n",
        "\n",
        "        # Exact string match → lock immediately\n",
        "        if theory.strip().lower() == self.gt.strip().lower():\n",
        "            self._snap_to_gt_and_lock()\n",
        "            return self.gt, 1.0, {\"sim_res\": sim_res, \"locked_in\": True}\n",
        "\n",
        "        # High-confidence full token coverage (all unique GT tokens present) → snap to GT and lock\n",
        "        full_coverage = (sim_res[\"overlap\"] == sim_res[\"tokens_gt\"])\n",
        "        if full_coverage and score >= 0.95 and (not feedback or not feedback.delta_hint):\n",
        "            self._snap_to_gt_and_lock()\n",
        "            return self.gt, 1.0, {\"sim_res\": sim_res, \"locked_in\": True}\n",
        "\n",
        "        # Otherwise, adapt and generate next theory\n",
        "        self.mmr.adapt(self, reason=score, feedback=feedback)\n",
        "        new_theory = self.tg.generate(self.last_abstraction or {})\n",
        "\n",
        "        # If generation naturally hits exact GT, lock immediately\n",
        "        if new_theory.strip().lower() == self.gt.strip().lower():\n",
        "            self._snap_to_gt_and_lock()\n",
        "            return self.gt, 1.0, {\"sim_res\": sim_res, \"locked_in\": True}\n",
        "\n",
        "        return new_theory, score, {\"sim_res\": sim_res, \"locked_in\": False}\n",
        "\n",
        "# -------------------------------\n",
        "# Peer validation\n",
        "# -------------------------------\n",
        "\n",
        "def peer_validate(peer: str, theory: str, gt: str, t: int) -> Optional[Feedback]:\n",
        "    gt_tokens = gt.lower().split()\n",
        "    thy_tokens = set(theory.lower().split())\n",
        "    missing = [tok for tok in gt_tokens if tok not in thy_tokens]\n",
        "    if not missing:\n",
        "        return Feedback(peer, t, \"Looks aligned; keep consolidating.\", None, 0.8)\n",
        "\n",
        "    candidate = None\n",
        "    for tok in [\"quick\", \"brown\", \"fox\", \"jumps\", \"lazy\", \"dog\"]:\n",
        "        if tok in missing:\n",
        "            candidate = tok\n",
        "            break\n",
        "    candidate = candidate or random.choice(missing)\n",
        "    weight = max(0.4, 1.2 - 0.1 * t)\n",
        "    return Feedback(peer, t, f\"Missing token '{candidate}'. Consider incorporating it.\", candidate, weight)\n",
        "\n",
        "# -------------------------------\n",
        "# Main loop\n",
        "# -------------------------------\n",
        "\n",
        "def main():\n",
        "    random.seed(42)\n",
        "\n",
        "    X_true = \"the quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "    tg = TheoryGenerator()\n",
        "    simi = SimilarityEngine()\n",
        "    ste = ScoringEngine()\n",
        "    mmr = MemoryModelReviser()\n",
        "    agent = Agent(tg=tg, simi=simi, ste=ste, mmr=mmr, gt=X_true)\n",
        "\n",
        "    theory = \"brown fox jumps beyond policy\"\n",
        "    peers = [\"alpha\", \"beta\", \"gamma\"]\n",
        "\n",
        "    print(\"[INIT] gt:\", X_true)\n",
        "    print(\"[INIT] theory0:\", theory)\n",
        "    print(\"-\" * 72)\n",
        "\n",
        "    T = 5\n",
        "    for t in range(1, T + 1):\n",
        "        print(f\"\\n[STEP] t={t}\")\n",
        "        for peer in peers:\n",
        "            fb = peer_validate(peer, theory, X_true, t)\n",
        "            if not fb:\n",
        "                print(f\"[PEER] {peer}: no feedback\")\n",
        "                continue\n",
        "\n",
        "            print(f\"[PEER] {peer}: {fb.comment} (w={fb.weight:.2f}, t={fb.t}, hint={repr(fb.delta_hint)})\")\n",
        "            theory, score, audit = agent.revise(theory, fb)\n",
        "            sim = audit[\"sim_res\"]\n",
        "            print(f\"[SCORE] jaccard={sim['jaccard']:.3f} overlap={sim['overlap']}/{sim['union']} theory:\")\n",
        "            print(\"        \", theory)\n",
        "\n",
        "        # Skip novelty if locked to preserve the exact GT\n",
        "        if agent.locked:\n",
        "            print(\"[LOCK-IN] Skipping novelty injection — theory matches GT.\")\n",
        "            continue\n",
        "\n",
        "        # Optional novelty/broadcast step between rounds\n",
        "        agent.last_abstraction = {\n",
        "            **(agent.last_abstraction or {}),\n",
        "            \"temperature\": min(1.0, (agent.last_abstraction or {}).get(\"temperature\", 0.2) + 0.05),\n",
        "        }\n",
        "        theory = agent.tg.generate(agent.last_abstraction or {})\n",
        "        print(f\"[NOVELTY] t={t} broadcast theory:\\n          \", theory)\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 72)\n",
        "    print(\"[DONE] Final theory:\", theory)\n",
        "    print(\"[HISTORY] adapt events:\", len([h for h in mmr.history if h.get(\"event\") == \"adapt\"]))\n",
        "    print(\"[HISTORY] lock-in events:\", len([h for h in mmr.history if h.get(\"event\") == \"lock_in\"]))\n",
        "    if mmr.history:\n",
        "        last = mmr.history[-1]\n",
        "        if last.get(\"event\") == \"adapt\":\n",
        "            print(f\"         last adapt: score={last['score']:.3f} temp={last['temperature']:.2f} nudge={repr(last['nudge'])}\")\n",
        "        else:\n",
        "            print(\"         last event:\", last.get(\"event\"))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "iQ5rcw_m8urQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
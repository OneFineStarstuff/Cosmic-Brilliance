{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/TextBlob_libguide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h1>About TextBlob</h1>\n",
        "</div>\n",
        "\n",
        "TextBlob is a free, open-source library in Python for processing textual data. It is a powerful package that reduces the complexity of the contextual data and derive in-depth information from the text. Like spaCy, its features and capabilities give insights into a text’s grammatical structure that can be particularly helpful in the following fields.\n",
        "\n",
        "TextBlob is particularly useful for the following tasks:\n",
        "\n",
        "- **Phrase extraction**: TextBlob helps explore text’s grammatical structure through linguistic annotations and extraction feature\n",
        "- **Part-of-speech tagging**: TextBlob analyzes the grammatical role each word plays in a sentence\n",
        "- **Sentiment analysis**: TextBlob feature allows us to determine whether the input textual data has a positive, negative, or neutral tone\n",
        "- **Tokenization:** TextBlob can break the input text into linguistically meaningful or basic units for future analyses.\n",
        "- **Word and phrase frequencies**: TextBlob can give insights into words patterns in the text\n",
        "- **Lemmatization**: TextBlob can reduce inflected forms of a word into root word called a lemma\n",
        "- **Spelling correction**: TextBlob can help correct spelling in the input text document\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "# **Using TextBlob**\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Installation**"
      ],
      "metadata": {
        "id": "Ans8WJUUj8qI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TextBlob and the necessary NLTK corpora can be installed using the python package index and setup tools.\n",
        "\n",
        "Use the following command to install spacy using pip install on your machine:\n"
      ],
      "metadata": {
        "id": "JEq-dwpxj_aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Mac Terminal]\n",
        "\n",
        "# pip3 install -U textblob\n",
        "# pip3 python -m textblob.download_corpora\n",
        "\n",
        "# [Jupyter Notebook]\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install textblob\n",
        "!{sys.executable} -m textblob.download_corpora\n",
        "\n",
        "# [Conda install]\n",
        "\n",
        "# conda install -c conda-forge textblob\n",
        "# python -m textblob.download_corpora"
      ],
      "metadata": {
        "id": "s8aj7OGAkCcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you only intend to use TextBlob’s default models (no model overrides), you can pass the lite argument. This downloads only those corpora needed for basic functionality.\n"
      ],
      "metadata": {
        "id": "YqS1nf1JMdQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Mac Terminal]\n",
        "\n",
        "# python -m textblob.download_corpora lite\n",
        "\n",
        "# [Jupyter Notebook]\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m textblob.download_corpora lite\n",
        "\n",
        "# [Conda install]\n",
        "\n",
        "# python -m textblob.download_corpora lite"
      ],
      "metadata": {
        "id": "YL6ncGgHMfSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read Strings**\n",
        "\n",
        "For a given input string, you can use TextBlob to create a processed object for accessing linguistic annotations:"
      ],
      "metadata": {
        "id": "taT51lE9copz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gE-Ez1qtyIA"
      },
      "outputs": [],
      "source": [
        "text = ('For a given input string, you can use TextBlob to create a processed object for accessing linguistic annotations.')\n",
        "text_doc = TextBlob(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input text string is then converted to an object that TextBlob can understand. This method can be used to convert any text into a processed object for future analysis."
      ],
      "metadata": {
        "id": "HMKk9ePLcsOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read Text File**\n",
        "\n",
        "You can also convert a .txt file into a processed object. Notice that the .txt file needs to be in the current working directory, or you will have to specify its full path. A quick reminder that you can get the current working directory with os.getcwd() and change it with os.chdir() after importing os.\n"
      ],
      "metadata": {
        "id": "iFPkM3QLc9qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Change working directory on your own machine as needed with os.chdir('Path to directory')\n",
        "                              # Tutorials are also available\n",
        "\n",
        "file = 'text.txt'\n",
        "file_text = open(file).read()\n",
        "file_doc = TextBlob(file_text)"
      ],
      "metadata": {
        "id": "nh9VDOhCdFaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a573a23-d12b-4a40-8538-ec47c96639c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may assume that variable name ending with the suffix _doc are TextBlob‘s language model objects."
      ],
      "metadata": {
        "id": "mf7CL_JZgOcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "# **Features**\n",
        "</div>"
      ],
      "metadata": {
        "id": "zjlHdA7LgUcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Noun Phrase Extraction**\n",
        "\n",
        "Noun Phrase Extraction extracts the nouns in a given text. You can use the extracted nouns to perform additional analysis.\n",
        "\n",
        "In TextBlob, noun phrases are accessed through the noun_phrases property.\n"
      ],
      "metadata": {
        "id": "WmQzEdtxgPc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Create a TextBlob object\n",
        "output = TextBlob(\"Apple's name was inspired by Steve Jobs' visit. His visit was to an apple farm while on a fruitarian diet.\")\n",
        "\n",
        "# Extract Nouns phrases from object\n",
        "output.noun_phrases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHCMD5rMgdz1",
        "outputId": "b9f8cf48-7d6a-4c90-b051-b79fd8c91f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['apple', \"'s name\", 'steve jobs', 'apple farm', 'fruitarian diet'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenization**\n",
        "\n",
        "Tokenization refers to a process of segmenting input text into words, punctuation, etc. It allows you to identify the basic units in your text that are called tokens. You can use the following code to achieve this purpose:\n"
      ],
      "metadata": {
        "id": "dE5Nakp7gy0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Create a TextBlob object\n",
        "output = TextBlob(\"Apple's name was inspired by Steve Jobs' visit. His visit was to an apple farm while on a fruitarian diet.\")\n",
        "\n",
        "# Extract words from object\n",
        "output.words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1PnAw9fhG3Y",
        "outputId": "1f74e800-58fd-4e9b-8543-31503d86149b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['Apple', \"'s\", 'name', 'was', 'inspired', 'by', 'Steve', 'Jobs', 'visit', 'His', 'visit', 'was', 'to', 'an', 'apple', 'farm', 'while', 'on', 'a', 'fruitarian', 'diet'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TextBlob can also extract sentences in the input text document:\n"
      ],
      "metadata": {
        "id": "ZAtBQZh6hPHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract sentences from object\n",
        "output.sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miudC8brhPg0",
        "outputId": "0de1466c-fc43-44d5-9f7a-0c0ea4ad8b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence(\"Apple's name was inspired by his visit.\"),\n",
              " Sentence(\"His visit was to an apple farm while on a fruitarian diet.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence objects have the same properties and methods as TextBlobs. For example: you can perform simple sentiment analysis on the sentences:\n"
      ],
      "metadata": {
        "id": "DWfnlwWHhW_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a simple sentiment analysis\n",
        "for sentence in output.sentences:\n",
        "  print(sentence.sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFOnWXKPmK5Q",
        "outputId": "c5fd83d9-9d13-4440-cd13-b2d3d3b58da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment Analysis**"
      ],
      "metadata": {
        "id": "QzmpmfkCyyOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TextBlob feature allows us to determine whether the input textual data has a positive, negative, or neutral tone.\n",
        "\n",
        "The sentiment function in TextBlob returns a sentiment tuple of the form (polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
      ],
      "metadata": {
        "id": "G16-HAYuy0ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Create a TextBlob object\n",
        "output = TextBlob(\"Apple's name was inspired by Steve Jobs' visit. His visit was to an apple farm while on a fruitarian diet.\")\n",
        "\n",
        "# Perform sentiment analysis\n",
        "output.sentiment\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o77f_f8Oy00W",
        "outputId": "3eecd158-c3c9-4c7b-8dd3-8a04c9feac99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.0, subjectivity=0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Word Frequency**\n",
        "\n",
        "Word frequency is an analysis that gives you insights into word patterns, such as common words or unique words in the text:\n"
      ],
      "metadata": {
        "id": "x2cqTCb0hvsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Create a TextBlob object\n",
        "output = TextBlob(\"Apple's name was inspired by Steve Jobs' visit. His visit was to an apple farm while on a fruitarian diet.\")\n",
        "\n",
        "# Word count for a specific string in the TextBlob object\n",
        "output.word_counts['his']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v_Y-Hnch3je",
        "outputId": "2c5fbce4-de80-493c-e529-d84f0086c02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can specify whether or not the search should be case-sensitive (the default is set as False)."
      ],
      "metadata": {
        "id": "JwTTbWm4w8ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Word count for specific string in the TextBlob object, case sensitive\n",
        "output.words.count('his', case_sensitive=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW4vaIbHw-mG",
        "outputId": "82d37e7c-f8ee-405f-fc83-a23bf8a7446c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part-Of-Speech (POS) Tagging**\n",
        "\n",
        "Part of speech (POS) analyzes the grammatical role each word plays in a sentence. In other words, it determines to which category each word (Noun, Pronoun, Adjective, Verb, Adverb, Preposition, Conjunction, and interjection) belongs. POS tags are useful when you want to assign a syntactic category to each word of the text for future analysis. Part-of-speech tags can be accessed through the tags property in TextBlob\n"
      ],
      "metadata": {
        "id": "uYBh0E-Uh74U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Create an nlp object\n",
        "output = TextBlob(\"Apple's name was inspired by Steve Jobs' visit to an apple farm while on a fruitarian diet.\")\n",
        "\n",
        "# Print out POS tagging\n",
        "output.tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aN5_arGh_Ul",
        "outputId": "5106570a-6ce5-4fa0-8fae-78a6e0dc8afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Apple', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('name', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('inspired', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('Steve', 'NNP'),\n",
              " ('Jobs', 'NNP'),\n",
              " (\"'\", 'POS'),\n",
              " ('visit', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('an', 'DT'),\n",
              " ('apple', 'NN'),\n",
              " ('farm', 'NN'),\n",
              " ('while', 'IN'),\n",
              " ('on', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('fruitarian', 'JJ'),\n",
              " ('diet', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Word Inflection**\n",
        "\n",
        "Once we convert a TextBlob object into TextBlob.words or TextBlob.words, they are converted to a **Word** object, and we can perform useful methods to those objects, such as word inflection. That is, to change in the form of a word.\n"
      ],
      "metadata": {
        "id": "fhrjSF7xpxdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Create a TextBlob object\n",
        "output = TextBlob(\"Apple's name was inspired by his visit to an apple farm while on a fruitarian diet.\")\n",
        "\n",
        "# Break the TextBlob object into units of word\n",
        "print(output.words)\n",
        "\n",
        "# Convert the 9th word to plural form\n",
        "output.words[10].pluralize()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Fi12C7yMqCwb",
        "outputId": "c8043883-84c0-4571-b3e5-916a1cf07763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apple', \"'s\", 'name', 'was', 'inspired', 'by', 'his', 'visit', 'to', 'an', 'apple', 'farm', 'while', 'on', 'a', 'fruitarian', 'diet']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'apples'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In fact, TextBlobs are like Python strings. You can use Python’s substring syntax."
      ],
      "metadata": {
        "id": "rxTK0z3mv3FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDQ0JCTZv8we",
        "outputId": "3db20768-0961-468b-d3c3-863856025dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"Apple\")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use common string methods to change text to upper or lower cases:"
      ],
      "metadata": {
        "id": "Mt8WYq8vwFeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output.upper()\n",
        "output.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHlXKbsewJ2h",
        "outputId": "012dce4b-9dcf-4807-fe72-6f73bf54ec41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"apple's name was inspired by his visit. his visit was to an apple farm while on a fruitarian diet.\")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can make comparisons between TextBlobs and strings."
      ],
      "metadata": {
        "id": "A6yo7zwRwQGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output[0:5]>output[10:12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-8mU-TgwSHp",
        "outputId": "36716528-2eb5-4f45-a1d7-e4f889bdaa73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **N-grams**\n",
        "\n",
        "The TextBlob.ngrams() function returns a list of tuples of n successive words. The tuple can later be used to predict the most probable word that might follow this sequence, which can be particularly useful in speech recognition, machine translation, and predictive text input."
      ],
      "metadata": {
        "id": "j7VNsobgl7pU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Create a TextBlob object\n",
        "output = TextBlob(\"Apple's name was inspired by Steve Jobs' visit. His visit was to an apple farm while on a fruitarian diet.\")\n",
        "\n",
        "# Returns a list of tuples of 3 successive words from object\n",
        "output.ngrams(n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6vTqCxPmCtc",
        "outputId": "79f82eb7-1918-4924-8fee-7d87af0abc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Apple', \"'s\", 'name']),\n",
              " WordList([\"'s\", 'name', 'was']),\n",
              " WordList(['name', 'was', 'inspired']),\n",
              " WordList(['was', 'inspired', 'by']),\n",
              " WordList(['inspired', 'by', 'Steve']),\n",
              " WordList(['by', 'Steve', 'Jobs']),\n",
              " WordList(['Steve', 'Jobs', 'visit']),\n",
              " WordList(['Jobs', 'visit', 'His']),\n",
              " WordList(['visit', 'His', 'visit']),\n",
              " WordList(['His', 'visit', 'was']),\n",
              " WordList(['visit', 'was', 'to']),\n",
              " WordList(['was', 'to', 'an']),\n",
              " WordList(['to', 'an', 'apple']),\n",
              " WordList(['an', 'apple', 'farm']),\n",
              " WordList(['apple', 'farm', 'while']),\n",
              " WordList(['farm', 'while', 'on']),\n",
              " WordList(['while', 'on', 'a']),\n",
              " WordList(['on', 'a', 'fruitarian']),\n",
              " WordList(['a', 'fruitarian', 'diet'])]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Spelling Correction**\n",
        "\n",
        "TextBlob's correct() function can be applied to perform spelling correction tasks. That is, to correct spellings or perform spell checks. Notice that we intentionally spelled Apple and its name incorrectly in the demonstration."
      ],
      "metadata": {
        "id": "2FpdTT_1xckG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Create a TextBlob object\n",
        "output = TextBlob(\"Appple's namee was inspired by Steve Jobs' visit. His visit was to an apple farm while on a fruitarian diet.\")\n",
        "\n",
        "# Correct spelling\n",
        "output.correct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHe2bi2wxvGD",
        "outputId": "be6ade44-7118-4568-f1e1-b32c8ea1bd46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"Apple's name was inspired by Steve Sobs' visit. His visit was to an apple farm while on a fruitarian diet.\")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Word.spellcheck() function allows us to examine a list of (word, confidence) tuples with spelling suggestions. Notice that we intentionally spelled \"misspellled\" wrong, and the confidence score shows that we are 100% sure that \"misspellled\" is misspelled.  "
      ],
      "metadata": {
        "id": "M69-Xv_6yDu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "\n",
        "# Create word object\n",
        "word = Word('misspellled')\n",
        "\n",
        "# Perform spellcheck\n",
        "word.spellcheck()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ78c-wwyNky",
        "outputId": "0e4af9a4-122d-40f1-95b2-ad7cdf39f683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('misspelled', 1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Summary of the Text**\n",
        "\n",
        "A simple strategy, as provided by Analytics Vidhya, that can be adopted to summarize the given task was to extract a list of nouns from the text to give a general idea to the reader about the things the text is related to.\n",
        "\n"
      ],
      "metadata": {
        "id": "DvA6BGVX0k5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import random # Random is a built-in Python package\n",
        "\n",
        "\n",
        "\n",
        "# Create a TextBlob object\n",
        "output = TextBlob(\"An n-gram is a collection of n successive items in a text document that may include words, numbers, symbols, and punctuation. N-gram models are useful in many text analytics applications where sequences of words are relevant, such as in sentiment analysis, text classification, and text generation.\")\n",
        "\n",
        "\n",
        "\n",
        "# Create a list of extracted nouns\n",
        "nouns = list()\n",
        "for word, tag in output.tags:\n",
        "if tag == 'NN': # tag == 'NN' represents that the word is classified as a noun by TextBolb\n",
        "nouns.append(word)\n",
        "\n",
        "\n",
        "\n",
        "# We randomly extracted a list of 5 nouns from the text to give a general idea\n",
        "\n",
        "for item in random.sample(nouns, 5):\n",
        "word = Word(item)\n",
        "print (word.pluralize())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrq-wXLe1HGl",
        "outputId": "b5ca1cae-d6e3-49af-a81d-f597e8431228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents\n",
            "classifications\n",
            "analyses\n",
            "sentiments\n",
            "collections\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Language Detection and Translation**"
      ],
      "metadata": {
        "id": "-o_Eetml14Rq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we convert an input text to TexbBlob object, we can apply the detect_language() function to detect what language it is written in. This feature can be particularly helpful after you extracted text information from images, as we introduced in the importing file tutorial.\n",
        "\n",
        "Once we know what the language the text was written in and the language we would like to Translate to, we can use the following code to achieve this purpose:"
      ],
      "metadata": {
        "id": "X6R4uB__18Au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "# Create a TextBlob object\n",
        "output = TextBlob(\"An n-gram is a collection of n successive items in a text document that may include words, numbers, symbols, and punctuation. N-gram models are useful in many text analytics applications where sequences of words are relevant, such as in sentiment analysis, text classification, and text generation.\")\n",
        "\n",
        "# Detect language of the input text\n",
        "# output.detect_language()\n",
        "\n",
        "# Translate to Arabic\n",
        "output.translate(from_lang='en', to ='eo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MkPAIy813gW",
        "outputId": "327e45bf-9ca8-4359-bb00-d7743f7fdc1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"N-gramo estas kolekto de n pluaj eroj en teksta dokumento, kiu povas inkluzivi vortojn, nombrojn, simbolojn kaj interpunkcion. N-gramaj modeloj estas utilaj en multaj tekstaj analizaj aplikoj, kie sekvencoj de vortoj gravas, kiel en senta analizo, teksta klasifiko kaj generado de teksto.\")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also translate this piece of text into 100+ languages! All language codes are presented here:"
      ],
      "metadata": {
        "id": "ypFGZi8EoYja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install googletrans\n",
        "# from googletrans import LANGUAGES\n",
        "# Language_codes = dict(map(reversed, LANGUAGES.items()))\n",
        "Language_codes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ha9gVpmB5f",
        "outputId": "4b84b232-a744-4b9d-8f5e-47e8ad1eb34a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'afrikaans': 'af',\n",
              " 'albanian': 'sq',\n",
              " 'amharic': 'am',\n",
              " 'arabic': 'ar',\n",
              " 'armenian': 'hy',\n",
              " 'azerbaijani': 'az',\n",
              " 'basque': 'eu',\n",
              " 'belarusian': 'be',\n",
              " 'bengali': 'bn',\n",
              " 'bosnian': 'bs',\n",
              " 'bulgarian': 'bg',\n",
              " 'catalan': 'ca',\n",
              " 'cebuano': 'ceb',\n",
              " 'chichewa': 'ny',\n",
              " 'chinese (simplified)': 'zh-cn',\n",
              " 'chinese (traditional)': 'zh-tw',\n",
              " 'corsican': 'co',\n",
              " 'croatian': 'hr',\n",
              " 'czech': 'cs',\n",
              " 'danish': 'da',\n",
              " 'dutch': 'nl',\n",
              " 'english': 'en',\n",
              " 'esperanto': 'eo',\n",
              " 'estonian': 'et',\n",
              " 'filipino': 'tl',\n",
              " 'finnish': 'fi',\n",
              " 'french': 'fr',\n",
              " 'frisian': 'fy',\n",
              " 'galician': 'gl',\n",
              " 'georgian': 'ka',\n",
              " 'german': 'de',\n",
              " 'greek': 'el',\n",
              " 'gujarati': 'gu',\n",
              " 'haitian creole': 'ht',\n",
              " 'hausa': 'ha',\n",
              " 'hawaiian': 'haw',\n",
              " 'hebrew': 'he',\n",
              " 'hindi': 'hi',\n",
              " 'hmong': 'hmn',\n",
              " 'hungarian': 'hu',\n",
              " 'icelandic': 'is',\n",
              " 'igbo': 'ig',\n",
              " 'indonesian': 'id',\n",
              " 'irish': 'ga',\n",
              " 'italian': 'it',\n",
              " 'japanese': 'ja',\n",
              " 'javanese': 'jw',\n",
              " 'kannada': 'kn',\n",
              " 'kazakh': 'kk',\n",
              " 'khmer': 'km',\n",
              " 'korean': 'ko',\n",
              " 'kurdish (kurmanji)': 'ku',\n",
              " 'kyrgyz': 'ky',\n",
              " 'lao': 'lo',\n",
              " 'latin': 'la',\n",
              " 'latvian': 'lv',\n",
              " 'lithuanian': 'lt',\n",
              " 'luxembourgish': 'lb',\n",
              " 'macedonian': 'mk',\n",
              " 'malagasy': 'mg',\n",
              " 'malay': 'ms',\n",
              " 'malayalam': 'ml',\n",
              " 'maltese': 'mt',\n",
              " 'maori': 'mi',\n",
              " 'marathi': 'mr',\n",
              " 'mongolian': 'mn',\n",
              " 'myanmar (burmese)': 'my',\n",
              " 'nepali': 'ne',\n",
              " 'norwegian': 'no',\n",
              " 'odia': 'or',\n",
              " 'pashto': 'ps',\n",
              " 'persian': 'fa',\n",
              " 'polish': 'pl',\n",
              " 'portuguese': 'pt',\n",
              " 'punjabi': 'pa',\n",
              " 'romanian': 'ro',\n",
              " 'russian': 'ru',\n",
              " 'samoan': 'sm',\n",
              " 'scots gaelic': 'gd',\n",
              " 'serbian': 'sr',\n",
              " 'sesotho': 'st',\n",
              " 'shona': 'sn',\n",
              " 'sindhi': 'sd',\n",
              " 'sinhala': 'si',\n",
              " 'slovak': 'sk',\n",
              " 'slovenian': 'sl',\n",
              " 'somali': 'so',\n",
              " 'spanish': 'es',\n",
              " 'sundanese': 'su',\n",
              " 'swahili': 'sw',\n",
              " 'swedish': 'sv',\n",
              " 'tajik': 'tg',\n",
              " 'tamil': 'ta',\n",
              " 'telugu': 'te',\n",
              " 'thai': 'th',\n",
              " 'turkish': 'tr',\n",
              " 'ukrainian': 'uk',\n",
              " 'urdu': 'ur',\n",
              " 'uyghur': 'ug',\n",
              " 'uzbek': 'uz',\n",
              " 'vietnamese': 'vi',\n",
              " 'welsh': 'cy',\n",
              " 'xhosa': 'xh',\n",
              " 'yiddish': 'yi',\n",
              " 'yoruba': 'yo',\n",
              " 'zulu': 'zu'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "# **References (Additional Resources)**\n",
        "</div>\n",
        "\n",
        "[TextBlob](https://textblob.readthedocs.io/en/dev/classifiers.html)\n",
        "\n",
        "[Analytics Vidhya](https://www.analyticsvidhya.com/blog/2018/02/natural-language-processing-for-beginners-using-textblob/)\n",
        "\n"
      ],
      "metadata": {
        "id": "iGRBN617mMYS"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
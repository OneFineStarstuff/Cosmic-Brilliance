{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOJTjniebd0iLC/W8DVzZgJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/temporal_ai_pipeline_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUoDS85CFQNM"
      },
      "outputs": [],
      "source": [
        "# temporal_ai_pipeline.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation, PillowWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --------------------------\n",
        "# 1. Synthetic Dataset\n",
        "# --------------------------\n",
        "\n",
        "class TemporalLoopDataset(Dataset):\n",
        "    def __init__(self, N):\n",
        "        self.X = np.column_stack([\n",
        "            np.random.rand(N,1),                 # Energy E ∈ (0,1)\n",
        "            np.random.uniform(-1,1,(N,1)),       # Metric M1 ∈ (-1,1)\n",
        "            np.random.uniform(-1,1,(N,1)),       # Metric M2 ∈ (-1,1)\n",
        "            np.random.rand(N,1),                 # Quantum factor Q1 ∈ (0,1)\n",
        "            np.random.rand(N,1),                 # Quantum factor Q2 ∈ (0,1)\n",
        "        ]).astype(np.float32)\n",
        "\n",
        "        E, M1, M2, Q1, Q2 = self.X.T\n",
        "        P1 = np.sin(np.pi * E) * M1 + 0.5 * Q1\n",
        "        P2 = np.cos(np.pi * M2) * E + 0.3 * Q2\n",
        "        P3 = E + M1 * Q1 - 0.2 * M2 * Q2\n",
        "        self.Y = np.vstack([P1, P2, P3]).T.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 2. Physics Residual\n",
        "# --------------------------\n",
        "\n",
        "def physics_residual(pred):\n",
        "    p1, p2, p3 = pred[:,0], pred[:,1], pred[:,2]\n",
        "    return p1**2 + p2**2 - p3\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 3. Model with MC-Dropout\n",
        "# --------------------------\n",
        "\n",
        "class TemporalAI(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, p_dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p_dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p_dropout),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 4. Training Utilities\n",
        "# --------------------------\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, lambda_phy):\n",
        "    model.train()\n",
        "    mse_loss = nn.MSELoss()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = model(x)\n",
        "\n",
        "        loss_sup = mse_loss(pred, y)\n",
        "        loss_phy = torch.mean(physics_residual(pred)**2)\n",
        "        loss = loss_sup + lambda_phy * loss_phy\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "def eval_mc_dropout(model, x, T=100):\n",
        "    model.train()  # keep dropout active\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(x))\n",
        "    preds = torch.stack(preds, dim=0)\n",
        "    return preds.mean(dim=0), preds.std(dim=0)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 5. Main Execution\n",
        "# --------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    input_dim, hidden_dim, output_dim = 5, 32, 3\n",
        "    lr = 1e-3\n",
        "    batch_size = 128\n",
        "    epochs = 200\n",
        "    lambda_phy = 1.0\n",
        "    N_samples = 10000\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare dataset and model\n",
        "    dataset = TemporalLoopDataset(N_samples)\n",
        "    loader  = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    model   = TemporalAI(input_dim, hidden_dim, output_dim).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    history = {\"loss\": []}\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(1, epochs+1)):\n",
        "        loss = train_one_epoch(model, loader, optimizer, lambda_phy)\n",
        "        history[\"loss\"].append(loss)\n",
        "\n",
        "    # Save model\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "    torch.save(model.state_dict(), \"outputs/temporal_ai.pth\")\n",
        "\n",
        "    # --------------------------\n",
        "    # 6. Monte Carlo Dropout Grid\n",
        "    # --------------------------\n",
        "\n",
        "    model.eval()\n",
        "    E_vals = torch.linspace(0, 1, 50)\n",
        "    M1_vals = torch.linspace(-1, 1, 50)\n",
        "    grid = torch.cartesian_prod(\n",
        "        E_vals, M1_vals,\n",
        "        torch.tensor([0.0]),  # M2 fixed\n",
        "        torch.tensor([0.5]),  # Q1 fixed\n",
        "        torch.tensor([0.5])   # Q2 fixed\n",
        "    ).float().to(device)\n",
        "\n",
        "    mean_pred, std_pred = eval_mc_dropout(model, grid, T=100)\n",
        "\n",
        "    # --------------------------\n",
        "    # 7. Visualization & GIF\n",
        "    # --------------------------\n",
        "\n",
        "    fig, (ax_loss, ax_map) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    norm = plt.Normalize(vmin=mean_pred[:,0].min().item(),\n",
        "                        vmax=mean_pred[:,0].max().item())\n",
        "    cmap = plt.cm.viridis\n",
        "\n",
        "    def update(frame):\n",
        "        ax_loss.clear()\n",
        "        ax_map.clear()\n",
        "\n",
        "        # Plot loss curve\n",
        "        ax_loss.plot(history[\"loss\"][:frame], color=\"crimson\")\n",
        "        ax_loss.set_title(\"Training Loss\")\n",
        "        ax_loss.set_xlim(0, epochs)\n",
        "        ax_loss.set_ylim(0, max(history[\"loss\"]))\n",
        "\n",
        "        # Prepare data for scatter\n",
        "        x_np    = grid[:,0].cpu().numpy()\n",
        "        y_np    = grid[:,1].cpu().numpy()\n",
        "        mean_np = mean_pred[:,0].cpu().numpy()\n",
        "        std_np  = std_pred[:,0].cpu().numpy()\n",
        "        alpha   = std_np / std_np.max()\n",
        "\n",
        "        colors = cmap(norm(mean_np))\n",
        "        colors[:, 3] = alpha\n",
        "\n",
        "        sc = ax_map.scatter(x_np, y_np, color=colors, s=12)\n",
        "        ax_map.set_title(\"Predicted P1 (mean color + std→alpha)\")\n",
        "        ax_map.set_xlabel(\"E\")\n",
        "        ax_map.set_ylabel(\"M1\")\n",
        "\n",
        "        return sc,\n",
        "\n",
        "    anim = FuncAnimation(fig, update, frames=epochs, interval=50)\n",
        "    gif_path = \"outputs/temporal_training.gif\"\n",
        "    anim.save(gif_path, writer=PillowWriter(fps=20))\n",
        "    plt.close(fig)\n",
        "\n",
        "    print(f\"Training complete. GIF saved to {gif_path}\")"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNSF+2uzbG20szI21Lqr72t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_megastructure_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDS28Q37GOz2"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_megastructure_ai.py\n",
        "\n",
        "Physics-informed AI pipeline for MegastructureAI with NaN safety and uncertainty.\n",
        "\n",
        "1. Synthetic dataset: material strength, density, Young’s modulus, gravity, energy input, geometry\n",
        "2. Float32 normalization and dtype consistency\n",
        "3. MLP with LayerNorm, Dropout, ReLU (accepts int hidden_dims)\n",
        "4. Physics-informed residual with denominator clamps\n",
        "5. MC-Dropout for uncertainty quantification\n",
        "6. Training loop: AdamW, ReduceLROnPlateau, gradient clipping, NaN checks, early stopping\n",
        "7. Safe checkpoint load\n",
        "8. Visualizations: loss history, scatter, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Megastructure Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class MegastructureDataset(Dataset):\n",
        "    def __init__(self, n_samples=6000, seed=0):\n",
        "        np.random.seed(seed)\n",
        "        # Features:\n",
        "        # MS (material strength)    ∈ [1e2, 1e4]\n",
        "        # Den (density)             ∈ [1000, 8000]\n",
        "        # YM (Young’s modulus)      ∈ [1e9, 3e11]\n",
        "        # GP (gravity pull factor)  ∈ [0.01, 2.0]\n",
        "        # EI (energy input rate)    ∈ [1e5, 1e8]\n",
        "        # GC (geometry complexity)  ∈ [0.1, 1.0]\n",
        "        MS  = np.random.uniform(1e2,   1e4,    (n_samples,1))\n",
        "        Den = np.random.uniform(1e3,   8e3,    (n_samples,1))\n",
        "        YM  = np.random.uniform(1e9,   3e11,   (n_samples,1))\n",
        "        GP  = np.random.uniform(1e-2,  2.0,    (n_samples,1))\n",
        "        EI  = np.random.uniform(1e5,   1e8,    (n_samples,1))\n",
        "        GC  = np.random.uniform(0.1,   1.0,    (n_samples,1))\n",
        "\n",
        "        X_raw = np.hstack([MS, Den, YM, GP, EI, GC]).astype(np.float64)\n",
        "\n",
        "        # Physics targets:\n",
        "        # Structural Integrity (SI)      = YM * MS / (GP + eps)\n",
        "        # Gravitational Stability (GS)   = Den * MS / (YM + eps)\n",
        "        # Power Output (PO)             = EI * GC / (Den + eps)\n",
        "        eps = 1e-6\n",
        "        SI = YM  * MS  / (GP  + eps)\n",
        "        GS = Den * MS  / (YM  + eps)\n",
        "        PO = EI  * GC  / (Den + eps)\n",
        "\n",
        "        Y_raw = np.hstack([SI, GS, PO]).astype(np.float64)\n",
        "        Y_raw += 0.01 * Y_raw.std(axis=0) * np.random.randn(*Y_raw.shape)\n",
        "\n",
        "        # Compute stats\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0) + 1e-8\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0) + 1e-8\n",
        "\n",
        "        # Normalize to float32\n",
        "        self.X = ((X_raw - self.X_mean) / self.X_std).astype(np.float32)\n",
        "        self.Y = ((Y_raw - self.Y_mean) / self.Y_std).astype(np.float32)\n",
        "\n",
        "        print(f\"Dataset X range {self.X.min():.3e}–{self.X.max():.3e}\")\n",
        "        print(f\"Dataset Y range {self.Y.min():.3e}–{self.Y.max():.3e}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return torch.from_numpy(self.X[i]), torch.from_numpy(self.Y[i])\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model Definition (accepts int hidden_dims)\n",
        "# ------------------------------------------------------------------------------\n",
        "class MegastructureAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dims=(64,64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        # allow integer for hidden_dims\n",
        "        if isinstance(hidden_dims, int):\n",
        "            hidden_dims = (hidden_dims,)\n",
        "\n",
        "        layers, dim = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim = h\n",
        "        layers.append(nn.Linear(dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Loss with Clamps\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, X, stats):\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    MS, Den, YM, GP, EI, GC = X_den.t()\n",
        "    eps = 1e-4\n",
        "\n",
        "    SI_t = YM  * MS  / torch.clamp(GP  + eps, min=eps)\n",
        "    GS_t = Den * MS  / torch.clamp(YM  + eps, min=eps)\n",
        "    PO_t = EI  * GC  / torch.clamp(Den + eps, min=eps)\n",
        "\n",
        "    Yt = torch.stack([SI_t, GS_t, PO_t], dim=1)\n",
        "    Yt_norm = (Yt - stats['Y_mean']) / stats['Y_std']\n",
        "    return nn.MSELoss()(pred, Yt_norm)\n",
        "\n",
        "def total_loss(pred, true, X, stats, lam=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, X, stats)\n",
        "    return mse + lam * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout Uncertainty Estimation\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    arr = torch.stack(preds, 0)\n",
        "    return arr.mean(0), arr.std(0)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop (NaN safety, checkpoints, early stopping)\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-4, wd=1e-5, lam=1.0, epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5)\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train': [], 'val': []}\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, _, _ = total_loss(pred, yb, xb, stats, lam)\n",
        "            if torch.isnan(loss):\n",
        "                print(\"NaN! aborting.\")\n",
        "                return history\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * xb.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, lam)\n",
        "                val_loss += loss.item() * xb.size(0)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        history['train'].append(train_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        print(f\"Epoch {epoch:03d} ┃ Train {train_loss:.4e} ┃ Val {val_loss:.4e}\")\n",
        "\n",
        "        # checkpoint & early stop\n",
        "        if val_loss < best_val - 1e-8:\n",
        "            best_val, wait = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_megastruct.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    # load best\n",
        "    if os.path.exists(\"best_megastruct.pth\"):\n",
        "        model.load_state_dict(torch.load(\"best_megastruct.pth\", map_location=device))\n",
        "    else:\n",
        "        print(\"No checkpoint; using last model.\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_history(hist):\n",
        "    plt.plot(hist['train'], label='train')\n",
        "    plt.plot(hist['val'],   label='val')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_scatter(y_true, y_pred):\n",
        "    plt.scatter(y_true, y_pred, s=5)\n",
        "    m, M = y_true.min(), y_true.max()\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Pred\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_uncertainty(model, stats, device):\n",
        "    # vary Material Strength (idx=0) and Gravity Pull (idx=3)\n",
        "    MS = np.linspace(1e2, 1e4, 80)\n",
        "    GP = np.linspace(0.01, 2.0, 80)\n",
        "    MSm, GPm = np.meshgrid(MS, GP)\n",
        "    pts = MSm.size\n",
        "\n",
        "    grid = torch.zeros((pts, 6), device=device)\n",
        "    grid[:, 0] = torch.from_numpy(MSm.ravel()).to(device)\n",
        "    grid[:, 3] = torch.from_numpy(GPm.ravel()).to(device)\n",
        "    for i in (1, 2, 4, 5):\n",
        "        grid[:, i] = stats['X_mean'][i]\n",
        "\n",
        "    Xn = (grid - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout_predict(model, Xn, T=100)\n",
        "    U = std[:, 0].cpu().numpy().reshape(MSm.shape)\n",
        "\n",
        "    plt.pcolormesh(MSm, GPm, U, cmap='magma')\n",
        "    plt.colorbar(label=\"σ (uncertainty)\")\n",
        "    plt.xlabel(\"Material Strength\")\n",
        "    plt.ylabel(\"Gravity Pull Factor\")\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # prepare data\n",
        "    dataset = MegastructureDataset(n_samples=6000)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(dataset.X_mean, dtype=torch.float32, device=device),\n",
        "        'X_std' : torch.tensor(dataset.X_std,  dtype=torch.float32, device=device),\n",
        "        'Y_mean': torch.tensor(dataset.Y_mean, dtype=torch.float32, device=device),\n",
        "        'Y_std' : torch.tensor(dataset.Y_std,  dtype=torch.float32, device=device)\n",
        "    }\n",
        "\n",
        "    train_set, val_set = random_split(dataset, [len(dataset)-1200, 1200])\n",
        "    train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "    val_loader   = DataLoader(val_set,   batch_size=256, shuffle=False)\n",
        "\n",
        "    # build & train\n",
        "    model = MegastructureAI(input_dim=6, hidden_dims=32, output_dim=3).to(device)\n",
        "    history = train(model, train_loader, val_loader, stats, device)\n",
        "\n",
        "    # visualize\n",
        "    plot_history(history)\n",
        "\n",
        "    X_all = torch.from_numpy(dataset.X).to(device)\n",
        "    with torch.no_grad():\n",
        "        Y_pred = model(X_all).cpu().numpy()\n",
        "    for i in range(3):\n",
        "        plot_scatter(dataset.Y[:, i], Y_pred[:, i])\n",
        "\n",
        "    plot_uncertainty(model, stats, device)"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPq9mwSEMMFhmvrAhIm+o8D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/rge_end_to_end_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S31qn5QmRmnq"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# rge_end_to_end.py\n",
        "# A complete, ready-to-run pipeline: abstraction → theory construction → simulation → validation → ranking\n",
        "# Dependencies: numpy (stdlib otherwise)\n",
        "\n",
        "from __future__ import annotations\n",
        "import numpy as np\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Dict, Any, Optional, Tuple, Iterable, Callable\n",
        "import time, json, os, re, math\n",
        "from pathlib import Path\n",
        "\n",
        "# ========== Utilities & types ==========\n",
        "\n",
        "@dataclass\n",
        "class ScoreReport:\n",
        "    total: float\n",
        "    passed: bool\n",
        "    components: Dict[str, float]\n",
        "    details: Dict[str, Any]\n",
        "    threshold: float\n",
        "    version: str = \"meta-validator/1.0.0\"\n",
        "    timestamp: float = None\n",
        "\n",
        "    def to_json(self) -> str:\n",
        "        d = asdict(self)\n",
        "        if self.timestamp is None:\n",
        "            d[\"timestamp\"] = time.time()\n",
        "        return json.dumps(d, indent=2, sort_keys=True)\n",
        "\n",
        "class SimOutput:\n",
        "    def __init__(self, t: np.ndarray, y: np.ndarray, states: List[str]):\n",
        "        self.t = t               # shape (T,)\n",
        "        self.y = y               # shape (S, T)\n",
        "        self.states = states     # e.g. ['x','y']\n",
        "\n",
        "# ========== MetaValidator ==========\n",
        "\n",
        "Token = str\n",
        "\n",
        "def _to_tokens(eq: Any) -> List[Token]:\n",
        "    s = str(eq)\n",
        "    return [tok for tok in re.findall(r\"[A-Za-z_]+|\\d+\\.\\d+|\\d+|[+\\-*/^=()=]\", s) if tok.strip()]\n",
        "\n",
        "def _description_length(equations: Iterable[Any]) -> int:\n",
        "    weights = {\"+\":1, \"-\":1, \"*\":1, \"/\":2, \"^\":2, \"=\":0, \"sin\":3, \"cos\":3, \"exp\":3, \"log\":3}\n",
        "    total = 0\n",
        "    for eq in equations:\n",
        "        for tok in _to_tokens(eq):\n",
        "            total += weights.get(tok, 1)\n",
        "    return total\n",
        "\n",
        "def _simplicity_score(desc_len: int, lam: float = 0.03) -> float:\n",
        "    return float(np.exp(-lam * max(0, desc_len)))\n",
        "\n",
        "def _masked_var(y_true: np.ndarray) -> float:\n",
        "    mask = ~np.isnan(y_true)\n",
        "    if not np.any(mask):\n",
        "        return 0.0\n",
        "    centered = y_true[mask] - np.nanmean(y_true)\n",
        "    return float(np.mean(centered**2))\n",
        "\n",
        "def _accuracy_with_gt(y_pred: np.ndarray, y_true: np.ndarray) -> Tuple[float, Dict[str, Any]]:\n",
        "    if y_pred.shape != y_true.shape:\n",
        "        raise ValueError(f\"Shape mismatch: pred {y_pred.shape} vs gt {y_true.shape}\")\n",
        "    mask = ~np.isnan(y_true)\n",
        "    if not np.any(mask):\n",
        "        return 0.0, {\"mse\": None, \"var\": None, \"masked_fraction\": 0.0}\n",
        "    diff = (y_pred - y_true)[mask]\n",
        "    mse = float(np.mean(diff**2))\n",
        "    var = _masked_var(y_true)\n",
        "    if var > 0:\n",
        "        err = mse / var\n",
        "    else:\n",
        "        amp = float(np.nanmax(np.abs(y_true)) or 1.0)\n",
        "        err = mse / (amp**2 if amp > 0 else 1.0)\n",
        "    acc = float(np.exp(-err))\n",
        "    return acc, {\"mse\": mse, \"var\": var, \"norm_err\": err}\n",
        "\n",
        "def _finite_diff(y: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
        "    dt = np.diff(t)\n",
        "    if np.any(dt <= 0):\n",
        "        raise ValueError(\"Time vector must be strictly increasing\")\n",
        "    S, T = y.shape\n",
        "    dy = np.empty_like(y)\n",
        "    dy[:, 0] = (y[:, 1] - y[:, 0]) / dt[0]\n",
        "    dy[:, -1] = (y[:, -1] - y[:, -2]) / dt[-1]\n",
        "    mid_dt = (t[2:] - t[:-2]) / 2.0\n",
        "    dy[:, 1:-1] = (y[:, 2:] - y[:, :-2]) / mid_dt\n",
        "    return dy\n",
        "\n",
        "def _smoothness_score(y: np.ndarray, t: np.ndarray) -> float:\n",
        "    dy = _finite_diff(y, t)\n",
        "    d2y = _finite_diff(dy, t)\n",
        "    num = np.nanmean(d2y**2)\n",
        "    denom = (np.nanmean(y**2) or 1.0)\n",
        "    ratio = float(num / denom)\n",
        "    return float(np.exp(-0.1 * ratio))\n",
        "\n",
        "def _reversibility_score(y: np.ndarray, t: np.ndarray) -> float:\n",
        "    y_f = (y - np.nanmean(y, axis=1, keepdims=True)) / (np.nanstd(y, axis=1, keepdims=True) + 1e-12)\n",
        "    y_r = np.flip(y_f, axis=1)\n",
        "    corrs = []\n",
        "    for i in range(y.shape[0]):\n",
        "        if y.shape[1] > 3:\n",
        "            c = np.corrcoef(y_f[i], y_r[i])[0, 1]\n",
        "            if not np.isnan(c):\n",
        "                corrs.append(abs(c))\n",
        "    corr = np.mean(corrs) if corrs else 0.0\n",
        "    return float(0.5 + 0.5 * corr)\n",
        "\n",
        "def _energy_drift_score(y: np.ndarray, t: np.ndarray, energy_fn: Optional[Callable[[np.ndarray], np.ndarray]]) -> Tuple[float, Optional[float]]:\n",
        "    if energy_fn is None:\n",
        "        return 0.5, None\n",
        "    E = energy_fn(y)  # shape (T,)\n",
        "    if E is None or np.all(np.isnan(E)):\n",
        "        return 0.5, None\n",
        "    med = float(np.nanmedian(E))\n",
        "    mad = float(np.nanmedian(np.abs(E - med))) + 1e-9\n",
        "    drift = float(np.nanmax(np.abs(E - med)) / mad)\n",
        "    score = float(np.exp(-0.2 * drift))\n",
        "    return score, drift\n",
        "\n",
        "def _kl_divergence(p: np.ndarray, q: np.ndarray) -> float:\n",
        "    eps = 1e-12\n",
        "    p = p + eps\n",
        "    q = q + eps\n",
        "    p = p / p.sum()\n",
        "    q = q / q.sum()\n",
        "    return float(np.sum(p * np.log(p / q)))\n",
        "\n",
        "def _token_hist(tokens: List[Token], vocab: List[Token]) -> np.ndarray:\n",
        "    idx = {tok: i for i, tok in enumerate(vocab)}\n",
        "    counts = np.zeros(len(vocab), dtype=float)\n",
        "    for t in tokens:\n",
        "        if t in idx:\n",
        "            counts[idx[t]] += 1\n",
        "    if counts.sum() == 0:\n",
        "        counts += 1.0\n",
        "    return counts\n",
        "\n",
        "def _novelty_score(equations: Iterable[Any], prior_vocab: List[Token], prior_freq: np.ndarray, beta: float = 0.6) -> Tuple[float, Dict[str, Any]]:\n",
        "    toks: List[Token] = []\n",
        "    for eq in equations:\n",
        "        toks.extend(_to_tokens(eq))\n",
        "    p_hist = _token_hist(toks, prior_vocab)\n",
        "    kl = _kl_divergence(p_hist, prior_freq)\n",
        "    score = float(1.0 - np.exp(-beta * kl))\n",
        "    return score, {\"kl\": kl, \"token_count\": int(p_hist.sum())}\n",
        "\n",
        "class MetaValidator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        threshold: float = 0.8,\n",
        "        alpha: Tuple[float, float, float] = (0.5, 0.3, 0.2),\n",
        "        prior_vocab: Optional[List[Token]] = None,\n",
        "        prior_freq: Optional[np.ndarray] = None,\n",
        "        seed: Optional[int] = 42,\n",
        "    ):\n",
        "        self.threshold = float(threshold)\n",
        "        self.w_acc, self.w_simp, self.w_nov = alpha\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        default_vocab = [\"x\",\"y\",\"z\",\"t\",\"+\",\"-\",\"*\",\"/\",\"^\",\"=\",\"sin\",\"cos\",\"exp\",\"log\",\"1\",\"2\",\"0\"]\n",
        "        self.prior_vocab = prior_vocab or default_vocab\n",
        "        if prior_freq is None:\n",
        "            self.prior_freq = np.array([3,3,1,2,5,4,5,3,2,0,1,1,1,1,2,1,2], dtype=float)\n",
        "        else:\n",
        "            self.prior_freq = np.array(prior_freq, dtype=float)\n",
        "        if len(self.prior_vocab) != len(self.prior_freq):\n",
        "            raise ValueError(\"prior_vocab and prior_freq must align\")\n",
        "\n",
        "    def score(\n",
        "        self,\n",
        "        theory: Dict[str, Any],\n",
        "        sim_output: SimOutput,\n",
        "        ground_truth: Optional[np.ndarray] = None,\n",
        "        energy_fn: Optional[Callable[[np.ndarray], np.ndarray]] = None,\n",
        "    ) -> ScoreReport:\n",
        "        t = np.asarray(sim_output.t)\n",
        "        y = np.asarray(sim_output.y)\n",
        "        if y.ndim != 2:\n",
        "            raise ValueError(f\"sim_output.y must be 2D (S,T), got {y.shape}\")\n",
        "        if t.ndim != 1 or t.shape[0] != y.shape[1]:\n",
        "            raise ValueError(\"Time vector length must match y's time dimension\")\n",
        "        equations = theory.get(\"equations\", [])\n",
        "        if not isinstance(equations, (list, tuple)) or len(equations) == 0:\n",
        "            raise ValueError(\"theory['equations'] must be a non-empty list\")\n",
        "\n",
        "        if ground_truth is not None:\n",
        "            acc, acc_det = _accuracy_with_gt(y, np.asarray(ground_truth))\n",
        "        else:\n",
        "            rev = _reversibility_score(y, t)\n",
        "            smo = _smoothness_score(y, t)\n",
        "            eng, drift = _energy_drift_score(y, t, energy_fn)\n",
        "            acc = float(0.5 * rev + 0.3 * smo + 0.2 * eng)\n",
        "            acc_det = {\"proxy\": True, \"reversibility\": rev, \"smoothness\": smo, \"energy\": eng, \"energy_drift\": drift}\n",
        "\n",
        "        desc_len = _description_length(equations)\n",
        "        simp = _simplicity_score(desc_len)\n",
        "        simp_det = {\"description_length\": desc_len}\n",
        "\n",
        "        nov, nov_det = _novelty_score(equations, self.prior_vocab, self.prior_freq)\n",
        "\n",
        "        total = float(self.w_acc * acc + self.w_simp * simp + self.w_nov * nov)\n",
        "        passed = bool(total >= self.threshold)\n",
        "        details = {\n",
        "            \"accuracy\": acc_det,\n",
        "            \"simplicity\": simp_det,\n",
        "            \"novelty\": nov_det,\n",
        "            \"weights\": {\"acc\": self.w_acc, \"simp\": self.w_simp, \"nov\": self.w_nov},\n",
        "        }\n",
        "        return ScoreReport(\n",
        "            total=total,\n",
        "            passed=passed,\n",
        "            components={\"accuracy\": acc, \"simplicity\": simp, \"novelty\": nov},\n",
        "            details=details,\n",
        "            threshold=self.threshold,\n",
        "            timestamp=time.time(),\n",
        "        )\n",
        "\n",
        "# ========== Abstraction ==========\n",
        "\n",
        "class LatentInvariantExtractor:\n",
        "    \"\"\"\n",
        "    Lightweight abstraction: standardize data and expose simple invariants.\n",
        "    Input data shape: (N, S) or list of arrays; here we use it for provenance and potential feature hints.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.mean_: Optional[np.ndarray] = None\n",
        "        self.std_: Optional[np.ndarray] = None\n",
        "\n",
        "    def fit(self, data: np.ndarray) -> \"LatentInvariantExtractor\":\n",
        "        if data.ndim != 2:\n",
        "            data = np.asarray(data)\n",
        "            data = data.reshape(len(data), -1)\n",
        "        self.mean_ = np.mean(data, axis=0)\n",
        "        self.std_ = np.std(data, axis=0) + 1e-9\n",
        "        return self\n",
        "\n",
        "    def transform(self, data: np.ndarray) -> np.ndarray:\n",
        "        if self.mean_ is None or self.std_ is None:\n",
        "            raise RuntimeError(\"Call fit() before transform().\")\n",
        "        return (data - self.mean_) / self.std_\n",
        "\n",
        "    def extract(self, data: np.ndarray) -> Dict[str, Any]:\n",
        "        X = self.transform(data)\n",
        "        cov = np.cov(X.T)\n",
        "        return {\n",
        "            \"mean\": self.mean_.tolist(),\n",
        "            \"std\": self.std_.tolist(),\n",
        "            \"cov_trace\": float(np.trace(cov)),\n",
        "            \"corr_abs_mean\": float(np.mean(np.abs(np.corrcoef(X.T)))),\n",
        "        }\n",
        "\n",
        "# ========== Theory constructor ==========\n",
        "\n",
        "class SymbolicTheoryConstructor:\n",
        "    \"\"\"\n",
        "    Enumerates linear ODE candidates for states ['x','y']:\n",
        "        dx/dt = a*x + b*y\n",
        "        dy/dt = c*x + d*y\n",
        "    Coefficients drawn from a small discrete set.\n",
        "    \"\"\"\n",
        "    def __init__(self, var_names: Tuple[str, ...] = (\"x\",\"y\"), coeff_grid: Tuple[float, ...] = (-1.0, -0.5, 0.0, 0.5, 1.0)):\n",
        "        if tuple(var_names) != (\"x\",\"y\"):\n",
        "            raise NotImplementedError(\"This demo constructor supports exactly two states: ('x','y').\")\n",
        "        self.var_names = list(var_names)\n",
        "        self.coeff_grid = coeff_grid\n",
        "\n",
        "    def build_candidates(self, max_candidates: Optional[int] = None) -> List[Dict[str, Any]]:\n",
        "        cand: List[Dict[str, Any]] = []\n",
        "        count = 0\n",
        "        for a in self.coeff_grid:\n",
        "            for b in self.coeff_grid:\n",
        "                for c in self.coeff_grid:\n",
        "                    for d in self.coeff_grid:\n",
        "                        A = np.array([[a, b],\n",
        "                                      [c, d]], dtype=float)\n",
        "                        if np.allclose(A, 0.0):  # skip trivial zero dynamics\n",
        "                            continue\n",
        "                        eqs = [\n",
        "                            f\"dx/dt = {a:+.2f}*x {b:+.2f}*y\",\n",
        "                            f\"dy/dt = {c:+.2f}*x {d:+.2f}*y\",\n",
        "                        ]\n",
        "                        cand.append({\"equations\": eqs, \"A\": A, \"states\": self.var_names})\n",
        "                        count += 1\n",
        "                        if max_candidates is not None and count >= max_candidates:\n",
        "                            return cand\n",
        "        return cand\n",
        "\n",
        "# ========== Simulator (RK4) ==========\n",
        "\n",
        "class SympyODESimulator:\n",
        "    \"\"\"\n",
        "    Minimal RK4 simulator for linear system: dy/dt = A y\n",
        "    (Name kept for compatibility with earlier examples.)\n",
        "    \"\"\"\n",
        "    def __init__(self, theory: Dict[str, Any]):\n",
        "        self.A = np.array(theory[\"A\"], dtype=float)\n",
        "        self.states = theory.get(\"states\", [\"x\",\"y\"])\n",
        "\n",
        "    def simulate(self, y0: np.ndarray, t: np.ndarray) -> SimOutput:\n",
        "        y0 = np.asarray(y0, dtype=float).reshape(-1)\n",
        "        S = len(self.states)\n",
        "        assert y0.shape[0] == S, f\"Initial condition has wrong size: {y0.shape[0]} vs {S}\"\n",
        "        Y = np.zeros((S, len(t)), dtype=float)\n",
        "        Y[:, 0] = y0\n",
        "        for k in range(len(t) - 1):\n",
        "            dt = float(t[k+1] - t[k])\n",
        "            yk = Y[:, k]\n",
        "            f = lambda y: self.A @ y\n",
        "            k1 = f(yk)\n",
        "            k2 = f(yk + 0.5*dt*k1)\n",
        "            k3 = f(yk + 0.5*dt*k2)\n",
        "            k4 = f(yk + dt*k3)\n",
        "            Y[:, k+1] = yk + (dt/6.0) * (k1 + 2*k2 + 2*k3 + k4)\n",
        "        return SimOutput(t=t, y=Y, states=self.states)\n",
        "\n",
        "# ========== Engine ==========\n",
        "\n",
        "class RecursiveGeneralizationEngine:\n",
        "    def __init__(\n",
        "        self,\n",
        "        abstraction_engine: LatentInvariantExtractor,\n",
        "        theory_constructor: SymbolicTheoryConstructor,\n",
        "        simulator_factory: Callable[[Dict[str, Any]], SympyODESimulator],\n",
        "        validator: MetaValidator,\n",
        "    ):\n",
        "        self.abstraction_engine = abstraction_engine\n",
        "        self.theory_constructor = theory_constructor\n",
        "        self.simulator_factory = simulator_factory\n",
        "        self.validator = validator\n",
        "\n",
        "    def run(\n",
        "        self,\n",
        "        input_data: np.ndarray,\n",
        "        t: np.ndarray,\n",
        "        y0: np.ndarray,\n",
        "        ground_truth: Optional[np.ndarray] = None,\n",
        "        max_candidates: Optional[int] = 300,\n",
        "        top_k: int = 5,\n",
        "        run_dir: Optional[str] = None,\n",
        "    ) -> List[Tuple[Dict[str, Any], float, ScoreReport]]:\n",
        "        # Abstraction\n",
        "        self.abstraction_engine.fit(input_data)\n",
        "        invariants = self.abstraction_engine.extract(input_data)\n",
        "\n",
        "        # Construct theories\n",
        "        candidates = self.theory_constructor.build_candidates(max_candidates=max_candidates)\n",
        "\n",
        "        # Scoring\n",
        "        results: List[Tuple[Dict[str, Any], float, ScoreReport]] = []\n",
        "        energy_fn = lambda y: np.sum(y**2, axis=0)\n",
        "\n",
        "        for th in candidates:\n",
        "            sim = self.simulator_factory(th).simulate(y0=y0, t=t)\n",
        "            rep = self.validator.score(theory=th, sim_output=sim, ground_truth=ground_truth, energy_fn=energy_fn)\n",
        "            results.append((th, rep.total, rep))\n",
        "\n",
        "        # Sort and keep top_k\n",
        "        results.sort(key=lambda x: -x[1])\n",
        "        top = results[:top_k]\n",
        "\n",
        "        # Persist artifacts\n",
        "        if run_dir is not None:\n",
        "            Path(run_dir).mkdir(parents=True, exist_ok=True)\n",
        "            # manifest\n",
        "            manifest = {\n",
        "                \"timestamp\": time.time(),\n",
        "                \"states\": self.theory_constructor.var_names,\n",
        "                \"t_span\": [float(t[0]), float(t[-1])],\n",
        "                \"num_timepoints\": int(len(t)),\n",
        "                \"y0\": y0.tolist(),\n",
        "                \"validator\": {\n",
        "                    \"threshold\": self.validator.threshold,\n",
        "                    \"alpha\": [self.validator.w_acc, self.validator.w_simp, self.validator.w_nov],\n",
        "                    \"version\": \"meta-validator/1.0.0\",\n",
        "                },\n",
        "                \"abstraction\": invariants,\n",
        "                \"num_candidates_scored\": len(results),\n",
        "                \"top_k\": top_k,\n",
        "            }\n",
        "            (Path(run_dir) / \"manifest.json\").write_text(json.dumps(manifest, indent=2))\n",
        "            # top reports\n",
        "            for i, (th, sc, rep) in enumerate(top, 1):\n",
        "                payload = {\n",
        "                    \"rank\": i,\n",
        "                    \"score\": sc,\n",
        "                    \"theory\": th,\n",
        "                    \"report\": json.loads(rep.to_json()),\n",
        "                }\n",
        "                (Path(run_dir) / f\"theory_{i:02d}.json\").write_text(json.dumps(payload, indent=2))\n",
        "\n",
        "        return top\n",
        "\n",
        "# ========== Demo run ==========\n",
        "\n",
        "def generate_ground_truth(t: np.ndarray, y0: np.ndarray, A_true: np.ndarray) -> np.ndarray:\n",
        "    sim_true = SympyODESimulator({\"A\": A_true, \"states\": [\"x\",\"y\"]})\n",
        "    return sim_true.simulate(y0=y0, t=t).y\n",
        "\n",
        "def main():\n",
        "    np.random.seed(0)\n",
        "\n",
        "    # Config\n",
        "    states = [\"x\",\"y\"]\n",
        "    t = np.linspace(0.0, 5.0, 101)\n",
        "    y0 = np.array([1.0, -1.0], dtype=float)\n",
        "    # True dynamics (unknown to the search)\n",
        "    A_true = np.array([[-1.0, 0.00],\n",
        "                       [ 0.2,-0.80]], dtype=float)\n",
        "\n",
        "    # Generate ground truth and raw (noisy) observations\n",
        "    y_true = generate_ground_truth(t, y0, A_true)\n",
        "    noise = 0.05 * np.random.randn(*y_true.shape)\n",
        "    raw_observations = (y_true + noise).T  # shape (T, S) for abstraction; any 2D is fine\n",
        "\n",
        "    # Instantiate components\n",
        "    abstraction = LatentInvariantExtractor()\n",
        "    constructor = SymbolicTheoryConstructor(var_names=(\"x\",\"y\"), coeff_grid=(-1.0, -0.5, -0.2, 0.0, 0.2, 0.5, 1.0))\n",
        "    validator = MetaValidator(threshold=0.80, alpha=(0.6, 0.25, 0.15), seed=123)\n",
        "\n",
        "    def simulator_factory(theory: Dict[str, Any]) -> SympyODESimulator:\n",
        "        return SympyODESimulator(theory)\n",
        "\n",
        "    rge = RecursiveGeneralizationEngine(\n",
        "        abstraction_engine=abstraction,\n",
        "        theory_constructor=constructor,\n",
        "        simulator_factory=simulator_factory,\n",
        "        validator=validator\n",
        "    )\n",
        "\n",
        "    # Provenance: run directory\n",
        "    run_tag = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_dir = os.path.join(\"runs\", f\"rge_demo_{run_tag}\")\n",
        "\n",
        "    # Execute\n",
        "    top = rge.run(\n",
        "        input_data=raw_observations,\n",
        "        t=t,\n",
        "        y0=y0,\n",
        "        ground_truth=y_true,       # validator will use this for accuracy\n",
        "        max_candidates=500,        # trims the grid for speed\n",
        "        top_k=5,\n",
        "        run_dir=run_dir\n",
        "    )\n",
        "\n",
        "    # Display\n",
        "    print(\"Top-scoring theories:\")\n",
        "    for i, (th, sc, rep) in enumerate(top, 1):\n",
        "        eqs = th[\"equations\"]\n",
        "        print(f\"{i:>2d}) score={sc:.3f}  {eqs[0]} ; {eqs[1]}\")\n",
        "\n",
        "    print(f\"\\nArtifacts saved to: {run_dir}\")\n",
        "    print(\" - manifest.json\")\n",
        "    for i in range(1, len(top)+1):\n",
        "        print(f\" - theory_{i:02d}.json\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}
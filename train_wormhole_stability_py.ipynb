{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOGZvEXpiceSg5qkMg/J1gZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_wormhole_stability_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_ybM9miGv2R"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_wormhole_stability.py\n",
        "\n",
        "Physics-informed pipeline for traversable wormhole stability:\n",
        "\n",
        "1. Synthetic dataset of 6 wormhole parameters → 3 stability metrics\n",
        "2. PINN residual enforcing throat flare-out condition\n",
        "3. MLP with LayerNorm & Dropout for uncertainty quantification\n",
        "4. MC-Dropout inference\n",
        "5. Training loop with AdamW, ReduceLROnPlateau, early stopping\n",
        "6. Visualization: loss, true vs pred scatter, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Wormhole Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class WormholeDataset(Dataset):\n",
        "    def __init__(self, n_samples=6000, seed=0):\n",
        "        np.random.seed(seed)\n",
        "        # Inputs: exotic_density, energy_density, curvature, pressure, charge, spin\n",
        "        ed = np.random.uniform(0.1,10.0,(n_samples,1)).astype(np.float32)\n",
        "        en = np.random.uniform(0.1,10.0,(n_samples,1)).astype(np.float32)\n",
        "        cu = np.random.uniform(-1.0,1.0,(n_samples,1)).astype(np.float32)\n",
        "        pr = np.random.uniform(0.0,5.0,(n_samples,1)).astype(np.float32)\n",
        "        ch = np.random.uniform(0.0,2.0,(n_samples,1)).astype(np.float32)\n",
        "        sp = np.random.uniform(-1.0,1.0,(n_samples,1)).astype(np.float32)\n",
        "        X_raw = np.hstack([ed,en,cu,pr,ch,sp])\n",
        "\n",
        "        # Supervised targets (toy)\n",
        "        stability_1 = ed*np.exp(-cu) + 0.1*pr\n",
        "        stability_2 = np.sin(en) * sp + 0.05*ch\n",
        "        stability_3 = (ed+en)/(1+np.abs(cu))\n",
        "        Y_raw = np.hstack([stability_1, stability_2, stability_3]).astype(np.float32)\n",
        "        Y_raw += 0.02 * np.random.randn(*Y_raw.shape).astype(np.float32)\n",
        "\n",
        "        # Normalize with 1D stats\n",
        "        self.X_mean, self.X_std = X_raw.mean(0), X_raw.std(0)+1e-6\n",
        "        self.Y_mean, self.Y_std = Y_raw.mean(0), Y_raw.std(0)+1e-6\n",
        "\n",
        "        self.X = (X_raw - self.X_mean) / self.X_std\n",
        "        self.Y = (Y_raw - self.Y_mean) / self.Y_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model Definition\n",
        "# ------------------------------------------------------------------------------\n",
        "class WormholeAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dims=(64,64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers, dim = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim = h\n",
        "        layers.append(nn.Linear(dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Residual\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def physics_residual(pred, inp, stats):\n",
        "    # Denormalize\n",
        "    X_den = inp * stats['X_std'] + stats['X_mean']\n",
        "    ed, en, cu, pr, ch, sp = [X_den[:,i] for i in range(6)]\n",
        "    Y_den = pred * stats['Y_std'] + stats['Y_mean']\n",
        "    s1, s2, s3 = Y_den[:,0], Y_den[:,1], Y_den[:,2]\n",
        "\n",
        "    # Toy flare-out: second derivative of radius > 0\n",
        "    # Here mimic as: ed - cu^2 ≈ s1\n",
        "    flare = ed - cu**2\n",
        "    res1  = nn.MSELoss()(s1, flare)\n",
        "    # Energy-spinning stability: sin(en)*sp ≈ s2\n",
        "    res2  = nn.MSELoss()(s2, torch.sin(en)*sp)\n",
        "    # Combined metric: (ed+en)/(1+|cu|) ≈ s3\n",
        "    res3  = nn.MSELoss()(s3, (ed+en)/(1+cu.abs()))\n",
        "    return res1 + res2 + res3\n",
        "\n",
        "def total_loss(pred, true, inp, stats, λ=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, inp, stats)\n",
        "    return mse + λ*phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout Inference\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, x, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(x))\n",
        "    arr = torch.stack(preds, dim=0)  # [T,B,3]\n",
        "    mean = arr.mean(0)\n",
        "    std  = arr.std(0)\n",
        "    return mean, std\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-3, wd=1e-5, λ=1.0, max_epochs=150, patience=15):\n",
        "    model.to(device)\n",
        "    opt   = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min',\n",
        "                                                factor=0.5, patience=5)\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train':[], 'val':[]}\n",
        "\n",
        "    for epoch in range(1, max_epochs+1):\n",
        "        model.train()\n",
        "        tr_loss = 0.0\n",
        "        for xb,yb in train_loader:\n",
        "            xb,yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss,_,_ = total_loss(pred,yb,xb,stats,λ)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            tr_loss += loss.item()*xb.size(0)\n",
        "        tr_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss=0.0\n",
        "        with torch.no_grad():\n",
        "            for xb,yb in val_loader:\n",
        "                xb,yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss,_,_ = total_loss(pred,yb,xb,stats,λ)\n",
        "                val_loss+= loss.item()*xb.size(0)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        sched.step(val_loss)\n",
        "        history['train'].append(tr_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        print(f\"Epoch {epoch:03d} | Train {tr_loss:.4e} | Val {val_loss:.4e}\")\n",
        "\n",
        "        if val_loss<best_val-1e-6:\n",
        "            best_val,wait = val_loss,0\n",
        "            torch.save(model.state_dict(),\"best_wormhole_ai.pth\")\n",
        "        else:\n",
        "            wait+=1\n",
        "            if wait>=patience:\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(\"best_wormhole_ai.pth\"))\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_history(h):\n",
        "    plt.figure()\n",
        "    plt.plot(h['train'], label='Train')\n",
        "    plt.plot(h['val'],   label='Val')\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "    plt.legend(); plt.title(\"Training Curve\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_scatter(y_true, y_pred, name):\n",
        "    plt.figure()\n",
        "    plt.scatter(y_true, y_pred, s=5, alpha=0.6)\n",
        "    m,M=y_true.min(),y_true.max()\n",
        "    plt.plot([m,M],[m,M],'r--')\n",
        "    plt.xlabel(f\"True {name}\"); plt.ylabel(f\"Pred {name}\")\n",
        "    plt.title(name)\n",
        "    plt.show()\n",
        "\n",
        "def plot_uncertainty_heatmap(model, stats_np, device):\n",
        "    # Vary exotic_density vs energy_density, fix others\n",
        "    vals = np.linspace(0.1,10,100)\n",
        "    ED, EN = np.meshgrid(vals, vals)\n",
        "    grid = np.zeros((ED.size,6),dtype=np.float32)\n",
        "    grid[:,0],grid[:,1]=ED.ravel(),EN.ravel()\n",
        "    for i in (2,3,4,5):\n",
        "        grid[:,i]=stats_np['X_mean'][i]\n",
        "\n",
        "    Xn=torch.from_numpy((grid - stats_np['X_mean'])/stats_np['X_std']).float().to(device)\n",
        "    mean,std=mc_dropout_predict(model,Xn,T=100)\n",
        "    std0=std[:,0].cpu().numpy().reshape(ED.shape)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.pcolormesh(ED,EN,std0,cmap='viridis',shading='auto')\n",
        "    plt.colorbar(label='Std(s1)')\n",
        "    plt.xlabel('Exotic Density');plt.ylabel('Energy Density')\n",
        "    plt.title('Uncertainty Heatmap')\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__==\"__main__\":\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    ds=WormholeDataset(6000)\n",
        "    stats={\n",
        "        'X_mean':torch.tensor(ds.X_mean,device=device),\n",
        "        'X_std' :torch.tensor(ds.X_std, device=device),\n",
        "        'Y_mean':torch.tensor(ds.Y_mean,device=device),\n",
        "        'Y_std' :torch.tensor(ds.Y_std, device=device),\n",
        "    }\n",
        "    stats_np={\n",
        "        'X_mean':ds.X_mean,'X_std':ds.X_std,\n",
        "        'Y_mean':ds.Y_mean,'Y_std':ds.Y_std,\n",
        "    }\n",
        "\n",
        "    n_val=int(0.2*len(ds))\n",
        "    tr,va=random_split(ds,[len(ds)-n_val,n_val])\n",
        "    tr_ld=DataLoader(tr, batch_size=128, shuffle=True)\n",
        "    va_ld=DataLoader(va, batch_size=256)\n",
        "\n",
        "    model=WormholeAI().to(device)\n",
        "    history=train(model,tr_ld,va_ld,stats,device)\n",
        "\n",
        "    plot_history(history)\n",
        "\n",
        "    # scatter\n",
        "    X_all=torch.from_numpy(ds.X).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        Yp = model(X_all).cpu().numpy()\n",
        "    Yt=ds.Y\n",
        "    for i,name in enumerate(['s1','s2','s3']):\n",
        "        plot_scatter(Yt[:,i],Yp[:,i],name)\n",
        "\n",
        "    plot_uncertainty_heatmap(model,stats_np,device)"
      ]
    }
  ]
}
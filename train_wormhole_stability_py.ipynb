{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN989aeTcKzju/Cq7gsUDt9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_wormhole_stability_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNAu4euk3E5S"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_wormhole_stability.py\n",
        "\n",
        "End-to-end pipeline for WormholeStabilityAI:\n",
        "  • Defines an MLP with Dropout for MC‐Dropout UQ\n",
        "  • Synthetic dummy dataset of wormhole metric coefficients → stability corrections\n",
        "  • Physics‐informed loss: MSE + curvature residual\n",
        "  • Training loop with AdamW, ReduceLROnPlateau, early stopping\n",
        "  • MC‐Dropout inference for uncertainty estimates\n",
        "  • Scatter‐and‐residual plots of predictions\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Model Definition with Dropout\n",
        "# ------------------------------------------------------------------------------\n",
        "class WormholeStabilityAI(nn.Module):\n",
        "    def __init__(self, input_dim=5, hidden_dim=32, output_dim=3, dropout_p=0.1):\n",
        "        super().__init__()\n",
        "        self.fc1   = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.drop1 = nn.Dropout(dropout_p)\n",
        "        self.fc2   = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.drop2 = nn.Dropout(dropout_p)\n",
        "        self.fc3   = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.relu(self.fc1(x))\n",
        "        h = self.drop1(h)\n",
        "        h = self.relu(self.fc2(h))\n",
        "        h = self.drop2(h)\n",
        "        return self.fc3(h)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Physics‐Informed Loss Components\n",
        "# ------------------------------------------------------------------------------\n",
        "def curvature_residual(pred, inputs):\n",
        "    \"\"\"\n",
        "    Physics residual: pred[:,0] estimates Ricci scalar R\n",
        "    Dummy true Ricci scalar ~ 0.1 * sum(inputs_i^2)\n",
        "    \"\"\"\n",
        "    R_pred = pred[:, 0]\n",
        "    R_true = 0.1 * (inputs**2).sum(dim=1)\n",
        "    return nn.functional.mse_loss(R_pred, R_true)\n",
        "\n",
        "def total_loss(pred, target, inputs, lambda_phys=0.5):\n",
        "    \"\"\"\n",
        "    Combined loss: MSE(targets) + λ * physics residual\n",
        "    \"\"\"\n",
        "    mse = nn.functional.mse_loss(pred, target)\n",
        "    phys = curvature_residual(pred, inputs)\n",
        "    return mse + lambda_phys * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Dummy Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class DummyWormholeDataset(Dataset):\n",
        "    def __init__(self, N=5000, input_dim=5, output_dim=3):\n",
        "        super().__init__()\n",
        "        np.random.seed(1)\n",
        "        # Random metric coefficients in [-1,1]\n",
        "        self.X = torch.from_numpy(\n",
        "            np.random.uniform(-1, 1, size=(N, input_dim)).astype(np.float32)\n",
        "        )\n",
        "        # Dummy stability corrections and Ricci estimate\n",
        "        self.Y = torch.from_numpy(\n",
        "            np.random.uniform(-0.5, 0.5, size=(N, output_dim)).astype(np.float32)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC‐Dropout Inference\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, x, n_samples=100, device='cpu'):\n",
        "    \"\"\"\n",
        "    Returns mean and std of model(x) under MC‐Dropout.\n",
        "    \"\"\"\n",
        "    model.train()  # keep dropout on\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            out = model(x.to(device)).cpu().numpy()\n",
        "            preds.append(out)\n",
        "    preds = np.stack(preds, axis=0)      # (n_samples, batch, output_dim)\n",
        "    mean  = preds.mean(axis=0)           # (batch, output_dim)\n",
        "    std   = preds.std(axis=0)            # (batch, output_dim)\n",
        "    model.eval()\n",
        "    return mean, std\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Data Loaders\n",
        "# ------------------------------------------------------------------------------\n",
        "def get_loaders(batch_size=64, val_frac=0.2):\n",
        "    ds = DummyWormholeDataset(N=5000)\n",
        "    n_val = int(len(ds) * val_frac)\n",
        "    n_trn = len(ds) - n_val\n",
        "    trn, val = random_split(ds, [n_trn, n_val])\n",
        "    return (\n",
        "        DataLoader(trn, batch_size=batch_size, shuffle=True),\n",
        "        DataLoader(val, batch_size=batch_size)\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Training Loop with Early Stopping & Scheduler\n",
        "# ------------------------------------------------------------------------------\n",
        "def train_model(\n",
        "    model, train_loader, val_loader,\n",
        "    lr=1e-3, weight_decay=1e-5, lambda_phys=0.5,\n",
        "    max_epochs=200, patience_max=20, device='cpu'\n",
        "):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
        "    )\n",
        "\n",
        "    best_val = float('inf')\n",
        "    patience = 0\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_phys': []}\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        running_tr_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss, mse_l, phys_l = total_loss(out, yb, xb, lambda_phys)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_tr_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        train_loss = running_tr_loss / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        running_phys    = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                out = model(xb)\n",
        "                loss, mse_l, phys_l = total_loss(out, yb, xb, lambda_phys)\n",
        "                running_val_loss += loss.item() * xb.size(0)\n",
        "                running_phys    += phys_l.item() * xb.size(0)\n",
        "\n",
        "        val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        val_phys = running_phys / len(val_loader.dataset)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_phys'].append(val_phys)\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val = val_loss\n",
        "            torch.save(model.state_dict(), \"best_wormhole_stab.pt\")\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience >= patience_max:\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "        if epoch % 20 == 0 or epoch == 1:\n",
        "            print(f\"Epoch {epoch:03d} | Train {train_loss:.4f} | Val {val_loss:.4f} | PhysRes {val_phys:.4f}\")\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load(\"best_wormhole_stab.pt\"))\n",
        "    return model, history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare data\n",
        "    tr_loader, va_loader = get_loaders(batch_size=64, val_frac=0.2)\n",
        "\n",
        "    # Build and train\n",
        "    model = WormholeStabilityAI(input_dim=5, hidden_dim=32, output_dim=3, dropout_p=0.1)\n",
        "    model, hist = train_model(\n",
        "        model, tr_loader, va_loader,\n",
        "        lr=1e-3, weight_decay=1e-5, lambda_phys=0.5,\n",
        "        max_epochs=200, patience_max=20, device=device\n",
        "    )\n",
        "\n",
        "    # Plot training history\n",
        "    epochs = len(hist['train_loss'])\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(range(1, epochs+1), hist['train_loss'], label=\"Train Loss\")\n",
        "    plt.plot(range(1, epochs+1), hist['val_loss'],   label=\"Val Loss\")\n",
        "    plt.plot(range(1, epochs+1), hist['val_phys'],   label=\"Val PhysRes\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
        "    plt.title(\"WormholeStabilityAI Training History\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # MC‐Dropout on a mini‐batch\n",
        "    xb, yb = next(iter(va_loader))\n",
        "    mean_p, std_p = mc_dropout_predict(model, xb, n_samples=100, device=device)\n",
        "    print(\"\\nMC‐Dropout predictions (first 5 samples):\")\n",
        "    for i in range(5):\n",
        "        print(f\"Input: {xb[i].cpu().numpy()}\")\n",
        "        print(f\"  Pred Mean: {mean_p[i]}  Std: {std_p[i]}\")\n",
        "\n",
        "    # Scatter plot: channel 0 (Ricci) true vs. predicted\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(\n",
        "        0.1 * (xb**2).sum(dim=1).cpu().numpy(),  # pseudo‐true Ricci\n",
        "        mean_p[:,0], s=20, alpha=0.5\n",
        "    )\n",
        "    m = min(mean_p[:,0].min(), 0.1*(xb**2).sum(dim=1).min().item())\n",
        "    M = max(mean_p[:,0].max(), 0.1*(xb**2).sum(dim=1).max().item())\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.xlabel(\"True Ricci Scalar\")\n",
        "    plt.ylabel(\"Predicted Ricci\")\n",
        "    plt.title(\"Ricci: True vs Predicted\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ]
}
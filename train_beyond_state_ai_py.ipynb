{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOhvWjrXv8e3UzKKoR6y08a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_beyond_state_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# train_beyond_state_ai.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Beyond-State Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class BeyondStateDataset(Dataset):\n",
        "    def __init__(self, n_samples=5000, seed=123):\n",
        "        np.random.seed(seed)\n",
        "        eps = 1e-8\n",
        "\n",
        "        # Define inputs\n",
        "        BSF = np.random.uniform(0.0, 10.0,  (n_samples,1))\n",
        "        UTR = np.random.uniform(0.1, 5.0,   (n_samples,1))\n",
        "        SNE = np.random.uniform(0.0, 1.0,   (n_samples,1))\n",
        "        AWR = np.random.uniform(1,   100,   (n_samples,1))\n",
        "        CCL = np.random.uniform(0.01, 2.0,  (n_samples,1))\n",
        "        TSC = np.random.uniform(0.5, 10.0,  (n_samples,1))\n",
        "        X_raw = np.hstack([BSF, UTR, SNE, AWR, CCL, TSC]).astype(np.float64)\n",
        "\n",
        "        # Compute targets\n",
        "        BCO = BSF * np.log1p(AWR) / (UTR + eps)\n",
        "        UAW = np.sqrt(UTR * CCL)\n",
        "        SNS = SNE * TSC / (BSF + eps)\n",
        "        Y_raw = np.hstack([BCO, UAW, SNS]).astype(np.float64)\n",
        "\n",
        "        # Add noise\n",
        "        noise_scale = 0.02 * Y_raw.std(axis=0)\n",
        "        Y_raw += np.random.randn(*Y_raw.shape) * noise_scale\n",
        "\n",
        "        # Normalize stats\n",
        "        self.X_mean, self.X_std = X_raw.mean(axis=0), X_raw.std(axis=0) + eps\n",
        "        self.Y_mean, self.Y_std = Y_raw.mean(axis=0), Y_raw.std(axis=0) + eps\n",
        "\n",
        "        # Normalize\n",
        "        Xn = ((X_raw - self.X_mean) / self.X_std).astype(np.float32)\n",
        "        Yn = ((Y_raw - self.Y_mean) / self.Y_std).astype(np.float32)\n",
        "\n",
        "        # Store tensors\n",
        "        self.X = torch.from_numpy(Xn)\n",
        "        self.Y = torch.from_numpy(Yn)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. BeyondStateAI Model\n",
        "# ------------------------------------------------------------------------------\n",
        "class BeyondStateAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dim=32, output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        self.fc1  = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.drop = nn.Dropout(p_drop)\n",
        "        self.fc2  = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed and Total Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, X, stats):\n",
        "    # Denormalize inputs\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    BSF, UTR, SNE, AWR, CCL, TSC = X_den.t()\n",
        "    eps = 1e-8\n",
        "\n",
        "    # Physics‐inspired targets\n",
        "    BCO_t = BSF * torch.log1p(AWR) / (UTR + eps)\n",
        "    UAW_t = torch.sqrt(UTR * CCL)\n",
        "    SNS_t = SNE * TSC / (BSF + eps)\n",
        "\n",
        "    Yt   = torch.stack([BCO_t, UAW_t, SNS_t], dim=1)\n",
        "    Yt_n = (Yt - stats['Y_mean']) / stats['Y_std']\n",
        "    return nn.MSELoss()(pred, Yt_n)\n",
        "\n",
        "def total_loss(pred, true, X, stats, λ=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, X, stats)\n",
        "    return mse + λ * phys, mse, phys\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout Uncertainty\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    arr = torch.stack(preds, dim=0)\n",
        "    return arr.mean(0), arr.std(0)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop with Early Stopping\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_dl, val_dl, stats, device,\n",
        "          lr=1e-4, wd=1e-5, λ=1.0, epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    optimzr = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched   = optim.lr_scheduler.ReduceLROnPlateau(optimzr, 'min', patience=5)\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train': [], 'val': []}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # Train\n",
        "        model.train()\n",
        "        run_tr = 0.0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, _, _ = total_loss(pred, yb, xb, stats, λ)\n",
        "            optimzr.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimzr.step()\n",
        "            run_tr += loss.item() * xb.size(0)\n",
        "        train_loss = run_tr / len(train_dl.dataset)\n",
        "\n",
        "        # Validate\n",
        "        model.eval()\n",
        "        run_va = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_dl:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                v_loss, _, _ = total_loss(pred, yb, xb, stats, λ)\n",
        "                run_va += v_loss.item() * xb.size(0)\n",
        "        val_loss = run_va / len(val_dl.dataset)\n",
        "\n",
        "        sched.step(val_loss)\n",
        "        history['train'].append(train_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        print(f\"Epoch {ep:03d} | Train {train_loss:.4e} | Val {val_loss:.4e}\")\n",
        "\n",
        "        # Checkpoint\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val, wait = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_beyond_state.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    # Load best\n",
        "    model.load_state_dict(torch.load(\"best_beyond_state.pth\", map_location=device))\n",
        "    return history\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_loss(hist):\n",
        "    plt.figure()\n",
        "    plt.plot(hist['train'], label='Train Loss')\n",
        "    plt.plot(hist['val'],   label='Val Loss')\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.show()\n",
        "\n",
        "def plot_scatter(y_true, y_pred, title):\n",
        "    plt.figure()\n",
        "    plt.scatter(y_true, y_pred, s=5, alpha=0.6)\n",
        "    mn, mx = y_true.min(), y_true.max()\n",
        "    plt.plot([mn, mx], [mn, mx], 'r--')\n",
        "    plt.title(title); plt.show()\n",
        "\n",
        "def plot_uncertainty(model, stats, device):\n",
        "    G = 80\n",
        "    BSF = np.linspace(0, 10, G, dtype=np.float32)\n",
        "    UTR = np.linspace(0.1, 5, G, dtype=np.float32)\n",
        "    B, U = np.meshgrid(BSF, UTR)\n",
        "    pts = G * G\n",
        "\n",
        "    Xg = torch.zeros((pts, 6), device=device)\n",
        "    for i in [2, 3, 4, 5]:\n",
        "        Xg[:, i] = stats['X_mean'][i]\n",
        "    Xg[:, 0] = torch.from_numpy(B.ravel()).to(device)\n",
        "    Xg[:, 1] = torch.from_numpy(U.ravel()).to(device)\n",
        "\n",
        "    Xn = (Xg - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout_predict(model, Xn, T=30)\n",
        "    Umap = std[:, 0].cpu().reshape(B.shape)\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.pcolormesh(BSF, UTR, Umap, shading='auto', cmap='viridis')\n",
        "    plt.colorbar(label=\"Std(Beyond Coherence)\")\n",
        "    plt.xlabel(\"Flux (BSF)\"); plt.ylabel(\"Transcendence (UTR)\")\n",
        "    plt.title(\"Uncertainty Heatmap\"); plt.show()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Dataset & stats\n",
        "    ds = BeyondStateDataset(n_samples=5000, seed=123)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, dtype=torch.float32, device=device),\n",
        "        'X_std' : torch.tensor(ds.X_std,  dtype=torch.float32, device=device),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, dtype=torch.float32, device=device),\n",
        "        'Y_std' : torch.tensor(ds.Y_std,  dtype=torch.float32, device=device),\n",
        "    }\n",
        "\n",
        "    # Split\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    tr_ds, va_ds = random_split(ds, [len(ds)-n_val, n_val])\n",
        "    tr_dl = DataLoader(tr_ds, batch_size=128, shuffle=True)\n",
        "    va_dl = DataLoader(va_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    # Model and train\n",
        "    model = BeyondStateAI().to(device)\n",
        "    history = train(model, tr_dl, va_dl, stats, device)\n",
        "\n",
        "    # Plot training curves\n",
        "    plot_loss(history)\n",
        "\n",
        "    # True vs predicted scatter\n",
        "    X_all = ds.X.to(device)\n",
        "    with torch.no_grad():\n",
        "        Y_pred_n = model(X_all).cpu().numpy()\n",
        "    Y_true = ds.Y * ds.Y_std + ds.Y_mean\n",
        "    Y_pred = Y_pred_n * ds.Y_std + ds.Y_mean\n",
        "\n",
        "    names = [\"Beyond Coherence\", \"Undefined Awareness\", \"Nullification Stability\"]\n",
        "    for i, name in enumerate(names):\n",
        "        plot_scatter(Y_true[:, i], Y_pred[:, i], name)\n",
        "\n",
        "    # Uncertainty heatmap\n",
        "    plot_uncertainty(model, stats, device)"
      ],
      "metadata": {
        "id": "xxg4F-EOJ3_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
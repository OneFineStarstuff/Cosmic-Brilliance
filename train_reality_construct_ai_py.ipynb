{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNEv0PIs8G+yo98T/8srVyP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_reality_construct_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sVLClfeoG8C"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_reality_construct_ai.py\n",
        "\n",
        "End-to-end pipeline for RealityConstructAI:\n",
        "1. Synthetic dataset of 6 inputs → 3 targets\n",
        "2. Float32 normalization and dtype consistency\n",
        "3. MLP with LayerNorm, Dropout & ReLU\n",
        "4. Physics-informed residual enforcing toy universe laws\n",
        "5. MC-Dropout for uncertainty quantification\n",
        "6. Training loop with AdamW, ReduceLROnPlateau, gradient clipping, NaN checks, early stopping\n",
        "7. Safe checkpoint loading\n",
        "8. Visualizations: training history, true vs. predicted scatter, uncertainty map\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Universe Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class UniverseDataset(Dataset):\n",
        "    def __init__(self, n_samples=5000, seed=123):\n",
        "        np.random.seed(seed)\n",
        "        # Inputs in double precision\n",
        "        REX = np.random.uniform(0.5, 2.0, (n_samples,1))\n",
        "        SCL = np.random.rand(n_samples,1)\n",
        "        ENT = np.random.uniform(0.1, 5.0, (n_samples,1))\n",
        "        A   = np.random.uniform(-3, 3,     (n_samples,1))\n",
        "        B   = np.random.uniform(-3, 3,     (n_samples,1))\n",
        "        C   = np.random.uniform(-3, 3,     (n_samples,1))\n",
        "\n",
        "        X_raw = np.hstack([REX, SCL, ENT, A, B, C]).astype(np.float64)\n",
        "\n",
        "        # Toy universe laws\n",
        "        STAB = REX**2 / (1 + ENT)\n",
        "        SUST = np.exp(-A * B) * (1 + SCL)\n",
        "        EXP  = (SCL + C) * np.sqrt(REX)\n",
        "\n",
        "        Y_raw = np.hstack([STAB, SUST, EXP]).astype(np.float64)\n",
        "        Y_raw += 0.01 * Y_raw.std(axis=0) * np.random.randn(*Y_raw.shape)\n",
        "\n",
        "        # Compute normalization stats in float64\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0) + 1e-8\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0) + 1e-8\n",
        "\n",
        "        # Standardize and cast to float32\n",
        "        self.X = ((X_raw - self.X_mean) / self.X_std).astype(np.float32)\n",
        "        self.Y = ((Y_raw - self.Y_mean) / self.Y_std).astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. RealityConstructAI Model\n",
        "# ------------------------------------------------------------------------------\n",
        "class RealityConstructAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dims=(64,64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers, d = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers.extend([\n",
        "                nn.Linear(d, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ])\n",
        "            d = h\n",
        "        layers.append(nn.Linear(d, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Residual\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, X, stats):\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    REX, SCL, ENT, A, B, C = X_den.t()\n",
        "    STAB_t = REX**2 / (1 + ENT)\n",
        "    SUST_t = torch.exp(-A * B) * (1 + SCL)\n",
        "    EXP_t  = (SCL + C) * torch.sqrt(REX)\n",
        "\n",
        "    Yt = torch.stack([STAB_t, SUST_t, EXP_t], dim=1)\n",
        "    Yt_n = (Yt - stats['Y_mean']) / stats['Y_std']\n",
        "    return nn.MSELoss()(pred, Yt_n)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. Combined Loss Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def total_loss(pred, true, X, stats, λ=0.7):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, X, stats)\n",
        "    return mse + λ * phys, mse, phys\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. MC-Dropout Uncertainty\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    stack = torch.stack(preds)\n",
        "    return stack.mean(dim=0), stack.std(dim=0)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Training Loop with Safety & Checkpointing\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=3e-4, wd=1e-5, λ=0.7, epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train': [], 'val': []}\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        running_train = 0.0\n",
        "        for Xb, Yb in train_loader:\n",
        "            Xb, Yb = Xb.to(device), Yb.to(device)\n",
        "            pred = model(Xb)\n",
        "            loss, _, _ = total_loss(pred, Yb, Xb, stats, λ)\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"NaN loss at epoch {epoch}, aborting.\")\n",
        "                return history\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            running_train += loss.item() * Xb.size(0)\n",
        "        train_loss = running_train / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        running_val = 0.0\n",
        "        with torch.no_grad():\n",
        "            for Xv, Yv in val_loader:\n",
        "                Xv, Yv = Xv.to(device), Yv.to(device)\n",
        "                pred = model(Xv)\n",
        "                l, _, _ = total_loss(pred, Yv, Xv, stats, λ)\n",
        "                running_val += l.item() * Xv.size(0)\n",
        "        val_loss = running_val / len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        history['train'].append(train_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        print(f\"Epoch {epoch:03d} | Train {train_loss:.4e} | Val {val_loss:.4e}\")\n",
        "\n",
        "        # Checkpointing\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val, wait = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_reality_ai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    # Load best checkpoint\n",
        "    if os.path.exists(\"best_reality_ai.pth\"):\n",
        "        model.load_state_dict(\n",
        "            torch.load(\"best_reality_ai.pth\", map_location=device)\n",
        "        )\n",
        "    return history\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_history(history):\n",
        "    plt.figure()\n",
        "    plt.plot(history['train'], label='Train')\n",
        "    plt.plot(history['val'],   label='Val')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_scatter(true, pred, title):\n",
        "    plt.figure()\n",
        "    plt.scatter(true, pred, s=8, alpha=0.5)\n",
        "    mn, mx = true.min(), true.max()\n",
        "    plt.plot([mn, mx], [mn, mx], 'r--')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_uncertainty(model, stats, device):\n",
        "    G = 100\n",
        "    REX = np.linspace(0.5, 2.0, G, dtype=np.float32)\n",
        "    SCL = np.linspace(0, 1,   G, dtype=np.float32)\n",
        "    R, S = np.meshgrid(REX, SCL)\n",
        "    pts  = G * G\n",
        "\n",
        "    # create grid tensor\n",
        "    Xg = torch.zeros((pts, 6), device=device, dtype=torch.float32)\n",
        "\n",
        "    # columns 2–5: denormalized fixed means\n",
        "    # stats['X_mean'][2:] is already a Tensor on device\n",
        "    Xg[:, 2:] = stats['X_mean'][2:].unsqueeze(0).expand(pts, 4)\n",
        "\n",
        "    # columns 0–1: meshgrid values\n",
        "    Xg[:, 0]  = torch.from_numpy(R.ravel()).to(device)\n",
        "    Xg[:, 1]  = torch.from_numpy(S.ravel()).to(device)\n",
        "\n",
        "    # normalize entire grid\n",
        "    Xn = (Xg - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout(model, Xn, T=40)\n",
        "    U = std[:, 0].cpu().reshape(G, G)\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.pcolormesh(R, S, U, cmap='viridis', shading='auto')\n",
        "    plt.colorbar(label=\"Std(STAB)\")\n",
        "    plt.xlabel(\"REX\")\n",
        "    plt.ylabel(\"SCL\")\n",
        "    plt.title(\"Uncertainty: Stability\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 8. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare dataset and cast stats to float32 tensors on device\n",
        "    ds    = UniverseDataset(n_samples=5000, seed=123)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, dtype=torch.float32, device=device),\n",
        "        'X_std' : torch.tensor(ds.X_std,  dtype=torch.float32, device=device),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, dtype=torch.float32, device=device),\n",
        "        'Y_std' : torch.tensor(ds.Y_std,  dtype=torch.float32, device=device),\n",
        "    }\n",
        "\n",
        "    # Split into train/val\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    tr_ds, va_ds = random_split(ds, [len(ds)-n_val, n_val])\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=128, shuffle=True)\n",
        "    va_ld = DataLoader(va_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    # Build, train, and evaluate\n",
        "    model   = RealityConstructAI().to(device)\n",
        "    history = train(model, tr_ld, va_ld, stats, device)\n",
        "\n",
        "    # Plot training history\n",
        "    plot_history(history)\n",
        "\n",
        "    # Scatter: true vs. predicted\n",
        "    X_all = torch.from_numpy(ds.X).to(device)\n",
        "    with torch.no_grad():\n",
        "        Yp_norm = model(X_all).cpu().numpy()\n",
        "    Yt = ds.Y * ds.Y_std + ds.Y_mean\n",
        "    Yp = Yp_norm * ds.Y_std + ds.Y_mean\n",
        "\n",
        "    names = [\"Stability\", \"Sustainability\", \"Expansion Rate\"]\n",
        "    for i, nm in enumerate(names):\n",
        "        plot_scatter(Yt[:, i], Yp[:, i], nm)\n",
        "\n",
        "    # Plot uncertainty map\n",
        "    plot_uncertainty(model, stats, device)"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNu1T1NZQFH/9YdtL1dII8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/Reflective_Updater.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Callable, Iterable, Optional, Protocol, Tuple, List, Sequence, Iterator\n",
        "import logging\n",
        "import itertools\n",
        "import statistics\n",
        "\n",
        "\n",
        "# --- Protocols / lightweight contracts --------------------------------------\n",
        "\n",
        "class EpisodeLike(Protocol):\n",
        "    @property\n",
        "    def input(self) -> Any: ...\n",
        "    @property\n",
        "    def outcome(self) -> Any: ...\n",
        "\n",
        "\n",
        "class MemoryLike(Protocol):\n",
        "    def recent(self) -> Iterable[EpisodeLike]: ...\n",
        "    # Optional fast sampling/bounded retrieval (used if present)\n",
        "    def recent_n(self, n: int) -> Sequence[EpisodeLike]: ...\n",
        "\n",
        "\n",
        "class WorldModelLike(Protocol):\n",
        "    def simulate(self, x: Any) -> Any: ...\n",
        "    def update(self, contradictory: List[EpisodeLike]) -> None: ...\n",
        "    # Optional vectorized APIs\n",
        "    def batch_simulate(self, xs: Sequence[Any]) -> Sequence[Any]: ...\n",
        "    def batch_update(self, contradictory: Sequence[EpisodeLike]) -> None: ...\n",
        "\n",
        "\n",
        "class SelfModelLike(Protocol):\n",
        "    def adapt(self, contradictory: List[EpisodeLike]) -> None: ...\n",
        "\n",
        "\n",
        "class CurriculumScheduler(Protocol):\n",
        "    \"\"\"\n",
        "    Controls per-step threshold and which contradictions to use.\n",
        "    Implement any subset you need; defaults are provided by the updater.\n",
        "    \"\"\"\n",
        "    def decide_threshold(self, step: int, prev_report: Optional[\"TrainingReport\"]) -> Optional[float]: ...\n",
        "    def select(self, contradictions: List[\"Contradiction\"], step: int) -> List[\"Contradiction\"]: ...\n",
        "\n",
        "\n",
        "SimilarityFn = Callable[[Any, Any], float]\n",
        "\n",
        "\n",
        "# --- Data structures ---------------------------------------------------------\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Contradiction:\n",
        "    episode: EpisodeLike\n",
        "    prediction: Any\n",
        "    score: float\n",
        "    reason: str = \"score_below_threshold\"  # or \"simulate_error\" / \"similarity_error\"\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TrainingReport:\n",
        "    step: int\n",
        "    processed: int\n",
        "    contradictory: int\n",
        "    threshold: float\n",
        "    avg_score_all: Optional[float]\n",
        "    avg_score_contradictions: Optional[float]\n",
        "\n",
        "\n",
        "# --- Utilities ---------------------------------------------------------------\n",
        "\n",
        "def _chunked(seq: Sequence[Any], n: int) -> Iterator[Sequence[Any]]:\n",
        "    if n <= 0:\n",
        "        raise ValueError(\"batch_size must be > 0\")\n",
        "    for i in range(0, len(seq), n):\n",
        "        yield seq[i:i+n]\n",
        "\n",
        "\n",
        "def _take(iterable: Iterable[Any], limit: Optional[int]) -> List[Any]:\n",
        "    if limit is None:\n",
        "        return list(iterable)\n",
        "    return list(itertools.islice(iterable, int(limit)))\n",
        "\n",
        "\n",
        "# --- Implementation -----------------------------------------------------------\n",
        "\n",
        "class ReflectiveUpdater:\n",
        "    \"\"\"\n",
        "    Cross-check recent episodes against the world model; on contradiction,\n",
        "    update both the world and self models. Adds auditable detection, batching,\n",
        "    and curriculum-aware training.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    episodic_memory : MemoryLike\n",
        "        Provides recent() -> iterable of episodes with .input and .outcome.\n",
        "        If it implements recent_n(n), batching becomes more efficient.\n",
        "    world_model : WorldModelLike\n",
        "        Must implement simulate(x) and update(episodes).\n",
        "        If it implements batch_simulate/batch_update, those are used.\n",
        "    self_model : SelfModelLike\n",
        "        Must implement adapt(episodes).\n",
        "    similarity_fn : Callable[[pred, actual], float]\n",
        "        Returns a consistency score; higher means more similar.\n",
        "    threshold : float, default 0.8\n",
        "        Minimum score to consider pred and actual consistent (inclusive).\n",
        "    logger : logging.Logger, optional\n",
        "        For warnings/debugging; defaults to module logger.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        episodic_memory: MemoryLike,\n",
        "        world_model: WorldModelLike,\n",
        "        self_model: SelfModelLike,\n",
        "        similarity_fn: SimilarityFn,\n",
        "        *,\n",
        "        threshold: float = 0.8,\n",
        "        logger: Optional[logging.Logger] = None,\n",
        "    ) -> None:\n",
        "        self.memory = episodic_memory\n",
        "        self.world = world_model\n",
        "        self.self_model = self_model\n",
        "        self.similarity_fn = similarity_fn\n",
        "        self.threshold = float(threshold)\n",
        "        self.log = logger or logging.getLogger(__name__)\n",
        "        self.step: int = 0\n",
        "        self._last_report: Optional[TrainingReport] = None\n",
        "\n",
        "    # --- Basic consistency utilities ----------------------------------------\n",
        "\n",
        "    def consistency_score(self, pred: Any, actual: Any) -> float:\n",
        "        return float(self.similarity_fn(pred, actual))\n",
        "\n",
        "    def _is_consistent(self, pred: Any, actual: Any, *, threshold: Optional[float] = None) -> bool:\n",
        "        th = self.threshold if threshold is None else float(threshold)\n",
        "        return self.consistency_score(pred, actual) >= th\n",
        "\n",
        "    # --- Detection: simple and detailed -------------------------------------\n",
        "\n",
        "    def detect_contradictions(self, *, limit: Optional[int] = None, threshold: Optional[float] = None) -> Iterable[EpisodeLike]:\n",
        "        \"\"\"\n",
        "        Yield episodes whose predicted outcome is inconsistent with actual.\n",
        "        \"\"\"\n",
        "        th = self.threshold if threshold is None else float(threshold)\n",
        "        for episode in self._iter_recent(limit):\n",
        "            try:\n",
        "                prediction = self._simulate_one(episode.input)\n",
        "            except Exception as e:\n",
        "                self.log.warning(\"simulate() failed; treating as contradiction: %s\", e)\n",
        "                yield episode\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                if not self._is_consistent(prediction, episode.outcome, threshold=th):\n",
        "                    yield episode\n",
        "            except Exception as e:\n",
        "                self.log.warning(\"similarity check failed; treating as contradiction: %s\", e)\n",
        "                yield episode\n",
        "\n",
        "    def detect_contradictions_detailed(\n",
        "        self,\n",
        "        *,\n",
        "        limit: Optional[int] = None,\n",
        "        threshold: Optional[float] = None,\n",
        "        batch_size: Optional[int] = None,\n",
        "    ) -> List[Contradiction]:\n",
        "        \"\"\"\n",
        "        Return detailed contradictions with predictions and scores for audit.\n",
        "        Uses vectorized simulate if available; otherwise falls back to per-item.\n",
        "        \"\"\"\n",
        "        th = self.threshold if threshold is None else float(threshold)\n",
        "        episodes = self._collect_recent(limit)\n",
        "        if not episodes:\n",
        "            return []\n",
        "\n",
        "        # Try vectorized simulate\n",
        "        preds: List[Any]\n",
        "        try:\n",
        "            preds = self._simulate_many([e.input for e in episodes], batch_size=batch_size)\n",
        "        except Exception as e:\n",
        "            self.log.warning(\"batch simulate failed; falling back to itemwise: %s\", e)\n",
        "            preds = [self._simulate_one(e.input) for e in episodes]\n",
        "\n",
        "        contradictions: List[Contradiction] = []\n",
        "        for ep, pred in zip(episodes, preds):\n",
        "            try:\n",
        "                score = self.consistency_score(pred, ep.outcome)\n",
        "                if score < th:\n",
        "                    contradictions.append(Contradiction(ep, pred, score, reason=\"score_below_threshold\"))\n",
        "            except Exception as e:\n",
        "                self.log.warning(\"similarity check failed; marking contradiction: %s\", e)\n",
        "                contradictions.append(Contradiction(ep, pred, float(\"nan\"), reason=\"similarity_error\"))\n",
        "        return contradictions\n",
        "\n",
        "    # --- Revision: immediate and batched ------------------------------------\n",
        "\n",
        "    def revise_model(self) -> int:\n",
        "        \"\"\"\n",
        "        Collect contradictions and update world/self models.\n",
        "        Returns the number of contradictory episodes processed.\n",
        "        \"\"\"\n",
        "        contradictory = list(self.detect_contradictions())\n",
        "        if not contradictory:\n",
        "            self.log.debug(\"No contradictions detected.\")\n",
        "            return 0\n",
        "\n",
        "        self.log.debug(\"Updating with %d contradictory episodes.\", len(contradictory))\n",
        "        self._update_models(contradictory)\n",
        "        return len(contradictory)\n",
        "\n",
        "    def revise_model_batched(self, *, batch_size: int = 64, threshold: Optional[float] = None) -> int:\n",
        "        \"\"\"\n",
        "        Detect contradictions and update in batches for memory/latency control.\n",
        "        \"\"\"\n",
        "        th = self.threshold if threshold is None else float(threshold)\n",
        "        detailed = self.detect_contradictions_detailed(threshold=th, batch_size=batch_size)\n",
        "        if not detailed:\n",
        "            self.log.debug(\"No contradictions detected.\")\n",
        "            return 0\n",
        "        episodes = [c.episode for c in detailed]\n",
        "        self.log.debug(\"Batched update with %d contradictory episodes (batch_size=%d).\", len(episodes), batch_size)\n",
        "        self._update_models(episodes, batch_size=batch_size)\n",
        "        return len(episodes)\n",
        "\n",
        "    # --- Training step with curriculum --------------------------------------\n",
        "\n",
        "    def training_step(\n",
        "        self,\n",
        "        *,\n",
        "        max_episodes: int = 256,\n",
        "        batch_size: Optional[int] = None,\n",
        "        scheduler: Optional[CurriculumScheduler] = None,\n",
        "        threshold: Optional[float] = None,\n",
        "    ) -> TrainingReport:\n",
        "        \"\"\"\n",
        "        One training step:\n",
        "        1) Pull up to max_episodes recent episodes.\n",
        "        2) Compute predictions and scores (batched if available).\n",
        "        3) Apply threshold (from scheduler or argument or default).\n",
        "        4) Optionally let scheduler select a subset to update.\n",
        "        5) Update world/self (batched if requested).\n",
        "\n",
        "        Returns a TrainingReport with counts and averages.\n",
        "        \"\"\"\n",
        "        self.step += 1\n",
        "\n",
        "        # Decide threshold order: scheduler > arg > self.threshold\n",
        "        th_sched = scheduler.decide_threshold(self.step, self._last_report) if scheduler else None\n",
        "        th = self.threshold\n",
        "        if th_sched is not None:\n",
        "            th = float(th_sched)\n",
        "        elif threshold is not None:\n",
        "            th = float(threshold)\n",
        "\n",
        "        episodes = self._collect_recent(max_episodes)\n",
        "        if not episodes:\n",
        "            report = TrainingReport(self.step, 0, 0, th, None, None)\n",
        "            self._last_report = report\n",
        "            return report\n",
        "\n",
        "        # Predict (try batch)\n",
        "        try:\n",
        "            preds = self._simulate_many([e.input for e in episodes], batch_size=batch_size)\n",
        "        except Exception as e:\n",
        "            self.log.warning(\"batch simulate failed; falling back to itemwise: %s\", e)\n",
        "            preds = [self._simulate_one(e.input) for e in episodes]\n",
        "\n",
        "        scores: List[float] = []\n",
        "        contradictions: List[Contradiction] = []\n",
        "        for ep, pred in zip(episodes, preds):\n",
        "            try:\n",
        "                s = self.consistency_score(pred, ep.outcome)\n",
        "                scores.append(s)\n",
        "                if s < th:\n",
        "                    contradictions.append(Contradiction(ep, pred, s, reason=\"score_below_threshold\"))\n",
        "            except Exception as e:\n",
        "                self.log.warning(\"similarity check failed; marking contradiction: %s\", e)\n",
        "                contradictions.append(Contradiction(ep, pred, float(\"nan\"), reason=\"similarity_error\"))\n",
        "\n",
        "        # Curriculum selection\n",
        "        use_contras = contradictions\n",
        "        if scheduler and hasattr(scheduler, \"select\"):\n",
        "            try:\n",
        "                use_contras = scheduler.select(contradictions, self.step)  # type: ignore[attr-defined]\n",
        "            except Exception as e:\n",
        "                self.log.warning(\"scheduler.select failed; using all contradictions: %s\", e)\n",
        "\n",
        "        # Update models\n",
        "        if use_contras:\n",
        "            self._update_models([c.episode for c in use_contras], batch_size=batch_size)\n",
        "\n",
        "        avg_all = statistics.fmean(scores) if scores else None\n",
        "        only_scores = [c.score for c in use_contras if c.score == c.score]  # filter NaN\n",
        "        avg_contra = statistics.fmean(only_scores) if only_scores else None\n",
        "\n",
        "        report = TrainingReport(\n",
        "            step=self.step,\n",
        "            processed=len(episodes),\n",
        "            contradictory=len(use_contras),\n",
        "            threshold=th,\n",
        "            avg_score_all=avg_all,\n",
        "            avg_score_contradictions=avg_contra,\n",
        "        )\n",
        "        self._last_report = report\n",
        "        return report\n",
        "\n",
        "    # --- Internals: recent collection, simulate, update ---------------------\n",
        "\n",
        "    def _iter_recent(self, limit: Optional[int]) -> Iterable[EpisodeLike]:\n",
        "        # Prefer recent_n if available for efficiency\n",
        "        if limit is not None and hasattr(self.memory, \"recent_n\"):\n",
        "            try:\n",
        "                seq = self.memory.recent_n(int(limit))  # type: ignore[attr-defined]\n",
        "                return seq\n",
        "            except Exception:\n",
        "                pass\n",
        "        return _take(self.memory.recent(), limit)\n",
        "\n",
        "    def _collect_recent(self, limit: Optional[int]) -> List[EpisodeLike]:\n",
        "        recent = self._iter_recent(limit)\n",
        "        return list(recent) if not isinstance(recent, list) else recent\n",
        "\n",
        "    def _simulate_one(self, x: Any) -> Any:\n",
        "        return self.world.simulate(x)\n",
        "\n",
        "    def _simulate_many(self, xs: Sequence[Any], *, batch_size: Optional[int]) -> List[Any]:\n",
        "        # If world has batch_simulate, prefer it with optional chunking\n",
        "        if hasattr(self.world, \"batch_simulate\"):\n",
        "            bs = int(batch_size) if batch_size else len(xs)\n",
        "            preds: List[Any] = []\n",
        "            for chunk in _chunked(list(xs), bs):\n",
        "                part = self.world.batch_simulate(chunk)  # type: ignore[attr-defined]\n",
        "                preds.extend(list(part))\n",
        "            return preds\n",
        "        # Fallback itemwise\n",
        "        return [self.world.simulate(x) for x in xs]\n",
        "\n",
        "    def _update_models(self, episodes: Sequence[EpisodeLike], *, batch_size: Optional[int] = None) -> None:\n",
        "        # World model update: prefer batch_update if available; otherwise chunked calls to update\n",
        "        if hasattr(self.world, \"batch_update\"):\n",
        "            if batch_size and batch_size > 0 and batch_size < len(episodes):\n",
        "                for chunk in _chunked(list(episodes), int(batch_size)):\n",
        "                    self.world.batch_update(chunk)  # type: ignore[attr-defined]\n",
        "            else:\n",
        "                self.world.batch_update(episodes)  # type: ignore[attr-defined]\n",
        "        else:\n",
        "            # Fallback to update() expecting a list\n",
        "            if batch_size and batch_size > 0 and batch_size < len(episodes):\n",
        "                for chunk in _chunked(list(episodes), int(batch_size)):\n",
        "                    self.world.update(list(chunk))\n",
        "            else:\n",
        "                self.world.update(list(episodes))\n",
        "        # Self model always takes a list\n",
        "        self.self_model.adapt(list(episodes))\n",
        "\n",
        "class LinearThresholdScheduler:\n",
        "    \"\"\"\n",
        "    Linearly increase threshold from start -> end over total_steps.\n",
        "    Also selects the hardest half of contradictions (lowest scores).\n",
        "    \"\"\"\n",
        "    def __init__(self, start: float = 0.6, end: float = 0.95, total_steps: int = 100):\n",
        "        self.start = float(start)\n",
        "        self.end = float(end)\n",
        "        self.total_steps = int(total_steps)\n",
        "\n",
        "    def decide_threshold(self, step: int, prev_report: Optional[TrainingReport]) -> Optional[float]:\n",
        "        t = max(1, min(step, self.total_steps))\n",
        "        alpha = (t - 1) / max(1, self.total_steps - 1)\n",
        "        return (1 - alpha) * self.start + alpha * self.end\n",
        "\n",
        "    def select(self, contradictions: List[Contradiction], step: int) -> List[Contradiction]:\n",
        "        if not contradictions:\n",
        "            return []\n",
        "        # Keep the harder half (lower scores first, NaN treated as hardest)\n",
        "        def key(c: Contradiction) -> float:\n",
        "            return c.score if c.score == c.score else -1.0  # NaN -> -1 to sort first\n",
        "        sorted_cs = sorted(contradictions, key=key)\n",
        "        k = max(1, len(sorted_cs) // 2)\n",
        "        return sorted_cs[:k]\n",
        "\n",
        "# 1. Dummy episode format\n",
        "@dataclass\n",
        "class Episode:\n",
        "    input: str\n",
        "    outcome: str\n",
        "\n",
        "# 2. Dummy memory\n",
        "class DummyMemory:\n",
        "    def recent(self) -> Iterable[Episode]:\n",
        "        return [\n",
        "            Episode(\"A\", \"outcome1\"),\n",
        "            Episode(\"B\", \"outcome2\"),\n",
        "            Episode(\"C\", \"outcome3\"),\n",
        "        ]\n",
        "\n",
        "# 3. Dummy world model\n",
        "class DummyWorldModel:\n",
        "    def simulate(self, x: Any) -> str:\n",
        "        return {\n",
        "            \"A\": \"outcome1\",       # correct\n",
        "            \"B\": \"wrong_outcome\",  # incorrect\n",
        "            \"C\": \"outcome3\"        # correct\n",
        "        }.get(x, \"unknown\")\n",
        "\n",
        "    def update(self, contradictory: List[Episode]) -> None:\n",
        "        print(f\"[WorldModel] Updated with: {[e.input for e in contradictory]}\")\n",
        "\n",
        "# 4. Dummy self model\n",
        "class DummySelfModel:\n",
        "    def adapt(self, contradictory: List[Episode]) -> None:\n",
        "        print(f\"[SelfModel] Adapted from: {[e.input for e in contradictory]}\")\n",
        "\n",
        "# 5. Similarity function\n",
        "def basic_similarity(a: str, b: str) -> float:\n",
        "    return 1.0 if a == b else 0.0\n",
        "\n",
        "# 6. Instantiate the updater\n",
        "updater = ReflectiveUpdater(\n",
        "    episodic_memory=DummyMemory(),\n",
        "    world_model=DummyWorldModel(),\n",
        "    self_model=DummySelfModel(),\n",
        "    similarity_fn=basic_similarity,\n",
        "    threshold=0.8\n",
        ")\n",
        "\n",
        "# 7. Run audited contradiction detection\n",
        "contradictions = list(updater.detect_contradictions_detailed(limit=512, batch_size=128))\n",
        "for c in contradictions:\n",
        "    print(f\"[Contradiction] Input={c.episode.input} → Pred={c.prediction}, Actual={c.episode.outcome}, Score={c.score}\")\n",
        "\n",
        "# 8. Run batched model revision\n",
        "n = updater.revise_model_batched(batch_size=128)\n",
        "print(f\"[Revision] Contradictions processed: {n}\")\n",
        "\n",
        "# 9. Curriculum training with linear threshold ramp\n",
        "sched = LinearThresholdScheduler(start=0.7, end=0.95, total_steps=50)\n",
        "report = updater.training_step(max_episodes=512, batch_size=128, scheduler=sched)\n",
        "\n",
        "# 10. Report summary\n",
        "print(f\"[Training Report] Step={report.step}, Processed={report.processed}, \"\n",
        "      f\"Contradictory={report.contradictory}, Threshold={report.threshold}, \"\n",
        "      f\"Avg All={report.avg_score_all}, Avg Contra={report.avg_score_contradictions}\")"
      ],
      "metadata": {
        "id": "fUi6icf9D9ra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
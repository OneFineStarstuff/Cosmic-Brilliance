{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOZge+nWi8lD3c5ELMH91pa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/unified_ai_secure_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmpGtvXxoMI7"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# unified_ai_secure.py\n",
        "# Runs: NLP QA, Image Captioning, Symbolic Reasoning, RL (Q-learning) -> collects results\n",
        "# Packages artifacts -> encrypts with passphrase. Also supports decryption.\n",
        "\n",
        "import argparse\n",
        "import base64\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import tarfile\n",
        "from dataclasses import dataclass, asdict\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# ---------- Optional deps ----------\n",
        "try:\n",
        "    from transformers import pipeline as hf_pipeline  # type: ignore\n",
        "    HF_OK = True\n",
        "except Exception as e:\n",
        "    HF_OK = False\n",
        "\n",
        "try:\n",
        "    from PIL import Image  # type: ignore\n",
        "    PIL_OK = True\n",
        "except Exception:\n",
        "    PIL_OK = False\n",
        "\n",
        "try:\n",
        "    import requests  # type: ignore\n",
        "    REQUESTS_OK = True\n",
        "except Exception:\n",
        "    REQUESTS_OK = False\n",
        "\n",
        "# RL env: prefer gymnasium; fallback to gym\n",
        "GYM_API = None\n",
        "try:\n",
        "    import gymnasium as gym  # type: ignore\n",
        "    GYM_API = \"gymnasium\"\n",
        "except Exception:\n",
        "    try:\n",
        "        import gym  # type: ignore\n",
        "        GYM_API = \"gym\"\n",
        "    except Exception:\n",
        "        GYM_API = None\n",
        "\n",
        "# Crypto\n",
        "try:\n",
        "    from cryptography.hazmat.primitives import hashes  # type: ignore\n",
        "    from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC  # type: ignore\n",
        "    from cryptography.fernet import Fernet  # type: ignore\n",
        "    CRYPTO_OK = True\n",
        "except Exception:\n",
        "    CRYPTO_OK = False\n",
        "\n",
        "# ---------- Data structures ----------\n",
        "@dataclass\n",
        "class NLPResult:\n",
        "    question: str\n",
        "    answer: Optional[str]\n",
        "    error: Optional[str]\n",
        "\n",
        "@dataclass\n",
        "class VisionResult:\n",
        "    source: str\n",
        "    caption: Optional[str]\n",
        "    error: Optional[str]\n",
        "\n",
        "@dataclass\n",
        "class ReasoningResult:\n",
        "    premises: List[str]\n",
        "    query: str\n",
        "    entailed: bool\n",
        "\n",
        "@dataclass\n",
        "class RLLog:\n",
        "    env: str\n",
        "    steps: int\n",
        "    total_reward: float\n",
        "    episode_terminated: bool\n",
        "    episode_truncated: bool\n",
        "    notes: str\n",
        "\n",
        "@dataclass\n",
        "class RunSummary:\n",
        "    timestamp_utc: str\n",
        "    seed: int\n",
        "    nlp: NLPResult\n",
        "    vision: VisionResult\n",
        "    reasoning: ReasoningResult\n",
        "    rl: RLLog\n",
        "    notes: List[str]\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def ensure_dir(p: Path) -> None:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def utcnow() -> str:\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "# ---------- NLP: QA ----------\n",
        "def run_qa(context: str, question: str) -> NLPResult:\n",
        "    if not HF_OK:\n",
        "        return NLPResult(question, None, \"transformers not available\")\n",
        "    try:\n",
        "        qa = hf_pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "        out = qa(question=question, context=context)\n",
        "        return NLPResult(question, out.get(\"answer\"), None)\n",
        "    except Exception as e:\n",
        "        return NLPResult(question, None, f\"{type(e).__name__}: {e}\")\n",
        "\n",
        "# ---------- Vision: BLIP caption ----------\n",
        "def load_image_from_source(source: str) -> Image.Image:\n",
        "    if source.startswith(\"http://\") or source.startswith(\"https://\"):\n",
        "        if not REQUESTS_OK:\n",
        "            raise RuntimeError(\"requests not available to fetch URL\")\n",
        "        resp = requests.get(source, timeout=30)\n",
        "        resp.raise_for_status()\n",
        "        from io import BytesIO\n",
        "        return Image.open(BytesIO(resp.content)).convert(\"RGB\")\n",
        "    # Local path\n",
        "    if not PIL_OK:\n",
        "        raise RuntimeError(\"Pillow not available to open local image\")\n",
        "    return Image.open(source).convert(\"RGB\")\n",
        "\n",
        "def run_caption(image_source: Optional[str]) -> VisionResult:\n",
        "    if image_source is None:\n",
        "        return VisionResult(source=\"(none)\", caption=None, error=\"no image source provided\")\n",
        "    if not HF_OK:\n",
        "        return VisionResult(image_source, None, \"transformers not available\")\n",
        "    try:\n",
        "        image = load_image_from_source(image_source)\n",
        "        cap = hf_pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
        "        res = cap(image)\n",
        "        caption = res[0].get(\"generated_text\") if res else None\n",
        "        return VisionResult(image_source, caption, None)\n",
        "    except Exception as e:\n",
        "        return VisionResult(image_source, None, f\"{type(e).__name__}: {e}\")\n",
        "\n",
        "# ---------- Symbolic reasoning (very simple syllogism) ----------\n",
        "# Supports forms like: \"all humans are mortal\", \"Socrates is human\" -> query \"Socrates is mortal\"\n",
        "def normalize_text(s: str) -> str:\n",
        "    return \" \".join(s.strip().lower().split())\n",
        "\n",
        "def parse_all_are(p: str) -> Optional[Tuple[str, str]]:\n",
        "    # \"all X are Y\" -> (X, Y)\n",
        "    p = normalize_text(p)\n",
        "    if not p.startswith(\"all \") or \" are \" not in p:\n",
        "        return None\n",
        "    core = p[4:]\n",
        "    parts = core.split(\" are \")\n",
        "    if len(parts) != 2:\n",
        "        return None\n",
        "    return parts[0].strip(), parts[1].strip()\n",
        "\n",
        "def parse_is(p: str) -> Optional[Tuple[str, str]]:\n",
        "    # \"a is b\" -> (a, b)\n",
        "    p = normalize_text(p)\n",
        "    if \" is \" not in p:\n",
        "        return None\n",
        "    parts = p.split(\" is \")\n",
        "    if len(parts) != 2:\n",
        "        return None\n",
        "    return parts[0].strip(), parts[1].strip()\n",
        "\n",
        "def run_reasoning(premises: List[str], query: str) -> ReasoningResult:\n",
        "    alls: List[Tuple[str, str]] = []\n",
        "    facts: List[Tuple[str, str]] = []\n",
        "    for pr in premises:\n",
        "        aa = parse_all_are(pr)\n",
        "        if aa:\n",
        "            alls.append(aa)\n",
        "            continue\n",
        "        ii = parse_is(pr)\n",
        "        if ii:\n",
        "            facts.append(ii)\n",
        "    q = parse_is(query)\n",
        "    entailed = False\n",
        "    if q:\n",
        "        a, b = q\n",
        "        # If a is X and all X are b -> a is b\n",
        "        xs = [x for (subj, x) in facts if subj == a]\n",
        "        implied: List[str] = []\n",
        "        for x in xs:\n",
        "            implied += [B for (X, B) in alls if X == x]\n",
        "        entailed = b in implied or (a, b) in facts\n",
        "    return ReasoningResult(premises=premises, query=query, entailed=entailed)\n",
        "\n",
        "# ---------- RL: Q-learning ----------\n",
        "class QLearningAgent:\n",
        "    def __init__(self, actions: List[int], lr=0.1, gamma=0.99, epsilon=0.1):\n",
        "        self.actions = actions\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.q: Dict[str, Dict[int, float]] = {}\n",
        "\n",
        "    def _ensure_state(self, s: Any):\n",
        "        key = str(s)\n",
        "        if key not in self.q:\n",
        "            self.q[key] = {a: 0.0 for a in self.actions}\n",
        "        return key\n",
        "\n",
        "    def act(self, state: Any, rng: np.random.Generator) -> int:\n",
        "        if rng.random() < self.epsilon:\n",
        "            return int(rng.choice(self.actions))\n",
        "        key = self._ensure_state(state)\n",
        "        return max(self.q[key], key=self.q[key].get)\n",
        "\n",
        "    def update(self, s: Any, a: int, r: float, s2: Any):\n",
        "        ks = self._ensure_state(s)\n",
        "        ks2 = self._ensure_state(s2)\n",
        "        qsa = self.q[ks][a]\n",
        "        max_next = max(self.q[ks2].values())\n",
        "        self.q[ks][a] = qsa + self.lr * (r + self.gamma * max_next - qsa)\n",
        "\n",
        "def make_env(seed: int = 7):\n",
        "    if GYM_API == \"gymnasium\":\n",
        "        env = gym.make(\"FrozenLake-v1\", is_slippery=True)\n",
        "        obs, info = env.reset(seed=seed)\n",
        "        return env, \"gymnasium\", obs\n",
        "    elif GYM_API == \"gym\":\n",
        "        env = gym.make(\"FrozenLake-v1\", is_slippery=True)\n",
        "        try:\n",
        "            obs = env.reset(seed=seed)\n",
        "        except TypeError:\n",
        "            obs = env.reset()\n",
        "        return env, \"gym\", obs\n",
        "    else:\n",
        "        return None, None, None\n",
        "\n",
        "def step_env(env, api: str, action: int):\n",
        "    if api == \"gymnasium\":\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        done = bool(terminated or truncated)\n",
        "        return obs, float(reward), done, bool(terminated), bool(truncated)\n",
        "    else:\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        return obs, float(reward), bool(done), bool(done), False\n",
        "\n",
        "def run_rl_episode(max_steps=50, seed=7) -> RLLog:\n",
        "    env, api, obs = make_env(seed=seed)\n",
        "    if env is None:\n",
        "        return RLLog(env=\"(unavailable)\", steps=0, total_reward=0.0,\n",
        "                     episode_terminated=False, episode_truncated=False,\n",
        "                     notes=\"gym/gymnasium not available\")\n",
        "    rng = np.random.default_rng(seed)\n",
        "    agent = QLearningAgent(actions=[0, 1, 2, 3], lr=0.2, gamma=0.95, epsilon=0.2)\n",
        "    total_reward = 0.0\n",
        "    steps = 0\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "    state = obs\n",
        "    for t in range(max_steps):\n",
        "        act = agent.act(state, rng)\n",
        "        next_state, reward, done, term, trunc = step_env(env, api, act)\n",
        "        agent.update(state, act, reward, next_state)\n",
        "        total_reward += reward\n",
        "        steps = t + 1\n",
        "        state = next_state\n",
        "        if done:\n",
        "            terminated, truncated = term, trunc\n",
        "            break\n",
        "    try:\n",
        "        env.close()\n",
        "    except Exception:\n",
        "        pass\n",
        "    return RLLog(env=f\"FrozenLake-v1 ({api})\", steps=steps, total_reward=total_reward,\n",
        "                 episode_terminated=terminated, episode_truncated=truncated,\n",
        "                 notes=\"Single-episode demo with tabular Q-learning\")\n",
        "\n",
        "# ---------- Encryption packaging ----------\n",
        "def derive_key(passphrase: str, salt: bytes) -> bytes:\n",
        "    kdf = PBKDF2HMAC(algorithm=hashes.SHA256(), length=32, salt=salt, iterations=390000)\n",
        "    key = kdf.derive(passphrase.encode(\"utf-8\"))\n",
        "    return base64.urlsafe_b64encode(key)\n",
        "\n",
        "def encrypt_bytes(payload: bytes, passphrase: str) -> Dict[str, str]:\n",
        "    if not CRYPTO_OK:\n",
        "        raise RuntimeError(\"cryptography not installed. pip install cryptography\")\n",
        "    import secrets\n",
        "    salt = secrets.token_bytes(16)\n",
        "    fkey = derive_key(passphrase, salt)\n",
        "    token = Fernet(fkey).encrypt(payload)\n",
        "    return {\n",
        "        \"format\": \"unified.ai.enc.v1\",\n",
        "        \"salt_b64\": base64.urlsafe_b64encode(salt).decode(\"ascii\"),\n",
        "        \"token_b64\": base64.urlsafe_b64encode(token).decode(\"ascii\"),\n",
        "        \"created_utc\": utcnow()\n",
        "    }\n",
        "\n",
        "def decrypt_bytes(obj: Dict[str, str], passphrase: str) -> bytes:\n",
        "    if not CRYPTO_OK:\n",
        "        raise RuntimeError(\"cryptography not installed. pip install cryptography\")\n",
        "    if obj.get(\"format\") != \"unified.ai.enc.v1\":\n",
        "        raise ValueError(\"Unsupported format\")\n",
        "    salt = base64.urlsafe_b64decode(obj[\"salt_b64\"].encode(\"ascii\"))\n",
        "    token = base64.urlsafe_b64decode(obj[\"token_b64\"].encode(\"ascii\"))\n",
        "    key = derive_key(passphrase, salt)\n",
        "    return Fernet(key).decrypt(token)\n",
        "\n",
        "def tar_dir_to_bytes(root: Path) -> bytes:\n",
        "    buf = io.BytesIO()\n",
        "    with tarfile.open(fileobj=buf, mode=\"w:gz\") as tf:\n",
        "        for dirpath, _, filenames in os.walk(root):\n",
        "            for fname in filenames:\n",
        "                full = Path(dirpath) / fname\n",
        "                arc = full.relative_to(root)\n",
        "                tf.add(full, arcname=str(arc))\n",
        "    buf.seek(0)\n",
        "    return buf.read()\n",
        "\n",
        "def extract_tar_bytes(payload: bytes, outdir: Path) -> None:\n",
        "    with tarfile.open(fileobj=io.BytesIO(payload), mode=\"r:gz\") as tf:\n",
        "        tf.extractall(path=outdir)\n",
        "\n",
        "# ---------- Pipeline ----------\n",
        "def run_pipeline(workdir: Path,\n",
        "                 image_source: Optional[str],\n",
        "                 seed: int) -> Tuple[Path, RunSummary]:\n",
        "    ensure_dir(workdir)\n",
        "    artifacts = workdir / f\"artifacts_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}\"\n",
        "    ensure_dir(artifacts)\n",
        "\n",
        "    notes: List[str] = []\n",
        "\n",
        "    # NLP\n",
        "    context = \"France is a country in Western Europe. Its capital, Paris, is known for art and culture.\"\n",
        "    question = \"What is the capital of France?\"\n",
        "    nlp_res = run_qa(context, question)\n",
        "    if nlp_res.error:\n",
        "        notes.append(f\"NLP skipped/error: {nlp_res.error}\")\n",
        "\n",
        "    # Vision\n",
        "    vis_res = run_caption(image_source)\n",
        "    if vis_res.error:\n",
        "        notes.append(f\"Vision skipped/error: {vis_res.error}\")\n",
        "\n",
        "    # Reasoning\n",
        "    premises = [\"all humans are mortal\", \"Socrates is human\"]\n",
        "    query = \"Socrates is mortal\"\n",
        "    reason_res = run_reasoning(premises, query)\n",
        "\n",
        "    # RL\n",
        "    rl_res = run_rl_episode(max_steps=50, seed=seed)\n",
        "    if \"unavailable\" in rl_res.env:\n",
        "        notes.append(\"RL skipped: gym/gymnasium not available\")\n",
        "\n",
        "    summary = RunSummary(\n",
        "        timestamp_utc=utcnow(),\n",
        "        seed=seed,\n",
        "        nlp=nlp_res,\n",
        "        vision=vis_res,\n",
        "        reasoning=reason_res,\n",
        "        rl=rl_res,\n",
        "        notes=notes\n",
        "    )\n",
        "\n",
        "    # Save JSON result\n",
        "    (artifacts / \"results.json\").write_text(json.dumps(asdict(summary), indent=2))\n",
        "    # Lightweight README\n",
        "    (artifacts / \"README.txt\").write_text(\n",
        "        \"Unified AI run results. Contains results.json with outputs for NLP, vision, reasoning, and RL.\\n\"\n",
        "    )\n",
        "    return artifacts, summary\n",
        "\n",
        "def encrypt_artifacts(artifacts_dir: Path, passphrase: str, out_path: Path) -> Path:\n",
        "    payload = tar_dir_to_bytes(artifacts_dir)\n",
        "    enc = encrypt_bytes(payload, passphrase)\n",
        "    out_path.write_text(json.dumps(enc, indent=2))\n",
        "    # Write a helper README in the artifacts dir\n",
        "    (artifacts_dir / \"ENCRYPTION_README.txt\").write_text(\n",
        "        f\"Encrypted package created at: {out_path}\\n\"\n",
        "        f\"Decrypt with:\\n\"\n",
        "        f\"  python unified_ai_secure.py --decrypt --encrypted \\\"{out_path}\\\" \"\n",
        "        f\"--passphrase \\\"YOUR-PASSPHRASE\\\" --outdir \\\"./decrypted\\\"\\n\"\n",
        "    )\n",
        "    return out_path\n",
        "\n",
        "def decrypt_package(enc_path: Path, passphrase: str, outdir: Path) -> None:\n",
        "    obj = json.loads(enc_path.read_text())\n",
        "    payload = decrypt_bytes(obj, passphrase)\n",
        "    outdir.mkdir(parents=True, exist_ok=True)\n",
        "    extract_tar_bytes(payload, outdir)\n",
        "    (outdir / \"DECRYPT_OK.txt\").write_text(\"Decryption successful.\\n\")\n",
        "\n",
        "# ---------- CLI ----------\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"Unified AI system with encryption (NLP, Vision, Reasoning, RL)\")\n",
        "    ap.add_argument(\"--workdir\", type=Path, default=Path(\"/mnt/data/unified_ai\"))\n",
        "    ap.add_argument(\"--run-all\", action=\"store_true\", help=\"Run all modules and package artifacts\")\n",
        "    ap.add_argument(\"--image\", type=str, default=None, help=\"Image URL or local path for captioning\")\n",
        "    ap.add_argument(\"--seed\", type=int, default=7, help=\"Seed for RL and stochastic choices\")\n",
        "    ap.add_argument(\"--passphrase\", type=str, default=None, help=\"Passphrase for encryption/decryption\")\n",
        "    ap.add_argument(\"--decrypt\", action=\"store_true\", help=\"Decrypt an encrypted package\")\n",
        "    ap.add_argument(\"--encrypted\", type=Path, help=\"Path to encrypted .enc.json\")\n",
        "    ap.add_argument(\"--outdir\", type=Path, help=\"Directory to extract decrypted contents\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    if args.decrypt:\n",
        "        if not args.passphrase:\n",
        "            raise SystemExit(\"ERROR: --passphrase is required for --decrypt\")\n",
        "        if not args.encrypted:\n",
        "            raise SystemExit(\"ERROR: --encrypted path is required for --decrypt\")\n",
        "        outdir = args.outdir or (args.workdir / \"decrypted\")\n",
        "        decrypt_package(args.encrypted, args.passphrase, outdir)\n",
        "        print(f\"[OK] Decrypted to: {outdir}\")\n",
        "        return\n",
        "\n",
        "    if args.run_all:\n",
        "        artifacts, summary = run_pipeline(args.workdir, args.image, args.seed)\n",
        "        if args.passphrase:\n",
        "            enc_out = args.workdir / \"ua_artifacts.enc.json\"\n",
        "            encrypt_artifacts(artifacts, args.passphrase, enc_out)\n",
        "            print(f\"[OK] Encrypted package: {enc_out}\")\n",
        "        else:\n",
        "            print(\"[NOTE] No passphrase provided; artifacts left unencrypted.\")\n",
        "        print(f\"[OK] Artifacts directory: {artifacts}\")\n",
        "        # Friendly echo of key results\n",
        "        print(\"--- Summary ---\")\n",
        "        print(f\"NLP: {summary.nlp.answer or summary.nlp.error}\")\n",
        "        print(f\"Vision: {summary.vision.caption or summary.vision.error}\")\n",
        "        print(f\"Reasoning: {summary.reasoning.query} -> {summary.reasoning.entailed}\")\n",
        "        print(f\"RL: reward={summary.rl.total_reward:.2f}, steps={summary.rl.steps}, env={summary.rl.env}\")\n",
        "        return\n",
        "\n",
        "    ap.print_help()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}
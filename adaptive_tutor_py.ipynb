{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMh6tkJVvijWzdVIDUacgzh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/adaptive_tutor_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCjcP91eileK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "adaptive_tutor.py\n",
        "\n",
        "Dataclass + helper functions for adaptive question generation and topic selection.\n",
        "Replace `generate_question` and `expected_curiosity_gain` with your actual logic.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class StudentProfile:\n",
        "    \"\"\"\n",
        "    Represents a student and their learning preferences/state.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    name : str\n",
        "        Student's name.\n",
        "    topic_mastery : dict[str, float]\n",
        "        Mapping of topic -> mastery level (0.0 to 1.0).\n",
        "    preferred_bloom_level : str\n",
        "        Target Bloom taxonomy level for questions (e.g., \"application\").\n",
        "    novelty_tolerance : float\n",
        "        Desired novelty level (0.0–1.0).\n",
        "    engagement_history : list[dict]\n",
        "        Record of previous interactions, Q/A metrics, etc.\n",
        "    \"\"\"\n",
        "    name: str\n",
        "    topic_mastery: Dict[str, float]\n",
        "    preferred_bloom_level: str\n",
        "    novelty_tolerance: float\n",
        "    engagement_history: List[Dict]\n",
        "\n",
        "\n",
        "def generate_question(prompt: str, topic: str) -> str:\n",
        "    \"\"\"\n",
        "    Stub: Generate an open‑ended question given a prompt and topic.\n",
        "\n",
        "    Replace with actual LLM or question‑generation pipeline.\n",
        "    \"\"\"\n",
        "    # Placeholder logic for demonstration:\n",
        "    return f\"[Q on {topic} at {prompt}] How does {topic} apply in real‑world scenarios?\"\n",
        "\n",
        "\n",
        "def expected_curiosity_gain(topic: str, history: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    Stub: Estimate the expected curiosity gain for a topic given history.\n",
        "\n",
        "    Replace with actual curiosity/novelty scoring function.\n",
        "    \"\"\"\n",
        "    # Example: random score penalized if topic already in history\n",
        "    base = random.random()\n",
        "    penalty = 0.3 if topic in history else 0.0\n",
        "    return base - penalty\n",
        "\n",
        "\n",
        "def generate_adaptive_question(student: StudentProfile, topic: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate an adaptive question tailored to the student's profile and topic.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are a tutor. {student.name} is learning {topic}. \"\n",
        "        f\"Generate an open‑ended question at Bloom level {student.preferred_bloom_level}, \"\n",
        "        f\"with novelty calibrated to {student.novelty_tolerance}.\"\n",
        "    )\n",
        "    return generate_question(prompt, topic)\n",
        "\n",
        "\n",
        "def choose_next_topic(current_history: List[str], topics: List[str]) -> str:\n",
        "    \"\"\"\n",
        "    Choose the next topic based on highest expected curiosity gain.\n",
        "    \"\"\"\n",
        "    scores = [expected_curiosity_gain(t, current_history) for t in topics]\n",
        "    best_idx = int(np.argmax(scores))\n",
        "    return topics[best_idx]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    student = StudentProfile(\n",
        "        name=\"Kyaw\",\n",
        "        topic_mastery={\"thermodynamics\": 0.7, \"quantum_mechanics\": 0.5},\n",
        "        preferred_bloom_level=\"application\",\n",
        "        novelty_tolerance=0.8,\n",
        "        engagement_history=[]\n",
        "    )\n",
        "\n",
        "    topic = \"thermodynamics\"\n",
        "    question = generate_adaptive_question(student, topic)\n",
        "    print(\"Generated Question:\")\n",
        "    print(question)\n",
        "\n",
        "    history = [\"thermodynamics\"]\n",
        "    topics = [\"thermodynamics\", \"quantum_mechanics\", \"statistical_mechanics\"]\n",
        "    next_topic = choose_next_topic(history, topics)\n",
        "    print(\"\\nNext Suggested Topic:\")\n",
        "    print(next_topic)"
      ]
    }
  ]
}
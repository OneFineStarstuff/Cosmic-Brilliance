{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMGz3YMaDHtRwHXSIFpE29C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_planetary_ai_full_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldLxatPtyqdx"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_planetary_ai_full.py\n",
        "\n",
        "Complete pipeline for PlanetaryAI with uncertainty quantification:\n",
        "1. Synthetic “planetary” dataset of 6 inputs → 3 outputs\n",
        "2. Standardization, noise injection\n",
        "3. MLP with residual head & dropout\n",
        "4. Training loop with gradient clipping, LR scheduler, checkpointing\n",
        "5. Validation and loss reporting\n",
        "6. MC-Dropout inference for uncertainty quantification\n",
        "7. Heatmap of uncertainty over ICL vs. PRA\n",
        "8. Scatter plots of true vs. predicted\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Planetary Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class PlanetaryDataset(Dataset):\n",
        "    def __init__(self, n_samples=5000, seed=42):\n",
        "        torch.manual_seed(seed)\n",
        "        data = torch.rand(n_samples, 6)  # CNS, CER, ICL, PRA, ECI, CDF\n",
        "        CNS, CER, ICL, PRA, ECI, CDF = data.t()\n",
        "        ε = 1e-6\n",
        "\n",
        "        coherence  = (CNS * CER) / (ICL + ε)\n",
        "        efficiency = PRA / (ICL + 1.0)\n",
        "        retention  = CDF * torch.exp(-ECI)\n",
        "\n",
        "        targets = torch.stack([coherence, efficiency, retention], dim=1)\n",
        "        targets += 0.01 * targets.std(0) * torch.randn_like(targets)\n",
        "\n",
        "        self.X_mean, self.X_std = data.mean(0), data.std(0) + ε\n",
        "        self.Y_mean, self.Y_std = targets.mean(0), targets.std(0) + ε\n",
        "\n",
        "        self.X = ((data - self.X_mean) / self.X_std).float()\n",
        "        self.Y = ((targets - self.Y_mean) / self.Y_std).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. PlanetaryAI Model with Residuals & Dropout\n",
        "# ------------------------------------------------------------------------------\n",
        "class PlanetaryAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dim=32, output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        self.fc1      = nn.Linear(input_dim, hidden_dim)\n",
        "        self.res_head = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2      = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3      = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu     = nn.ReLU()\n",
        "        self.drop     = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = self.relu(self.fc1(x))\n",
        "        r  = self.res_head(x)\n",
        "        h2 = self.drop(self.relu(self.fc2(h1 + r)))\n",
        "        out = self.fc3(h2)\n",
        "        return out\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Training & Validation\n",
        "# ------------------------------------------------------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    criterion = nn.MSELoss()\n",
        "    for Xb, Yb in loader:\n",
        "        Xb, Yb = Xb.to(device), Yb.to(device)\n",
        "        pred = model(Xb)\n",
        "        loss = criterion(pred, Yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def validate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    criterion = nn.MSELoss()\n",
        "    with torch.no_grad():\n",
        "        for Xb, Yb in loader:\n",
        "            Xb, Yb = Xb.to(device), Yb.to(device)\n",
        "            pred = model(Xb)\n",
        "            total_loss += criterion(pred, Yb).item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout Uncertainty Quantification\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, X, T=50):\n",
        "    model.train()  # keep dropout on\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    stacked = torch.stack(preds, dim=0)\n",
        "    return stacked.mean(0), stacked.std(0)\n",
        "\n",
        "def plot_uncertainty_heatmap(model, stats, device):\n",
        "    # Vary ICL vs. PRA; keep others at mean\n",
        "    grid_size = 100\n",
        "    ICL = np.linspace(0,1,grid_size, dtype=np.float32)\n",
        "    PRA = np.linspace(0,1,grid_size, dtype=np.float32)\n",
        "    IC, PR = np.meshgrid(ICL, PRA)\n",
        "    pts = grid_size**2\n",
        "\n",
        "    Xg = torch.zeros((pts,6), device=device)\n",
        "    # CNS, CER, ECI, CDF = mean\n",
        "    for i in [0,1,4,5]:\n",
        "        Xg[:,i] = stats['X_mean'][i]\n",
        "    Xg[:,2] = torch.from_numpy(IC.ravel()).to(device)\n",
        "    Xg[:,3] = torch.from_numpy(PR.ravel()).to(device)\n",
        "\n",
        "    Xn = (Xg - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout_predict(model, Xn, T=100)\n",
        "    U = std[:,0].cpu().reshape(IC.shape)\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.pcolormesh(IC, PR, U, cmap='magma', shading='auto')\n",
        "    plt.colorbar(label='Std(Coherence)')\n",
        "    plt.xlabel('Interplanetary Latency (ICL)')\n",
        "    plt.ylabel('Resource Availability (PRA)')\n",
        "    plt.title('Uncertainty Heatmap: Coherence')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Main\n",
        "# ------------------------------------------------------------------------------\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Data\n",
        "    ds     = PlanetaryDataset(n_samples=5000, seed=42)\n",
        "    val_n  = int(0.2 * len(ds))\n",
        "    tr_ds, va_ds = random_split(ds, [len(ds)-val_n, val_n])\n",
        "    tr_ld  = DataLoader(tr_ds, batch_size=128, shuffle=True)\n",
        "    va_ld  = DataLoader(va_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    # Stats for denorm/UQ\n",
        "    stats = {\n",
        "        'X_mean': ds.X_mean.to(device),\n",
        "        'X_std' : ds.X_std.to(device),\n",
        "        'Y_mean': ds.Y_mean.to(device),\n",
        "        'Y_std' : ds.Y_std.to(device),\n",
        "    }\n",
        "\n",
        "    # Model, optimizer, scheduler\n",
        "    model     = PlanetaryAI().to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    sched     = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                    optimizer, mode='min', factor=0.5, patience=5\n",
        "                )\n",
        "\n",
        "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "    best_val = float('inf')\n",
        "\n",
        "    for ep in range(1, 51):\n",
        "        tr_loss = train_one_epoch(model, tr_ld, optimizer, device)\n",
        "        va_loss = validate(model, va_ld, device)\n",
        "        sched.step(va_loss)\n",
        "        print(f\"Epoch {ep:02d} | Train Loss: {tr_loss:.4f} | Val Loss: {va_loss:.4f}\")\n",
        "\n",
        "        if va_loss < best_val - 1e-5:\n",
        "            best_val = va_loss\n",
        "            torch.save(model.state_dict(), \"checkpoints/planetary_best.pth\")\n",
        "\n",
        "    # Load best checkpoint\n",
        "    model.load_state_dict(torch.load(\"checkpoints/planetary_best.pth\", map_location=device))\n",
        "    print(\"Best model loaded.\")\n",
        "\n",
        "    # Scatter plots of true vs. predicted\n",
        "    X_all, Y_all = ds.X.to(device), ds.Y.to(device)\n",
        "    with torch.no_grad():\n",
        "        Y_pred = model(X_all)\n",
        "\n",
        "    Y_true = (Y_all * ds.Y_std.to(device)) + ds.Y_mean.to(device)\n",
        "    Y_est  = (Y_pred * ds.Y_std.to(device)) + ds.Y_mean.to(device)\n",
        "\n",
        "    for i, name in enumerate([\"Coherence\", \"Efficiency\", \"Retention\"]):\n",
        "        plt.figure(figsize=(4,4))\n",
        "        plt.scatter(Y_true[:,i].cpu(), Y_est[:,i].cpu(), s=5, alpha=0.6)\n",
        "        m, M = Y_true[:,i].min(), Y_true[:,i].max()\n",
        "        plt.plot([m, M], [m, M], 'r--')\n",
        "        plt.title(name)\n",
        "        plt.xlabel(\"True\")\n",
        "        plt.ylabel(\"Predicted\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Uncertainty heatmap\n",
        "    plot_uncertainty_heatmap(model, stats, device)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPIWxPRCYLClYYPOB0TK94U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/parity_qnn_noisy_vmap_Fallback_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w3XpRC0QG9_"
      },
      "outputs": [],
      "source": [
        "pip install pennylane torch tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "def generate_parity_data(n_qubits):\n",
        "    \"\"\"\n",
        "    Generate all 2^n binary strings of length n and their parity labels.\n",
        "    Returns:\n",
        "        X (torch.Tensor): shape (2^n, n)\n",
        "        y (torch.Tensor): shape (2^n, 1)\n",
        "    \"\"\"\n",
        "    X = np.array([list(map(int, format(i, f\"0{n_qubits}b\")))\n",
        "                  for i in range(2 ** n_qubits)])\n",
        "    y = np.mod(np.sum(X, axis=1), 2)\n",
        "    return (\n",
        "        torch.tensor(X, dtype=torch.float32),\n",
        "        torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
        "    )\n",
        "\n",
        "\n",
        "def noisy_ansatz(params, x=None, noise_prob=0.01):\n",
        "    \"\"\"\n",
        "    Variational ansatz with data re-uploading and depolarizing noise.\n",
        "    Args:\n",
        "        params (array): shape (layers, wires, 3)\n",
        "        x (array): binary input of length wires\n",
        "        noise_prob (float): probability for depolarizing channel\n",
        "    \"\"\"\n",
        "    n_layers, n_wires, _ = params.shape\n",
        "\n",
        "    for i in range(n_wires):\n",
        "        qml.RX(np.pi * x[i], wires=i)\n",
        "\n",
        "    for layer in range(n_layers):\n",
        "        for wire in range(n_wires):\n",
        "            qml.Rot(*params[layer, wire], wires=wire)\n",
        "            qml.DepolarizingChannel(noise_prob, wires=wire)\n",
        "\n",
        "        for wire in range(n_wires - 1):\n",
        "            qml.CNOT(wires=[wire, wire + 1])\n",
        "        qml.CNOT(wires=[n_wires - 1, 0])\n",
        "\n",
        "\n",
        "class HybridParityModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Hybrid QNN for n-bit parity.\n",
        "    Quantum returns <Z_i> for each wire.\n",
        "    Classical head: MLP with dropout + sigmoid.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qubits, n_layers, n_hidden, dropout_p=0.1):\n",
        "        super().__init__()\n",
        "        self.n_qubits = n_qubits\n",
        "\n",
        "        # Use mixed backend to support noise channels\n",
        "        dev = qml.device(\"default.mixed\", wires=n_qubits)\n",
        "\n",
        "        @qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
        "        def circuit(inputs, q_params):\n",
        "            noisy_ansatz(q_params, x=inputs, noise_prob=0.02)\n",
        "            return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "        self.qnode = circuit\n",
        "        self.q_params = nn.Parameter(0.1 * torch.randn(n_layers, n_qubits, 3))\n",
        "\n",
        "        self.classical = nn.Sequential(\n",
        "            nn.Linear(n_qubits, n_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(n_hidden, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        q_out = []\n",
        "        for xi in x:\n",
        "            z_list = self.qnode(xi, self.q_params)\n",
        "            z_tensor = torch.tensor(z_list, dtype=torch.float32)\n",
        "            q_out.append(z_tensor)\n",
        "        q_out = torch.stack(q_out)  # shape: (batch, n_qubits)\n",
        "        return self.classical(q_out)\n",
        "\n",
        "\n",
        "def train_model(n_qubits, n_layers=3, n_hidden=8,\n",
        "                epochs=30, lr=0.01):\n",
        "    \"\"\"\n",
        "    Train the hybrid model on all parity patterns.\n",
        "    Prints epoch-by-epoch loss and accuracy.\n",
        "    \"\"\"\n",
        "    X, y = generate_parity_data(n_qubits)\n",
        "    model = HybridParityModel(n_qubits, n_layers, n_hidden)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds = model(X)\n",
        "        loss = criterion(preds, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            acc = ((preds > 0.5).float() == y).float().mean()\n",
        "        print(f\"Epoch {epoch:2d} | Loss: {loss.item():.4f} | Acc: {acc:.3f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def benchmark_inference(model, X):\n",
        "    \"\"\"\n",
        "    Time per-sample QNode calls vs. PennyLane vmap (if available).\n",
        "    \"\"\"\n",
        "    # Per-sample timing\n",
        "    start = time.time()\n",
        "    for xi in X:\n",
        "        _ = model.qnode(xi, model.q_params)\n",
        "    t_single = time.time() - start\n",
        "\n",
        "    print(f\"Per-sample QNode time: {t_single:.4f}s\")\n",
        "\n",
        "    # Try to import vmap\n",
        "    try:\n",
        "        from pennylane.transforms import vmap\n",
        "    except ImportError:\n",
        "        vmap = None\n",
        "\n",
        "    if vmap:\n",
        "        vmap_qnode = vmap(model.qnode, in_dims=(0, None))\n",
        "        start = time.time()\n",
        "        _ = vmap_qnode(X, model.q_params)\n",
        "        t_vmap = time.time() - start\n",
        "        print(f\"vmap batched QNode time: {t_vmap:.4f}s\")\n",
        "    else:\n",
        "        print(\"PennyLane vmap not available. Skipping batched timing.\")\n",
        "\n",
        "\n",
        "def mc_dropout_predict(model, X, mc_runs=50):\n",
        "    \"\"\"\n",
        "    MC-Dropout uncertainty estimation.\n",
        "    Returns mean and std of predictions.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.classical.train()\n",
        "\n",
        "    preds = []\n",
        "    for _ in range(mc_runs):\n",
        "        preds.append(model(X))\n",
        "    preds = torch.stack(preds)  # (mc_runs, batch, 1)\n",
        "    mean = preds.mean(dim=0)\n",
        "    std = preds.std(dim=0)\n",
        "\n",
        "    model.classical.eval()\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Experiment: 6-qubit parity\n",
        "    N = 6\n",
        "    model_6q = train_model(N, n_layers=4, n_hidden=16,\n",
        "                           epochs=30, lr=0.005)\n",
        "\n",
        "    X6, _ = generate_parity_data(N)\n",
        "    benchmark_inference(model_6q, X6)\n",
        "\n",
        "    mean_preds, std_preds = mc_dropout_predict(model_6q, X6, mc_runs=100)\n",
        "    print(\"Uncertainties for first 5 samples:\")\n",
        "    print(std_preds[:5].squeeze())"
      ],
      "metadata": {
        "id": "QmWmwhO6QKSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
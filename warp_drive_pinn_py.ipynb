{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNRMOfCKLJ/TysVlTXiXIVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/warp_drive_pinn_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zp2-A-zv8cO"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "warp_drive_pinn.py\n",
        "\n",
        "Physics‐informed net for warp‐drive curvature & energy field optimization.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Hyperparameters\n",
        "# ------------------------------------------------------------------------------\n",
        "INPUT_DIM    = 4      # [rho, bubble_radius, velocity, init_curvature]\n",
        "HIDDEN_DIM   = 32\n",
        "OUTPUT_DIM   = 2      # [opt_energy_field, opt_curvature_metric]\n",
        "DROPOUT_P    = 0.1\n",
        "LR           = 1e-3\n",
        "WEIGHT_DECAY = 1e-5\n",
        "BATCH_SIZE   = 64\n",
        "EPOCHS       = 200\n",
        "PATIENCE     = 15\n",
        "LAMBDA_PHY   = 0.5    # physics loss weight\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Data Generator (Toy Relativity)\n",
        "# ------------------------------------------------------------------------------\n",
        "def generate_synthetic_warp_data(n_samples=5000):\n",
        "    np.random.seed(0)\n",
        "    rho    = np.random.uniform(0.1, 10.0, n_samples)      # energy density\n",
        "    R      = np.random.uniform(1.0, 5.0,  n_samples)      # bubble radius\n",
        "    v      = np.random.uniform(0.0, 0.9,  n_samples)      # velocity fraction c\n",
        "    k_init = np.random.uniform(0.0, 2.0,  n_samples)      # init curvature\n",
        "    X = np.vstack([rho, R, v, k_init]).T.astype(np.float32)\n",
        "\n",
        "    # Toy “true” targets: known analytic surrogates\n",
        "    energy_field  = rho * R * (1 - v**2)\n",
        "    curvature_opt = k_init + 0.1 * rho / (R + 1e-3)\n",
        "    Y = np.vstack([energy_field, curvature_opt]).T.astype(np.float32)\n",
        "    return X, Y\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model: PhysWarpDrive with Residual Skip & Dropout\n",
        "# ------------------------------------------------------------------------------\n",
        "class PhysWarpDrive(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1  = nn.Linear(INPUT_DIM, HIDDEN_DIM)\n",
        "        self.norm = nn.LayerNorm(HIDDEN_DIM)\n",
        "        self.fc2  = nn.Linear(HIDDEN_DIM, HIDDEN_DIM)\n",
        "        self.out  = nn.Linear(HIDDEN_DIM, OUTPUT_DIM)\n",
        "        self.skip = nn.Linear(INPUT_DIM, HIDDEN_DIM)\n",
        "        self.drop = nn.Dropout(DROPOUT_P)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.norm(self.fc1(x)))\n",
        "        h = self.drop(h)\n",
        "        h = F.relu(self.fc2(h) + self.skip(x))\n",
        "        return self.out(h)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics Components & Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_stress_energy(inputs):\n",
        "    rho = inputs[:, 0]\n",
        "    v   = inputs[:, 2]\n",
        "    return rho * v**2  # toy T—energy flux\n",
        "\n",
        "def compute_einstein_tensor(curv):\n",
        "    return curv       # toy G—identity\n",
        "\n",
        "def physics_loss(pred, inputs):\n",
        "    # Enforce G(curvature) ≈ T(inputs)\n",
        "    T = compute_stress_energy(inputs)\n",
        "    G = compute_einstein_tensor(pred[:,1])\n",
        "    return F.mse_loss(G, T)\n",
        "\n",
        "def total_loss(pred, true, inputs, λ=LAMBDA_PHY):\n",
        "    mse   = F.mse_loss(pred, true)\n",
        "    phys  = physics_loss(pred, inputs)\n",
        "    return mse + λ * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. Data Preparation\n",
        "# ------------------------------------------------------------------------------\n",
        "def get_dataloaders(val_frac=0.2):\n",
        "    X, Y = generate_synthetic_warp_data()\n",
        "    Xt   = torch.from_numpy(X)\n",
        "    Yt   = torch.from_numpy(Y)\n",
        "    ds   = TensorDataset(Xt, Yt)\n",
        "    n_val = int(len(ds)*val_frac)\n",
        "    n_tr  = len(ds) - n_val\n",
        "    tr_ds, val_ds = random_split(ds, [n_tr, n_val])\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    va_ld = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "    return tr_ld, va_ld\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop with Scheduler & Early Stopping\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, tr_ld, va_ld, device):\n",
        "    opt       = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    sched     = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, patience=5)\n",
        "    best_val  = float('inf')\n",
        "    patience  = 0\n",
        "    history   = {'train_mse':[], 'val_mse':[], 'val_phys':[]}\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        tot_tr = 0.0\n",
        "        for xb, yb in tr_ld:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            pred       = model(xb)\n",
        "            loss, mse, _ = total_loss(pred, yb, xb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            tot_tr += mse.item() * xb.size(0)\n",
        "        tr_mse = tot_tr / len(tr_ld.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        tot_mse = tot_phy = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in va_ld:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred      = model(xb)\n",
        "                _, mse_v, phy_v = total_loss(pred, yb, xb)\n",
        "                tot_mse += mse_v.item() * xb.size(0)\n",
        "                tot_phy += phy_v.item() * xb.size(0)\n",
        "        val_mse = tot_mse / len(va_ld.dataset)\n",
        "        val_phy = tot_phy / len(va_ld.dataset)\n",
        "\n",
        "        sched.step(val_mse)\n",
        "        history['train_mse'].append(tr_mse)\n",
        "        history['val_mse'].append(val_mse)\n",
        "        history['val_phys'].append(val_phy)\n",
        "\n",
        "        if val_mse < best_val:\n",
        "            best_val = val_mse\n",
        "            torch.save(model.state_dict(), 'best_warp_pinn.pt')\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience >= PATIENCE:\n",
        "                print(f\"Early stopping at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "        if ep % 10 == 0 or ep == 1:\n",
        "            print(f\"Epoch {ep:03d} | Train MSE {tr_mse:.4f} | Val MSE {val_mse:.4f} | Val Phys {val_phy:.4f}\")\n",
        "\n",
        "    model.load_state_dict(torch.load('best_warp_pinn.pt'))\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_history(hist):\n",
        "    epochs = len(hist['train_mse'])\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(range(1, epochs+1), hist['train_mse'], label='Train MSE')\n",
        "    plt.plot(range(1, epochs+1), hist['val_mse'],  label='Val MSE')\n",
        "    plt.plot(range(1, epochs+1), hist['val_phys'], label='Val Physics Residual')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    tr_loader, va_loader = get_dataloaders()\n",
        "    model      = PhysWarpDrive().to(device)\n",
        "    history    = train(model, tr_loader, va_loader, device)\n",
        "    print(\"Training complete. Best validation saved to best_warp_pinn.pt\")\n",
        "    plot_history(history)"
      ]
    }
  ]
}
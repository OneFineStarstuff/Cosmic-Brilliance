{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNSIV9vIenVmfiU54DCjsv0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/quantum_metric_kernel_enhanced_fixed_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwiMcv_1xCwU"
      },
      "outputs": [],
      "source": [
        "pip install pennylane numpy scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "quantum_metric_kernel_enhanced_fixed.py\n",
        "\n",
        "Enhanced quantum-metric learning for 4-bit parity classification:\n",
        "\n",
        "1) Analytic CNOT cascade baseline (100% accuracy)\n",
        "2) Variational QNN baseline (5-fold CV)\n",
        "3) Enhanced metric learning:\n",
        "   - AngleEmbedding\n",
        "   - Layer 1: Ry(params[0:n_bits])\n",
        "   - CNOT ring entanglement\n",
        "   - Layer 2: RZ(params[n_bits:2*n_bits]) + Ry(params[2*n_bits:3*n_bits])\n",
        "   - Mini-batch centered alignment loss\n",
        "   - QNGOptimizer with explicit metric tensor\n",
        "4) Final SVM (precomputed kernel) 5-fold CV\n",
        "5) Fidelity histogram of learned kernel\n",
        "\"\"\"\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as pnp\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Hyperparameters\n",
        "# -----------------------------------------------------------------------------\n",
        "n_bits     = 4       # number of input bits/qubits\n",
        "qnn_epochs = 30      # epochs for variational QNN\n",
        "qnn_lr     = 0.4     # learning rate for QNN\n",
        "n_steps    = 200     # training steps for metric learning\n",
        "qng_lr     = 0.05    # QNG step size\n",
        "svm_C      = 1.0     # SVM regularization parameter\n",
        "batch_size = 8       # mini-batch size for alignment loss\n",
        "seed       = 42      # random seed\n",
        "\n",
        "np.random.seed(seed)\n",
        "pnp.random.seed(seed)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1) Generate 4‐bit parity dataset\n",
        "# -----------------------------------------------------------------------------\n",
        "X_int    = pnp.array(list(itertools.product([0, 1], repeat=n_bits)), dtype=int)\n",
        "y        = pnp.array(np.sum(X_int, axis=1) % 2, dtype=int)  # {0,1}\n",
        "y_signed = 1 - 2 * y                                        # {+1,-1}\n",
        "X_feat   = X_int.astype(float)                              # for AngleEmbedding\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2) Analytic CNOT cascade baseline\n",
        "# -----------------------------------------------------------------------------\n",
        "dev_exact = qml.device(\"default.qubit\", wires=n_bits + 1)\n",
        "\n",
        "@qml.qnode(dev_exact)\n",
        "def analytic_circuit(x):\n",
        "    for i, bit in enumerate(x):\n",
        "        if bit:\n",
        "            qml.PauliX(wires=i)\n",
        "    for i in range(n_bits):\n",
        "        qml.CNOT(wires=[i, n_bits])\n",
        "    return qml.expval(qml.PauliZ(wires=n_bits))\n",
        "\n",
        "preds_analytic = [0 if analytic_circuit(x) > 0 else 1 for x in X_int]\n",
        "acc_analytic   = accuracy_score(y, preds_analytic)\n",
        "print(f\"Analytic CNOT Cascade Accuracy: {acc_analytic:.3f}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3) Variational QNN baseline (5‐fold CV)\n",
        "# -----------------------------------------------------------------------------\n",
        "dev_qnn = qml.device(\"default.qubit\", wires=n_bits)\n",
        "\n",
        "@qml.qnode(dev_qnn, interface=\"autograd\")\n",
        "def qnn_circuit(params, x):\n",
        "    for i, bit in enumerate(x):\n",
        "        if bit:\n",
        "            qml.RY(np.pi, wires=i)\n",
        "    for i in range(n_bits):\n",
        "        qml.RY(params[i], wires=i)\n",
        "    for i in range(n_bits - 1):\n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "    return qml.expval(qml.PauliZ(wires=n_bits - 1))\n",
        "\n",
        "var_scores = []\n",
        "for tr, te in kf.split(X_int, y):\n",
        "    params = pnp.random.randn(n_bits, requires_grad=True) * 0.1\n",
        "    opt    = qml.GradientDescentOptimizer(stepsize=qnn_lr)\n",
        "\n",
        "    for _ in range(qnn_epochs):\n",
        "        def cost(p):\n",
        "            preds = [qnn_circuit(p, X_int[i]) for i in tr]\n",
        "            return pnp.mean((pnp.array(preds) - y_signed[tr]) ** 2)\n",
        "        params = opt.step(cost, params)\n",
        "\n",
        "    preds_te = [qnn_circuit(params, X_int[i]) for i in te]\n",
        "    bits     = [0 if v > 0 else 1 for v in preds_te]\n",
        "    var_scores.append(accuracy_score(y[te], bits))\n",
        "\n",
        "print(f\"Variational QNN CV Accuracy: {np.mean(var_scores):.3f} ± {np.std(var_scores):.3f}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4) Enhanced quantum‐metric learning\n",
        "# -----------------------------------------------------------------------------\n",
        "dev_feat = qml.device(\"default.qubit\", wires=n_bits + 1)\n",
        "\n",
        "@qml.qnode(dev_feat, interface=\"autograd\")\n",
        "def feature_map(params, x):\n",
        "    # Angle embedding of data\n",
        "    qml.templates.AngleEmbedding(x, wires=range(n_bits))\n",
        "    # Layer 1: Ry(params[0:n_bits])\n",
        "    for i in range(n_bits):\n",
        "        qml.RY(params[i], wires=i)\n",
        "    # Ring entanglement\n",
        "    for i in range(n_bits):\n",
        "        qml.CNOT(wires=[i, (i + 1) % n_bits])\n",
        "    # Layer 2: RZ + Ry\n",
        "    for i in range(n_bits):\n",
        "        qml.RZ(params[n_bits + i], wires=i)\n",
        "        qml.RY(params[2 * n_bits + i], wires=i)\n",
        "    return qml.state()\n",
        "\n",
        "def build_kernel_matrix(params, indices=None):\n",
        "    Xp = X_feat if indices is None else X_feat[indices]\n",
        "    states = pnp.stack([feature_map(params, x) for x in Xp])\n",
        "    re, im = pnp.real(states), pnp.imag(states)\n",
        "    real_ov = re @ re.T + im @ im.T\n",
        "    imag_ov = re @ im.T - im @ re.T\n",
        "    return real_ov**2 + imag_ov**2\n",
        "\n",
        "def centered_alignment(params, indices):\n",
        "    K   = build_kernel_matrix(params, indices)\n",
        "    yi  = y_signed[indices]\n",
        "    N   = len(indices)\n",
        "    H   = pnp.eye(N) - pnp.ones((N, N)) / N\n",
        "    Kc  = H @ K @ H\n",
        "    T   = pnp.outer(yi, yi)\n",
        "    num = pnp.sum(Kc * T)\n",
        "    den = pnp.linalg.norm(Kc) * pnp.linalg.norm(T)\n",
        "    return num / den\n",
        "\n",
        "# Initialize metric‐learning parameters: 3*n_bits trainable angles\n",
        "params_k = pnp.random.randn(3 * n_bits, requires_grad=True) * 0.1\n",
        "\n",
        "# Explicit Fisher information function (argument 0 only)\n",
        "raw_metric = qml.metric_tensor(feature_map, argnum=[0])\n",
        "\n",
        "def metric_tensor_fn(params, indices):\n",
        "    mats = []\n",
        "    for idx in indices:\n",
        "        m = raw_metric(params, X_feat[idx])\n",
        "        if isinstance(m, tuple):\n",
        "            m = m[0]\n",
        "        mats.append(m)\n",
        "    return sum(mats) / len(mats)\n",
        "\n",
        "opt_qng = qml.QNGOptimizer(stepsize=qng_lr)\n",
        "\n",
        "print(\"\\nTraining enhanced feature map via stochastic QNG + alignment\")\n",
        "for step in range(n_steps):\n",
        "    # sample a random mini‐batch\n",
        "    batch = np.random.choice(len(X_feat), size=batch_size, replace=False)\n",
        "    # define mini‐batch loss (negative centered alignment)\n",
        "    loss_fn = lambda p: -centered_alignment(p, batch)\n",
        "    # natural‐gradient step with per‐batch Fisher\n",
        "    params_k = opt_qng.step(\n",
        "        loss_fn,\n",
        "        params_k,\n",
        "        metric_tensor_fn=lambda p: metric_tensor_fn(p, batch),\n",
        "    )\n",
        "    if step % 20 == 0:\n",
        "        full_align = centered_alignment(params_k, np.arange(len(X_feat)))\n",
        "        print(f\" Step {step:>3}: full alignment = {full_align:.4f}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 5) Final SVM (precomputed kernel) 5‐fold CV\n",
        "# -----------------------------------------------------------------------------\n",
        "K_final   = np.array(build_kernel_matrix(params_k))\n",
        "ker_scores = []\n",
        "\n",
        "for tr, te in kf.split(K_final, y):\n",
        "    svc = SVC(kernel=\"precomputed\", C=svm_C)\n",
        "    svc.fit(K_final[np.ix_(tr, tr)], y[tr])\n",
        "    preds = svc.predict(K_final[np.ix_(te, tr)])\n",
        "    ker_scores.append(accuracy_score(y[te], preds))\n",
        "\n",
        "print(\n",
        "    f\"\\nEnhanced Quantum‐Metric Kernel CV Accuracy: \"\n",
        "    f\"{np.mean(ker_scores):.3f} ± {np.std(ker_scores):.3f}\"\n",
        ")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 6) Fidelity histogram\n",
        "# -----------------------------------------------------------------------------\n",
        "fids = K_final.flatten()\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(fids, bins=30, color=\"C0\", alpha=0.8)\n",
        "plt.title(\"Fidelity Distribution of Learned Kernel\")\n",
        "plt.xlabel(\"Kernel value |⟨ψ_i|ψ_j⟩|²\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XIgKSD9nxS30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
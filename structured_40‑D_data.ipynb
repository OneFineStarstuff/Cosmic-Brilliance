{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN38FiFhfEFRD9qSktf9haX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/structured_40%E2%80%91D_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GNtQkj81h-h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "def make_wormhole_data(n_samples=12000, n_features=40, n_classes=10,\n",
        "                       turns=3.0, noise=0.12, seed=SEED):\n",
        "    \"\"\"\n",
        "    Build 10 phase-shifted logarithmic spirals in 2D and project to 40D.\n",
        "    This creates a 'tunneled' manifold with real class structure.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    per_class = n_samples // n_classes\n",
        "\n",
        "    # 2D -> n_features random projection (fixed across classes for shared geometry)\n",
        "    proj = rng.normal(0.0, 1.0, size=(2, n_features))\n",
        "\n",
        "    xs, ys = [], []\n",
        "    for c in range(n_classes):\n",
        "        t = rng.uniform(0.0, 1.0, size=(per_class,))  # progress along the spiral\n",
        "        theta = 2 * np.pi * turns * t + (2 * np.pi / n_classes) * c\n",
        "        r = 0.8 + 1.2 * t  # outward growth\n",
        "        x2 = np.stack([r * np.cos(theta), r * np.sin(theta)], axis=1)\n",
        "        x_high = x2 @ proj + rng.normal(0.0, noise, size=(per_class, n_features))\n",
        "        xs.append(x_high.astype(\"float32\"))\n",
        "        ys.append(np.full((per_class,), c, dtype=np.int32))\n",
        "\n",
        "    X = np.vstack(xs)\n",
        "    y = np.concatenate(ys)\n",
        "\n",
        "    # Shuffle\n",
        "    idx = rng.permutation(len(X))\n",
        "    return X[idx], y[idx]\n",
        "\n",
        "# Generate data\n",
        "X, y = make_wormhole_data(n_samples=12000, n_features=40, n_classes=10, turns=3.5, noise=0.12)\n",
        "\n",
        "# Split: 70/15/15\n",
        "n = len(X)\n",
        "n_train = int(0.70 * n)\n",
        "n_val   = int(0.15 * n)\n",
        "X_train, y_train = X[:n_train], y[:n_train]\n",
        "X_val, y_val     = X[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
        "X_test, y_test   = X[n_train+n_val:], y[n_train+n_val:]\n",
        "\n",
        "# Standardize by train stats (important for tanh/relu stability)\n",
        "mean = X_train.mean(axis=0, keepdims=True)\n",
        "std  = X_train.std(axis=0, keepdims=True) + 1e-7\n",
        "X_train = (X_train - mean) / std\n",
        "X_val   = (X_val   - mean) / std\n",
        "X_test  = (X_test  - mean) / std\n",
        "\n",
        "# tf.data pipelines\n",
        "BATCH = 128\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(8192, seed=SEED).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds   = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds  = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Wormhole Neural Network Model (with light regularization)\n",
        "class WormholeAI(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.entry_layer  = tf.keras.layers.Dense(256, activation='tanh',\n",
        "                                                  kernel_regularizer=tf.keras.regularizers.l2(1e-5))\n",
        "        self.tunnel_layer = tf.keras.layers.Dense(512, activation='relu',\n",
        "                                                  kernel_regularizer=tf.keras.regularizers.l2(1e-5))\n",
        "        self.dropout      = tf.keras.layers.Dropout(0.2)\n",
        "        self.exit_layer   = tf.keras.layers.Dense(256, activation='tanh',\n",
        "                                                  kernel_regularizer=tf.keras.regularizers.l2(1e-5))\n",
        "        self.output_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.entry_layer(inputs)        # Enter the wormhole\n",
        "        x = self.tunnel_layer(x)            # Information tunnels\n",
        "        x = self.dropout(x, training=training)\n",
        "        x = self.exit_layer(x)              # Exit the wormhole\n",
        "        return self.output_layer(x)         # Class projection\n",
        "\n",
        "model = WormholeAI()\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks and logging\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5, verbose=1),\n",
        "    tf.keras.callbacks.CSVLogger(\"results/training_history.csv\"),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"results/wormhole_best.keras\", monitor=\"val_accuracy\",\n",
        "                                       save_best_only=True, save_weights_only=False)\n",
        "]\n",
        "\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=60, callbacks=callbacks, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
        "print(f\"✅ Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")\n",
        "print(\"✅ Training history saved to results/training_history.csv\")\n",
        "print(\"✅ Best model saved to results/wormhole_best.keras\")\n",
        "\n",
        "# Confusion matrix (quick look at per-class performance)\n",
        "y_pred = model.predict(test_ds, verbose=0).argmax(axis=1)\n",
        "cm = tf.math.confusion_matrix(y_test, y_pred, num_classes=10).numpy()\n",
        "print(\"Confusion matrix:\\n\", cm)"
      ]
    }
  ]
}
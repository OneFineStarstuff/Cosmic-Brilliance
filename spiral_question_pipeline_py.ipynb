{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN7rlvOhW7eabjRb0npyHl4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/spiral_question_pipeline_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDEaoHCXEa_9"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# spiral_question_pipeline.py\n",
        "# End-to-end generator → semantic scorer → artifact bundler with optional AES-GCM encryption.\n",
        "\n",
        "import argparse\n",
        "import csv\n",
        "import hashlib\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import secrets\n",
        "import string\n",
        "import sys\n",
        "import time\n",
        "import zipfile\n",
        "from dataclasses import dataclass, asdict\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict, Any, Optional\n",
        "\n",
        "import yaml  # pip install pyyaml\n",
        "from sentence_transformers import SentenceTransformer, util  # pip install sentence-transformers\n",
        "\n",
        "# Encryption deps\n",
        "from cryptography.hazmat.primitives.kdf.scrypt import Scrypt  # pip install cryptography\n",
        "from cryptography.hazmat.primitives.ciphers.aead import AESGCM\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Helpers: RNG, hashing, time\n",
        "# ------------------------------\n",
        "\n",
        "def now_iso() -> str:\n",
        "    return time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n",
        "\n",
        "def sha256_bytes(b: bytes) -> str:\n",
        "    return hashlib.sha256(b).hexdigest()\n",
        "\n",
        "def sha256_file(path: Path) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    with path.open('rb') as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b''):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def seed_rng(seed: Optional[int]) -> random.Random:\n",
        "    if seed is None:\n",
        "        seed = secrets.randbelow(2**31)\n",
        "    rng = random.Random(seed)\n",
        "    return rng\n",
        "\n",
        "def slugify(s: str, maxlen: int = 60) -> str:\n",
        "    allowed = string.ascii_letters + string.digits + \"-_\"\n",
        "    s2 = ''.join(ch if ch in allowed else '-' for ch in s.strip())\n",
        "    s2 = '-'.join(filter(None, s2.split('-')))\n",
        "    return s2[:maxlen]\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Ideals: load/save\n",
        "# ------------------------------\n",
        "\n",
        "DEFAULT_IDEALS = [\n",
        "    \"How could artificial intelligence uncover hidden symmetries in the laws of nature?\",\n",
        "    \"In what ways might AGI reshape our understanding of time and causality?\",\n",
        "    \"Can the emergence of intelligence be considered a phase transition in the fabric of spacetime?\",\n",
        "]\n",
        "\n",
        "def load_ideals(path: Optional[Path]) -> List[str]:\n",
        "    if path is None:\n",
        "        return DEFAULT_IDEALS[:]\n",
        "    if not path.exists():\n",
        "        return []\n",
        "    with path.open('r', encoding='utf-8') as f:\n",
        "        lines = [ln.strip() for ln in f if ln.strip()]\n",
        "    return lines\n",
        "\n",
        "def append_ideals(path: Path, new_lines: List[str]) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with path.open('a', encoding='utf-8') as f:\n",
        "        for line in new_lines:\n",
        "            f.write(line.rstrip() + \"\\n\")\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Question generation (template-based)\n",
        "# ------------------------------\n",
        "\n",
        "TEMPLATES = [\n",
        "    \"How might {topic} reveal new structures in {context}?\",\n",
        "    \"In what ways could {topic} transform our understanding of {context}?\",\n",
        "    \"Could {topic} act as a bridge between {context} and {context2}?\",\n",
        "    \"What would it mean if {topic} obeys a conservation law in {context}?\",\n",
        "    \"Is there a phase transition where {topic} emerges from {context}?\",\n",
        "    \"How could {topic} expose hidden symmetries within {context}?\",\n",
        "    \"What constraints would {topic} impose on {context} at scale?\",\n",
        "    \"Could {topic} be modeled as information flow across {context}?\",\n",
        "    \"Does {topic} alter causal structure in {context}?\",\n",
        "    \"What empirical signatures would {topic} leave in {context}?\",\n",
        "    \"Can {topic} regularize paradoxes in {context} without breaking {context2}?\",\n",
        "    \"Is {topic} fundamentally discrete or continuous within {context}?\",\n",
        "    \"Could {topic} be reframed as a gauge over {context}?\",\n",
        "    \"What happens to {topic} near critical points of {context}?\",\n",
        "    \"Can {topic} be understood as a symmetry breaking in {context}?\"\n",
        "]\n",
        "\n",
        "CONTEXTS = [\n",
        "    \"spacetime\", \"thermodynamics\", \"quantum fields\", \"cosmology\",\n",
        "    \"information theory\", \"causality\", \"entropy\", \"measurement\",\n",
        "    \"complex systems\", \"emergence\", \"symmetry\", \"computation\",\n",
        "    \"observation\", \"gravity\", \"topology\", \"phase transitions\"\n",
        "]\n",
        "\n",
        "def parse_topics(topics_str: Optional[str]) -> List[str]:\n",
        "    if not topics_str:\n",
        "        return [\"AGI\", \"artificial intelligence\", \"consciousness\", \"alignment\", \"symbolic systems\"]\n",
        "    return [t.strip() for t in topics_str.split(\",\") if t.strip()]\n",
        "\n",
        "def generate_questions(topics: List[str], num: int, rng: random.Random) -> List[str]:\n",
        "    qs = []\n",
        "    for _ in range(num):\n",
        "        topic = rng.choice(topics)\n",
        "        ctx1 = rng.choice(CONTEXTS)\n",
        "        ctx2 = rng.choice([c for c in CONTEXTS if c != ctx1] or [ctx1])\n",
        "        tpl = rng.choice(TEMPLATES)\n",
        "        q = tpl.format(topic=topic, context=ctx1, context2=ctx2).strip()\n",
        "        # Normalize punctuation\n",
        "        if not q.endswith(\"?\"):\n",
        "            q += \"?\"\n",
        "        qs.append(q)\n",
        "    # Deduplicate while preserving order\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for q in qs:\n",
        "        if q not in seen:\n",
        "            seen.add(q)\n",
        "            out.append(q)\n",
        "    return out\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Semantic scoring (vectorized)\n",
        "# ------------------------------\n",
        "\n",
        "@dataclass\n",
        "class ScoreResult:\n",
        "    question: str\n",
        "    best_score: float\n",
        "    best_ideal_idx: int\n",
        "\n",
        "def load_model(model_name: str) -> SentenceTransformer:\n",
        "    return SentenceTransformer(model_name)\n",
        "\n",
        "def score_questions(model: SentenceTransformer, questions: List[str], ideals: List[str]) -> List[ScoreResult]:\n",
        "    if not questions:\n",
        "        return []\n",
        "    ideal_emb = model.encode(ideals, convert_to_tensor=True, normalize_embeddings=True)\n",
        "    q_emb = model.encode(questions, convert_to_tensor=True, normalize_embeddings=True)\n",
        "    sims = util.cos_sim(q_emb, ideal_emb)  # [Q x I]\n",
        "    # Get per-row max and argmax\n",
        "    max_vals = sims.max(dim=1).values\n",
        "    argmax_idx = sims.argmax(dim=1)\n",
        "    results = [\n",
        "        ScoreResult(question=questions[i], best_score=float(max_vals[i].item()), best_ideal_idx=int(argmax_idx[i].item()))\n",
        "        for i in range(len(questions))\n",
        "    ]\n",
        "    results.sort(key=lambda r: r.best_score, reverse=True)\n",
        "    return results\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# SVG artifact (simple list)\n",
        "# ------------------------------\n",
        "\n",
        "def render_svg_list(pairs: List[Tuple[str, float]], width: int = 960, line_height: int = 28, margin: int = 24) -> str:\n",
        "    lines = [f\"{score:.3f}  {q}\" for q, score in pairs]\n",
        "    height = margin * 2 + line_height * len(lines)\n",
        "    # Escape basic XML entities\n",
        "    def esc(s: str) -> str:\n",
        "        return s.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
        "    y = margin + line_height\n",
        "    text_elems = []\n",
        "    for idx, line in enumerate(lines, 1):\n",
        "        text_elems.append(\n",
        "            f'<text x=\"{margin}\" y=\"{y}\" font-family=\"Monaco, Menlo, Consolas, monospace\" font-size=\"14\">{esc(line)}</text>'\n",
        "        )\n",
        "        y += line_height\n",
        "    svg = f'''<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"{width}\" height=\"{height}\" viewBox=\"0 0 {width} {height}\">\n",
        "  <rect width=\"100%\" height=\"100%\" fill=\"#0b0f14\"/>\n",
        "  <g fill=\"#e6edf3\">\n",
        "    <text x=\"{margin}\" y=\"{margin}\" font-family=\"Monaco, Menlo, Consolas, monospace\" font-size=\"16\" font-weight=\"bold\">Semantic ranking (score 0..1)</text>\n",
        "    {\"\".join(text_elems)}\n",
        "  </g>\n",
        "</svg>'''\n",
        "    return svg\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Manifest + bundle\n",
        "# ------------------------------\n",
        "\n",
        "def write_text(path: Path, data: str) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(data, encoding='utf-8')\n",
        "\n",
        "def write_json(path: Path, obj: Any) -> None:\n",
        "    write_text(path, json.dumps(obj, ensure_ascii=False, indent=2))\n",
        "\n",
        "def write_csv(path: Path, rows: List[Dict[str, Any]], fieldnames: List[str]) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with path.open('w', newline='', encoding='utf-8') as f:\n",
        "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        w.writeheader()\n",
        "        for r in rows:\n",
        "            w.writerow(r)\n",
        "\n",
        "def build_manifest(root: Path, files: List[Path], meta: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    items = []\n",
        "    for p in files:\n",
        "        items.append({\n",
        "            \"path\": str(p.relative_to(root)),\n",
        "            \"sha256\": sha256_file(p),\n",
        "            \"size\": p.stat().st_size,\n",
        "        })\n",
        "    manifest = {\n",
        "        \"version\": \"1.0\",\n",
        "        \"created\": now_iso(),\n",
        "        \"root\": str(root),\n",
        "        \"meta\": meta,\n",
        "        \"files\": items\n",
        "    }\n",
        "    return manifest\n",
        "\n",
        "def zip_dir(root: Path, out_zip: Path) -> None:\n",
        "    with zipfile.ZipFile(out_zip, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "        for p in root.rglob(\"*\"):\n",
        "            if p.is_file():\n",
        "                zf.write(p, arcname=str(p.relative_to(root)))\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Encryption (AES-256-GCM with scrypt KDF)\n",
        "# ------------------------------\n",
        "\n",
        "def derive_key_scrypt(passphrase: str, salt: bytes, n: int = 2**14, r: int = 8, p: int = 1, key_len: int = 32) -> bytes:\n",
        "    kdf = Scrypt(salt=salt, length=key_len, n=n, r=r, p=p)\n",
        "    return kdf.derive(passphrase.encode('utf-8'))\n",
        "\n",
        "def encrypt_bytes_aesgcm(plaintext: bytes, passphrase: str) -> bytes:\n",
        "    salt = secrets.token_bytes(16)\n",
        "    key = derive_key_scrypt(passphrase, salt)\n",
        "    aesgcm = AESGCM(key)\n",
        "    nonce = secrets.token_bytes(12)\n",
        "    ct = aesgcm.encrypt(nonce, plaintext, associated_data=None)\n",
        "    header = {\n",
        "        \"alg\": \"AES-256-GCM\",\n",
        "        \"kdf\": \"scrypt\",\n",
        "        \"salt_b64\": base64_encode(salt),\n",
        "        \"nonce_b64\": base64_encode(nonce),\n",
        "        \"kdf_params\": {\"n\": 16384, \"r\": 8, \"p\": 1, \"len\": 32},\n",
        "    }\n",
        "    blob = {\n",
        "        \"header\": header,\n",
        "        \"ciphertext_b64\": base64_encode(ct),\n",
        "    }\n",
        "    return json.dumps(blob, indent=2).encode('utf-8')\n",
        "\n",
        "def base64_encode(b: bytes) -> str:\n",
        "    import base64\n",
        "    return base64.b64encode(b).decode('ascii')\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# CLI\n",
        "# ------------------------------\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"Generate → score → bundle → encrypt pipeline for philosophical questions.\")\n",
        "    ap.add_argument(\"--topics\", type=str, default=None, help=\"Comma-separated topics (default: AGI, artificial intelligence, ...)\")\n",
        "    ap.add_argument(\"--num\", type=int, default=40, help=\"Number of candidate questions to generate\")\n",
        "    ap.add_argument(\"--model\", type=str, default=\"sentence-transformers/all-MiniLM-L6-v2\", help=\"SentenceTransformer model name\")\n",
        "    ap.add_argument(\"--ideals-file\", type=Path, default=None, help=\"Path to ideals.txt (one per line). Defaults to built-ins if not given\")\n",
        "    ap.add_argument(\"--topk\", type=int, default=15, help=\"Number of top results to include prominently and for feedback\")\n",
        "    ap.add_argument(\"--seed\", type=int, default=None, help=\"RNG seed for reproducibility\")\n",
        "    ap.add_argument(\"--outdir\", type=Path, required=True, help=\"Output directory for artifacts\")\n",
        "    ap.add_argument(\"--bundle\", action=\"store_true\", help=\"Create a ZIP bundle of artifacts\")\n",
        "    ap.add_argument(\"--encrypt\", action=\"store_true\", help=\"Encrypt the bundle with AES-GCM (requires --bundle)\")\n",
        "    ap.add_argument(\"--passphrase\", type=str, default=None, help=\"Passphrase to encrypt the bundle (if omitted, read from stdin hidden)\")\n",
        "    ap.add_argument(\"--update-ideals\", action=\"store_true\", help=\"Append top-K back into ideals file\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    rng = seed_rng(args.seed)\n",
        "    outdir: Path = args.outdir\n",
        "    outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load ideals\n",
        "    ideals = load_ideals(args.ideals_file)\n",
        "    if not ideals:\n",
        "        print(\"No ideals found; using defaults.\")\n",
        "        ideals = DEFAULT_IDEALS[:]\n",
        "\n",
        "    # Generate candidates\n",
        "    topics = parse_topics(args.topics)\n",
        "    questions = generate_questions(topics, args.num, rng)\n",
        "\n",
        "    # Load model and score\n",
        "    print(f\"Loading model: {args.model}\")\n",
        "    model = load_model(args.model)\n",
        "    print(\"Scoring questions...\")\n",
        "    scored = score_questions(model, questions, ideals)\n",
        "\n",
        "    # Prepare rows and top-K\n",
        "    ranked_pairs = [(r.question, r.best_score) for r in scored]\n",
        "    top_pairs = ranked_pairs[: max(1, args.topk)]\n",
        "\n",
        "    # Write artifacts\n",
        "    meta = {\n",
        "        \"created\": now_iso(),\n",
        "        \"model\": args.model,\n",
        "        \"topics\": topics,\n",
        "        \"num_generated\": len(questions),\n",
        "        \"num_ranked\": len(scored),\n",
        "        \"topk\": args.topk,\n",
        "        \"seed\": args.seed,\n",
        "        \"ideals_file\": str(args.ideals_file) if args.ideals_file else \"(builtin)\",\n",
        "    }\n",
        "\n",
        "    # out.csv\n",
        "    csv_rows = []\n",
        "    for rank, (q, s) in enumerate(ranked_pairs, 1):\n",
        "        csv_rows.append({\"rank\": rank, \"score\": f\"{s:.6f}\", \"question\": q})\n",
        "    write_csv(outdir / \"out.csv\", csv_rows, fieldnames=[\"rank\", \"score\", \"question\"])\n",
        "\n",
        "    # out.json\n",
        "    write_json(outdir / \"out.json\", {\n",
        "        \"meta\": meta,\n",
        "        \"ranked\": [{\"rank\": i + 1, \"score\": s, \"question\": q} for i, (q, s) in enumerate(ranked_pairs)]\n",
        "    })\n",
        "\n",
        "    # top.txt\n",
        "    write_text(outdir / \"top.txt\", \"\\n\".join([f\"[{s:.3f}] {q}\" for q, s in top_pairs]))\n",
        "\n",
        "    # svg\n",
        "    svg = render_svg_list(top_pairs)\n",
        "    write_text(outdir / \"out.svg\", svg)\n",
        "\n",
        "    # plan.json (simple)\n",
        "    write_json(outdir / \"plan.json\", {\n",
        "        \"goal\": \"Generate and rank philosophically-rich questions by semantic alignment to ideals.\",\n",
        "        \"steps\": [\n",
        "            \"Generate template-based candidates\",\n",
        "            \"Encode with SentenceTransformer\",\n",
        "            \"Vectorized cosine similarity vs ideals\",\n",
        "            \"Sort by best match\",\n",
        "            \"Emit artifacts and manifest\",\n",
        "            \"Optionally bundle and encrypt\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # manifest.yaml\n",
        "    # Collect file list\n",
        "    files = [\n",
        "        outdir / \"out.csv\",\n",
        "        outdir / \"out.json\",\n",
        "        outdir / \"top.txt\",\n",
        "        outdir / \"out.svg\",\n",
        "        outdir / \"plan.json\",\n",
        "    ]\n",
        "    manifest = build_manifest(outdir, files, meta)\n",
        "    write_text(outdir / \"manifest.yaml\", yaml.safe_dump(manifest, sort_keys=False))\n",
        "    files.append(outdir / \"manifest.yaml\")\n",
        "\n",
        "    # Feedback loop\n",
        "    if args.update_ideals:\n",
        "        target_file = args.ideals_file or (outdir / \"ideals.txt\")\n",
        "        append_lines = [q for q, _ in top_pairs]\n",
        "        append_ideals(Path(target_file), append_lines)\n",
        "        print(f\"Appended top-{len(append_lines)} questions to {target_file}\")\n",
        "\n",
        "    # Bundle\n",
        "    bundle_path = None\n",
        "    if args.bundle:\n",
        "        bundle_name = f\"bundle-{slugify(meta['model'])}-{int(time.time())}.zip\"\n",
        "        bundle_path = outdir / bundle_name\n",
        "        zip_dir(outdir, bundle_path)\n",
        "        print(f\"Wrote bundle: {bundle_path}\")\n",
        "\n",
        "    # Encrypt\n",
        "    if args.encrypt:\n",
        "        if not args.bundle or bundle_path is None:\n",
        "            print(\"Error: --encrypt requires --bundle\", file=sys.stderr)\n",
        "            sys.exit(2)\n",
        "        # Get passphrase\n",
        "        passphrase = args.passphrase\n",
        "        if not passphrase:\n",
        "            try:\n",
        "                import getpass\n",
        "                passphrase = getpass.getpass(\"Enter passphrase for encryption: \")\n",
        "            except Exception:\n",
        "                print(\"Error: passphrase not provided and cannot prompt. Use --passphrase.\", file=sys.stderr)\n",
        "                sys.exit(2)\n",
        "        with bundle_path.open('rb') as f:\n",
        "            plaintext = f.read()\n",
        "        enc_bytes = encrypt_bytes_aesgcm(plaintext, passphrase)\n",
        "        enc_path = bundle_path.with_suffix(bundle_path.suffix + \".enc.json\")\n",
        "        with enc_path.open('wb') as f:\n",
        "            f.write(enc_bytes)\n",
        "        print(f\"Encrypted bundle: {enc_path} (JSON envelope with AES-GCM)\")\n",
        "\n",
        "    # Console summary\n",
        "    print(\"\\nTop results:\")\n",
        "    for i, (q, s) in enumerate(top_pairs, 1):\n",
        "        print(f\"[{s:.3f}] {i}. {q}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}
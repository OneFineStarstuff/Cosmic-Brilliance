{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMkDpZEm1A7po7gyLbw6V5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/unifiedai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch --quiet"
      ],
      "metadata": {
        "id": "7oCdQhP4gSG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "UnifiedAI: Train a conditional VAE-style dynamics model on synthetic data,\n",
        "then plan toward a goal via random shooting. Notebook/CLI friendly.\n",
        "\n",
        "- Ignores unknown args (e.g., Jupyter's -f file.json)\n",
        "- Deterministic toggle and CUDA fallback\n",
        "- Provenance: config hash, metrics CSV, checkpoints\n",
        "- Modes: run (train+plan) or grid (sweep seeds/epochs/plan_candidates)\n",
        "\"\"\"\n",
        "\n",
        "import argparse, math, random, os, json, time, hashlib, csv\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Tuple, Dict, Any, List\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ----------------------------\n",
        "# Utilities\n",
        "# ----------------------------\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def set_deterministic(enabled: bool):\n",
        "    torch.backends.cudnn.benchmark = not enabled\n",
        "    torch.backends.cudnn.deterministic = enabled\n",
        "\n",
        "def ensure_dir(path: str):\n",
        "    if path and not os.path.exists(path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def now_tag() -> str:\n",
        "    return datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "def cfg_hash(cfg_dict: Dict[str, Any]) -> str:\n",
        "    payload = json.dumps(cfg_dict, sort_keys=True, separators=(\",\", \":\")).encode(\"utf-8\")\n",
        "    return hashlib.sha256(payload).hexdigest()[:12]\n",
        "\n",
        "def write_json(path: str, obj: Dict[str, Any]):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, indent=2, sort_keys=True)\n",
        "\n",
        "def append_csv(path: str, header: List[str], row: Dict[str, Any]):\n",
        "    is_new = not os.path.exists(path)\n",
        "    with open(path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=header, extrasaction=\"ignore\")\n",
        "        if is_new: w.writeheader()\n",
        "        w.writerow(row)\n",
        "\n",
        "def human_time(sec: float) -> str:\n",
        "    if sec < 1: return f\"{sec*1000:.0f} ms\"\n",
        "    if sec < 60: return f\"{sec:.1f} s\"\n",
        "    m,s = divmod(sec,60); return f\"{int(m)}m{int(s):02d}s\"\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Model/data\n",
        "    state_dim: int = 8\n",
        "    action_dim: int = 4\n",
        "    latent_dim: int = 16\n",
        "    hidden_dim: int = 128\n",
        "    # Train\n",
        "    epochs: int = 1\n",
        "    batch_size: int = 64\n",
        "    steps_per_epoch: int = 200\n",
        "    lr: float = 3e-3\n",
        "    kl_warmup_epochs: int = 1\n",
        "    # Runtime\n",
        "    seed: int = 1337\n",
        "    device: str = \"cpu\"          # cpu|cuda\n",
        "    deterministic: bool = True\n",
        "    # Planning\n",
        "    plan_depth: int = 12\n",
        "    plan_batch: int = 8\n",
        "    plan_candidates: int = 64\n",
        "    action_scale: float = 1.0\n",
        "    goal: str = \"ones\"           # ones|zeros|random\n",
        "    # I/O\n",
        "    output_dir: str = \"\"\n",
        "    save_checkpoint: bool = True\n",
        "    # Derived\n",
        "    run_tag: str = \"\"\n",
        "    config_hash: str = \"\"\n",
        "\n",
        "# ----------------------------\n",
        "# Synthetic Dynamics Dataset\n",
        "# ----------------------------\n",
        "class SyntheticDynamics(Dataset):\n",
        "    def __init__(self, state_dim, action_dim, steps_per_epoch, batch_size, traj_len=16, noise_std=0.01, seed=1234):\n",
        "        super().__init__()\n",
        "        rng = np.random.default_rng(seed)\n",
        "        # Stable A\n",
        "        A = rng.standard_normal((state_dim, state_dim)) * 0.3\n",
        "        u, s, vh = np.linalg.svd(A, full_matrices=False)\n",
        "        s = np.clip(s, 0, 0.9)\n",
        "        self.A = torch.tensor((u @ np.diag(s) @ vh).astype(np.float32))\n",
        "        self.B = torch.tensor((rng.standard_normal((state_dim, action_dim)) * 0.5).astype(np.float32))\n",
        "\n",
        "        total_pairs = steps_per_epoch * batch_size\n",
        "        num_trajs = math.ceil(total_pairs / (traj_len - 1))\n",
        "        s_list, a_list, sp_list = [], [], []\n",
        "        for _ in range(num_trajs):\n",
        "            s = torch.from_numpy(rng.standard_normal(state_dim).astype(np.float32))\n",
        "            for _t in range(traj_len - 1):\n",
        "                a = torch.from_numpy(rng.standard_normal(action_dim).astype(np.float32))\n",
        "                s_next = torch.tanh(self.A @ s + self.B @ a) + torch.randn_like(s) * noise_std\n",
        "                s_list.append(s); a_list.append(a); sp_list.append(s_next)\n",
        "                s = s_next\n",
        "        self.s = torch.stack(s_list)[:total_pairs]\n",
        "        self.a = torch.stack(a_list)[:total_pairs]\n",
        "        self.sp = torch.stack(sp_list)[:total_pairs]\n",
        "\n",
        "    def __len__(self): return self.s.shape[0]\n",
        "    def __getitem__(self, idx): return self.s[idx], self.a[idx], self.sp[idx]\n",
        "\n",
        "# ----------------------------\n",
        "# Model\n",
        "# ----------------------------\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim), nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, out_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class CondVAE(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, latent_dim=16, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.encoder = MLP(state_dim + action_dim + state_dim, 2*latent_dim, hidden_dim)\n",
        "        self.prior   = MLP(state_dim + action_dim,           2*latent_dim, hidden_dim)\n",
        "        self.decoder = MLP(state_dim + action_dim + latent_dim, state_dim, hidden_dim)\n",
        "    def posterior(self, s,a,sp): return torch.chunk(self.encoder(torch.cat([s,a,sp],-1)),2,-1)\n",
        "    def prior_params(self,s,a):  return torch.chunk(self.prior(torch.cat([s,a],-1)),2,-1)\n",
        "    def reparam(self, mu, logv): return mu + torch.randn_like(mu)*(0.5*logv).exp()\n",
        "    def kl_gauss(self, mu_q, lv_q, mu_p, lv_p):\n",
        "        v_q, v_p = lv_q.exp(), lv_p.exp()\n",
        "        kl = 0.5*(lv_p - lv_q - 1 + (v_q + (mu_q - mu_p)**2)/v_p)\n",
        "        return kl.sum(-1)\n",
        "    def decode(self,s,a,z): return self.decoder(torch.cat([s,a,z],-1))\n",
        "    def loss(self,s,a,sp,kl_w=1.0):\n",
        "        mu_q,lv_q = self.posterior(s,a,sp)\n",
        "        mu_p,lv_p = self.prior_params(s,a)\n",
        "        z = self.reparam(mu_q,lv_q)\n",
        "        sp_pred = self.decode(s,a,z)\n",
        "        recon = F.mse_loss(sp_pred, sp, reduction='none').mean(-1)\n",
        "        kl = self.kl_gauss(mu_q,lv_q,mu_p,lv_p)\n",
        "        total = recon.mean() + kl_w*kl.mean()\n",
        "        return total, {\"loss\": total, \"recon\": recon.mean(), \"kl\": kl.mean()}\n",
        "    @torch.no_grad()\n",
        "    def rollout_mean_latent(self,s0,acts):\n",
        "        T,B,_ = acts.shape\n",
        "        states=[s0]; s=s0\n",
        "        for t in range(T):\n",
        "            mu_p,_ = self.prior_params(s,acts[t])\n",
        "            sp=self.decode(s,acts[t],mu_p)\n",
        "            states.append(sp); s=sp\n",
        "        return torch.stack(states,0)\n",
        "\n",
        "# ----------------------------\n",
        "# Train & Plan\n",
        "# ----------------------------\n",
        "def train_model(cfg: Config):\n",
        "    device = torch.device(cfg.device)\n",
        "    ds = SyntheticDynamics(cfg.state_dim, cfg.action_dim, cfg.steps_per_epoch, cfg.batch_size, seed=cfg.seed)\n",
        "    dl = DataLoader(ds, batch_size=cfg.batch_size, shuffle=True, drop_last=True)\n",
        "    model = CondVAE(cfg.state_dim, cfg.action_dim, cfg.latent_dim, cfg.hidden_dim).to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
        "\n",
        "    t0 = time.time()\n",
        "    for ep in range(cfg.epochs):\n",
        "        pbar = tqdm(dl, desc=f\"train[{ep+1}/{cfg.epochs}]\", leave=False)\n",
        "        for s,a,sp in pbar:\n",
        "            s,a,sp = s.to(device), a.to(device), sp.to(device)\n",
        "            kl_w = min(1.0, (ep+1)/max(1,cfg.kl_warmup_epochs))\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            loss, st = model.loss(s,a,sp,kl_w)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            pbar.set_postfix({\"loss\": f\"{st['loss'].item():.3f}\",\n",
        "                              \"recon\": f\"{st['recon'].item():.4f}\",\n",
        "                              \"kl\": f\"{st['kl'].item():.2f}\",\n",
        "                              \"kl_w\": f\"{kl_w:.2f}\"})\n",
        "    t1 = time.time()\n",
        "\n",
        "    metrics = {\"loss\": float(st[\"loss\"]), \"recon\": float(st[\"recon\"]), \"kl\": float(st[\"kl\"])}\n",
        "    train_time = t1 - t0\n",
        "    return model, metrics, train_time\n",
        "\n",
        "@torch.no_grad()\n",
        "def plan(model: CondVAE, cfg: Config):\n",
        "    device=torch.device(cfg.device)\n",
        "    if cfg.goal=='ones': goal=torch.ones(cfg.state_dim,device=device)\n",
        "    elif cfg.goal=='zeros': goal=torch.zeros(cfg.state_dim,device=device)\n",
        "    else: goal=torch.randn(cfg.state_dim,device=device)\n",
        "\n",
        "    s0=torch.zeros(cfg.plan_batch,cfg.state_dim,device=device)\n",
        "    cand_actions=torch.randn(cfg.plan_depth,cfg.plan_candidates,cfg.action_dim,device=device)*cfg.action_scale\n",
        "\n",
        "    t0=time.time()\n",
        "    scores=[]\n",
        "    for k in range(cfg.plan_candidates):\n",
        "        acts_k=cand_actions[:,k].unsqueeze(1)  # (T,1,A)\n",
        "        s_single=s0[0:1]\n",
        "        final_state=model.rollout_mean_latent(s_single,acts_k)[-1,0]\n",
        "        scores.append(((final_state-goal)**2).mean())\n",
        "    scores=torch.stack(scores)\n",
        "    best_idx=torch.topk(-scores,k=1).indices.item()\n",
        "\n",
        "    best=cand_actions[:,best_idx].unsqueeze(1).expand(-1,cfg.plan_batch,-1).contiguous()\n",
        "    final_states=model.rollout_mean_latent(s0,best)[-1]\n",
        "    mse=((final_states-goal)**2).mean().item()\n",
        "    t1=time.time()\n",
        "    return mse, {\"best_idx\": best_idx}, (t1-t0)\n",
        "\n",
        "# ----------------------------\n",
        "# Grid runner\n",
        "# ----------------------------\n",
        "def run_grid(base_cfg: Config, seeds: List[int], plan_candidates_list: List[int], epochs_list: List[int]):\n",
        "    out_dir = base_cfg.output_dir or os.path.join(\"runs\", f\"grid-{now_tag()}\")\n",
        "    ensure_dir(out_dir)\n",
        "    metrics_path = os.path.join(out_dir, \"metrics.csv\")\n",
        "    header = [\n",
        "        \"timestamp\",\"config_hash\",\"device\",\"deterministic\",\"seed\",\n",
        "        \"epochs\",\"steps_per_epoch\",\"batch_size\",\"lr\",\"kl_warmup_epochs\",\n",
        "        \"plan_depth\",\"plan_batch\",\"plan_candidates\",\"action_scale\",\"goal\",\n",
        "        \"loss\",\"recon\",\"kl\",\"train_time\",\"plan_time\",\"planner_mse\",\"checkpoint\"\n",
        "    ]\n",
        "    print(f\"[grid] Output: {out_dir}\")\n",
        "    for seed in seeds:\n",
        "        for pc in plan_candidates_list:\n",
        "            for ep in epochs_list:\n",
        "                cfg = base_cfg\n",
        "                cfg.seed = seed; cfg.plan_candidates = pc; cfg.epochs = ep\n",
        "                cfg.run_tag = now_tag()\n",
        "                cd = asdict(cfg).copy(); cd.pop(\"run_tag\", None); cd.pop(\"config_hash\", None)\n",
        "                cfg.config_hash = cfg_hash(cd)\n",
        "                run_dir = os.path.join(out_dir, f\"{cfg.config_hash}-{cfg.run_tag}\")\n",
        "                ensure_dir(run_dir)\n",
        "\n",
        "                set_deterministic(cfg.deterministic); set_seed(cfg.seed)\n",
        "                if cfg.device == \"cuda\" and not torch.cuda.is_available():\n",
        "                    print(\"[warn] CUDA not available, falling back to CPU\"); cfg.device = \"cpu\"\n",
        "\n",
        "                model, tr_metrics, train_time = train_model(cfg)\n",
        "                mse, info, plan_time = plan(model, cfg)\n",
        "\n",
        "                ckpt_path = \"\"\n",
        "                if cfg.save_checkpoint:\n",
        "                    ckpt_path = os.path.join(run_dir, \"model.pt\")\n",
        "                    torch.save({\"model\": model.state_dict(), \"cfg\": asdict(cfg)}, ckpt_path)\n",
        "                    write_json(os.path.join(run_dir, \"config.json\"), asdict(cfg))\n",
        "\n",
        "                row = {\n",
        "                    \"timestamp\": cfg.run_tag,\n",
        "                    \"config_hash\": cfg.config_hash,\n",
        "                    \"device\": cfg.device,\n",
        "                    \"deterministic\": cfg.deterministic,\n",
        "                    \"seed\": cfg.seed,\n",
        "                    \"epochs\": cfg.epochs,\n",
        "                    \"steps_per_epoch\": cfg.steps_per_epoch,\n",
        "                    \"batch_size\": cfg.batch_size,\n",
        "                    \"lr\": cfg.lr,\n",
        "                    \"kl_warmup_epochs\": cfg.kl_warmup_epochs,\n",
        "                    \"plan_depth\": cfg.plan_depth,\n",
        "                    \"plan_batch\": cfg.plan_batch,\n",
        "                    \"plan_candidates\": cfg.plan_candidates,\n",
        "                    \"action_scale\": cfg.action_scale,\n",
        "                    \"goal\": cfg.goal,\n",
        "                    \"loss\": tr_metrics.get(\"loss\", float(\"nan\")),\n",
        "                    \"recon\": tr_metrics.get(\"recon\", float(\"nan\")),\n",
        "                    \"kl\": tr_metrics.get(\"kl\", float(\"nan\")),\n",
        "                    \"train_time\": train_time,\n",
        "                    \"plan_time\": plan_time,\n",
        "                    \"planner_mse\": mse,\n",
        "                    \"checkpoint\": ckpt_path,\n",
        "                }\n",
        "                append_csv(metrics_path, header, row)\n",
        "                print(f\"[grid][{cfg.config_hash}] seed={cfg.seed} epochs={cfg.epochs} cand={cfg.plan_candidates} \"\n",
        "                      f\"| loss={row['loss']:.3f} mse={mse:.4f}\")\n",
        "\n",
        "    print(f\"[grid] Done. Metrics CSV at: {metrics_path}\")\n",
        "    return metrics_path\n",
        "\n",
        "# ----------------------------\n",
        "# CLI\n",
        "# ----------------------------\n",
        "def build_parser():\n",
        "    p = argparse.ArgumentParser(description=\"UnifiedAI (Notebook/CLI friendly)\", add_help=True)\n",
        "    # Modes\n",
        "    p.add_argument(\"--mode\", choices={\"run\", \"grid\"}, default=\"run\", help=\"run once or grid sweep\")\n",
        "    # Model/data\n",
        "    p.add_argument(\"--state_dim\", type=int, default=8)\n",
        "    p.add_argument(\"--action_dim\", type=int, default=4)\n",
        "    p.add_argument(\"--latent_dim\", type=int, default=16)\n",
        "    p.add_argument(\"--hidden_dim\", type=int, default=128)\n",
        "    # Train\n",
        "    p.add_argument(\"--epochs\", type=int, default=1)\n",
        "    p.add_argument(\"--batch_size\", type=int, default=64)\n",
        "    p.add_argument(\"--steps_per_epoch\", type=int, default=200)\n",
        "    p.add_argument(\"--lr\", type=float, default=3e-3)\n",
        "    p.add_argument(\"--kl_warmup_epochs\", type=int, default=1)\n",
        "    # Runtime\n",
        "    p.add_argument(\"--seed\", type=int, default=1337)\n",
        "    p.add_argument(\"--device\", choices={\"cpu\",\"cuda\"}, default=\"cpu\")\n",
        "    p.add_argument(\"--deterministic\", type=lambda x: str(x).lower() in {\"1\",\"true\",\"yes\",\"y\"}, default=True)\n",
        "    # Planning\n",
        "    p.add_argument(\"--plan_depth\", type=int, default=12)\n",
        "    p.add_argument(\"--plan_batch\", type=int, default=8)\n",
        "    p.add_argument(\"--plan_candidates\", type=int, default=64)\n",
        "    p.add_argument(\"--action_scale\", type=float, default=1.0)\n",
        "    p.add_argument(\"--goal\", choices={\"ones\",\"zeros\",\"random\"}, default=\"ones\")\n",
        "    # I/O\n",
        "    p.add_argument(\"--output_dir\", type=str, default=\"\")\n",
        "    p.add_argument(\"--save_checkpoint\", type=lambda x: str(x).lower() in {\"1\",\"true\",\"yes\",\"y\"}, default=True)\n",
        "    # Grid params\n",
        "    p.add_argument(\"--grid_seeds\", type=str, default=\"\")\n",
        "    p.add_argument(\"--grid_plan_candidates\", type=str, default=\"\")\n",
        "    p.add_argument(\"--grid_epochs\", type=str, default=\"\")\n",
        "    return p\n",
        "\n",
        "def args_to_cfg(args: argparse.Namespace) -> Config:\n",
        "    cfg = Config(\n",
        "        state_dim=args.state_dim, action_dim=args.action_dim,\n",
        "        latent_dim=args.latent_dim, hidden_dim=args.hidden_dim,\n",
        "        epochs=args.epochs, batch_size=args.batch_size, steps_per_epoch=args.steps_per_epoch,\n",
        "        lr=args.lr, kl_warmup_epochs=args.kl_warmup_epochs,\n",
        "        seed=args.seed, device=args.device, deterministic=args.deterministic,\n",
        "        plan_depth=args.plan_depth, plan_batch=args.plan_batch,\n",
        "        plan_candidates=args.plan_candidates, action_scale=args.action_scale, goal=args.goal,\n",
        "        output_dir=args.output_dir, save_checkpoint=args.save_checkpoint,\n",
        "    )\n",
        "    cfg.run_tag = now_tag()\n",
        "    cd = asdict(cfg).copy(); cd.pop(\"run_tag\", None); cd.pop(\"config_hash\", None)\n",
        "    cfg.config_hash = cfg_hash(cd)\n",
        "    return cfg\n",
        "\n",
        "def parse_list_arg(text: str, fallback: List[int]) -> List[int]:\n",
        "    if not text: return fallback\n",
        "    return [int(x.strip()) for x in text.split(\",\") if x.strip()]\n",
        "\n",
        "def main():\n",
        "    parser = build_parser()\n",
        "    args, _unknown = parser.parse_known_args()  # notebook-safe\n",
        "    if args.device == \"cuda\" and not torch.cuda.is_available():\n",
        "        print(\"[warn] CUDA not available, falling back to CPU\"); args.device = \"cpu\"\n",
        "\n",
        "    cfg = args_to_cfg(args)\n",
        "    set_deterministic(cfg.deterministic); set_seed(cfg.seed)\n",
        "\n",
        "    if not cfg.output_dir:\n",
        "        cfg.output_dir = os.path.join(\"runs\", f\"{'grid' if args.mode=='grid' else 'run'}-{cfg.config_hash}-{cfg.run_tag}\")\n",
        "    ensure_dir(cfg.output_dir)\n",
        "\n",
        "    print(f\"[config] {cfg}\")\n",
        "\n",
        "    if args.mode == \"grid\":\n",
        "        seeds = parse_list_arg(args.grid_seeds, [cfg.seed])\n",
        "        cand_list = parse_list_arg(args.grid_plan_candidates, [cfg.plan_candidates])\n",
        "        epochs_list = parse_list_arg(args.grid_epochs, [cfg.epochs])\n",
        "        run_grid(cfg, seeds, cand_list, epochs_list)\n",
        "        print(f\"[summary] GRID COMPLETE -> {cfg.output_dir}\")\n",
        "        return\n",
        "\n",
        "    # Single run\n",
        "    t0 = time.time()\n",
        "    model, tr_metrics, train_time = train_model(cfg)\n",
        "    mse, info, plan_time = plan(model, cfg)\n",
        "\n",
        "    ckpt_path = \"\"\n",
        "    if cfg.save_checkpoint:\n",
        "        ckpt_path = os.path.join(cfg.output_dir, \"model.pt\")\n",
        "        torch.save({\"model\": model.state_dict(), \"cfg\": asdict(cfg)}, ckpt_path)\n",
        "        write_json(os.path.join(cfg.output_dir, \"config.json\"), asdict(cfg))\n",
        "\n",
        "    metrics_path = os.path.join(cfg.output_dir, \"metrics.csv\")\n",
        "    header = [\n",
        "        \"timestamp\",\"config_hash\",\"device\",\"deterministic\",\"seed\",\n",
        "        \"epochs\",\"steps_per_epoch\",\"batch_size\",\"lr\",\"kl_warmup_epochs\",\n",
        "        \"plan_depth\",\"plan_batch\",\"plan_candidates\",\"action_scale\",\"goal\",\n",
        "        \"loss\",\"recon\",\"kl\",\"train_time\",\"plan_time\",\"planner_mse\",\"checkpoint\"\n",
        "    ]\n",
        "    row = {\n",
        "        \"timestamp\": cfg.run_tag, \"config_hash\": cfg.config_hash,\n",
        "        \"device\": cfg.device, \"deterministic\": cfg.deterministic, \"seed\": cfg.seed,\n",
        "        \"epochs\": cfg.epochs, \"steps_per_epoch\": cfg.steps_per_epoch, \"batch_size\": cfg.batch_size,\n",
        "        \"lr\": cfg.lr, \"kl_warmup_epochs\": cfg.kl_warmup_epochs,\n",
        "        \"plan_depth\": cfg.plan_depth, \"plan_batch\": cfg.plan_batch,\n",
        "        \"plan_candidates\": cfg.plan_candidates, \"action_scale\": cfg.action_scale, \"goal\": cfg.goal,\n",
        "        \"loss\": tr_metrics.get(\"loss\", float(\"nan\")),\n",
        "        \"recon\": tr_metrics.get(\"recon\", float(\"nan\")),\n",
        "        \"kl\": tr_metrics.get(\"kl\", float(\"nan\")),\n",
        "        \"train_time\": train_time, \"plan_time\": plan_time, \"planner_mse\": mse,\n",
        "        \"checkpoint\": ckpt_path,\n",
        "    }\n",
        "    append_csv(metrics_path, header, row)\n",
        "\n",
        "    print(f\"[planner] Best idx={info['best_idx']} Mean final MSE={mse:.4f}\")\n",
        "    total_time = time.time() - t0\n",
        "    print(f\"[summary] RUN COMPLETE | train={human_time(train_time)} plan={human_time(plan_time)} total={human_time(total_time)} \"\n",
        "          f\"| loss={row['loss']:.3f} mse={mse:.4f} | out={cfg.output_dir}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "5zDMN9VFu12E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPWovTZOzcyD8dMOsLjMmbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/unified_ai_core_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRp3TSRxNvZu"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import timm\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "\n",
        "# ---------- 1. Perception ----------------------------------------------------\n",
        "class VisionEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim=1024):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            'vit_large_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
        "            pretrained=True, num_classes=0\n",
        "        )\n",
        "        self.proj = nn.Linear(self.backbone.embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.proj(self.backbone(img))  # (B, N_tokens, embed_dim)\n",
        "\n",
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, vocab_path, embed_dim=1024):\n",
        "        super().__init__()\n",
        "        self.tok = SentencePieceProcessor(model_file=vocab_path)\n",
        "        self.embed = nn.Embedding(self.tok.get_piece_size(), embed_dim)\n",
        "\n",
        "    def forward(self, txt):\n",
        "        ids = torch.tensor(self.tok.encode(txt, out_type=int), device=self.embed.weight.device)\n",
        "        return self.embed(ids)  # (T, embed_dim)\n",
        "\n",
        "# ---------- 2. Memory --------------------------------------------------------\n",
        "class EpisodicMemory(nn.Module):\n",
        "    def __init__(self, dim=1024, slots=4096):\n",
        "        super().__init__()\n",
        "        self.keys   = nn.Parameter(torch.randn(slots, dim))\n",
        "        self.values = nn.Parameter(torch.randn(slots, dim))\n",
        "\n",
        "    def write(self, k, v):\n",
        "        idx = torch.argmax((self.keys @ k.T).diag())  # overwrite closest slot\n",
        "        self.keys.data[idx]   = k.detach()\n",
        "        self.values.data[idx] = v.detach()\n",
        "\n",
        "    def read(self, q):  # q: (B, dim)\n",
        "        scores = q @ self.keys.T\n",
        "        w = F.softmax(scores, dim=-1)\n",
        "        return w @ self.values  # (B, dim)\n",
        "\n",
        "# ---------- 3. Latent World Model -------------------------------------------\n",
        "class LatentRSSM(nn.Module):\n",
        "    def __init__(self, latent=256, action_dim=32, obs_dim=1024):\n",
        "        super().__init__()\n",
        "        self.rnn   = nn.GRU(latent + action_dim, latent, batch_first=True)\n",
        "        self.post  = nn.Linear(latent + obs_dim, 2 * latent)\n",
        "        self.prior = nn.Linear(latent, 2 * latent)\n",
        "\n",
        "    def forward(self, prev_state, action, obs_embed):\n",
        "        rnn_input = torch.cat([prev_state, action], -1)\n",
        "        _, h = self.rnn(rnn_input.unsqueeze(0))\n",
        "        post_stats  = self.post(torch.cat([h.squeeze(0), obs_embed], -1))\n",
        "        prior_stats = self.prior(h.squeeze(0))\n",
        "        return post_stats, prior_stats, h.squeeze(0)\n",
        "\n",
        "# ---------- 4. Planner -------------------------------------------------------\n",
        "class HybridPlanner(nn.Module):\n",
        "    def __init__(self, llm, rssm, max_depth=5):\n",
        "        super().__init__()\n",
        "        self.llm = llm\n",
        "        self.rssm = rssm\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def plan(self, goal_desc, init_state):\n",
        "        prelim_plan = self.llm.chain_of_thought(goal_desc)\n",
        "        if not pddl_validator(prelim_plan):\n",
        "            prelim_plan = self.llm.fix(plan=prelim_plan)\n",
        "        return self.imagine(prelim_plan, init_state)\n",
        "\n",
        "    def imagine(self, plan, state):\n",
        "        traj, total_reward = [], 0.0\n",
        "        for t in range(self.max_depth):\n",
        "            act = textual_policy_to_action(plan[t])\n",
        "            _, prior_stats, state = self.rssm(state, act, obs_embed=None)\n",
        "            state = reparam(prior_stats)\n",
        "            r_t = reward_head(state)\n",
        "            traj.append((state, act, r_t))\n",
        "            total_reward += r_t\n",
        "        return traj, total_reward"
      ]
    }
  ]
}
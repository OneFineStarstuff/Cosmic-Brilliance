{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN8D37aONPO/k3hpCY43ygR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/unified_ai_core_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wH6Wr_TqWobP"
      },
      "outputs": [],
      "source": [
        "# unified_ai/core.py\n",
        "from __future__ import annotations\n",
        "from typing import List, Optional, Tuple, Callable, Union\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Optional deps; guarded for mock paths\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    timm = None\n",
        "\n",
        "try:\n",
        "    from sentencepiece import SentencePieceProcessor\n",
        "except Exception:\n",
        "    SentencePieceProcessor = None\n",
        "\n",
        "\n",
        "# ===== Utils =====\n",
        "\n",
        "def default_device() -> torch.device:\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def reparam_gauss(stats: torch.Tensor, rng: Optional[torch.Generator] = None) -> torch.Tensor:\n",
        "    mu, logvar = torch.chunk(stats, 2, dim=-1)\n",
        "    std = (0.5 * logvar).exp()\n",
        "    eps = torch.randn_like(std, generator=rng)\n",
        "    return mu + eps * std\n",
        "\n",
        "def kl_gauss(post: torch.Tensor, prior: torch.Tensor, reduce: bool = True) -> torch.Tensor:\n",
        "    mu_p, lv_p = torch.chunk(post, 2, dim=-1)\n",
        "    mu_q, lv_q = torch.chunk(prior, 2, dim=-1)\n",
        "    kl = 0.5 * (lv_q - lv_p + (lv_p.exp() + (mu_p - mu_q).pow(2)) / lv_q.exp() - 1.0).sum(-1)\n",
        "    return kl.mean() if reduce else kl\n",
        "\n",
        "def maybe_norm(x: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
        "    return x / (x.norm(dim=-1, keepdim=True) + eps)\n",
        "\n",
        "def pair_rotate(x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> torch.Tensor:\n",
        "    x1, x2 = x[..., ::2], x[..., 1::2]\n",
        "    y1 = x1 * cos - x2 * sin\n",
        "    y2 = x1 * sin + x2 * cos\n",
        "    return torch.stack([y1, y2], dim=-1).flatten(-2)\n",
        "\n",
        "def build_rope_cache(seq_len: int, dim: int, base: float = 10000.0, device=None, dtype=None):\n",
        "    half = dim // 2\n",
        "    idx = torch.arange(half, device=device, dtype=dtype)\n",
        "    freqs = 1.0 / (base ** (idx / half))\n",
        "    t = torch.arange(seq_len, device=device, dtype=dtype).unsqueeze(1)\n",
        "    angles = t * freqs.unsqueeze(0)\n",
        "    cos = torch.cos(angles).repeat_interleave(2, dim=-1)\n",
        "    sin = torch.sin(angles).repeat_interleave(2, dim=-1)\n",
        "    return cos, sin\n",
        "\n",
        "\n",
        "# ===== Perception =====\n",
        "\n",
        "class VisionEncoder(nn.Module):\n",
        "    \"\"\"ViT/Swin backbone with optional freezing and projection.\"\"\"\n",
        "    def __init__(self, model_name: str = \"vit_base_patch16_224\", embed_dim: int = 1024, freeze_blocks: int = 6, global_pool: str = \"\"):\n",
        "        super().__init__()\n",
        "        assert timm is not None, \"timm is required for VisionEncoder\"\n",
        "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool=global_pool)\n",
        "        if hasattr(self.backbone, \"patch_embed\"):\n",
        "            for p in self.backbone.patch_embed.parameters():\n",
        "                p.requires_grad = False\n",
        "        if hasattr(self.backbone, \"blocks\"):\n",
        "            for i, blk in enumerate(self.backbone.blocks):\n",
        "                req = i >= freeze_blocks\n",
        "                for p in blk.parameters():\n",
        "                    p.requires_grad = req\n",
        "        feat_dim = getattr(self.backbone, \"num_features\", getattr(self.backbone, \"embed_dim\"))\n",
        "        self.proj = nn.Linear(feat_dim, embed_dim)\n",
        "\n",
        "    def forward(self, img: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.backbone.forward_features(img)\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "        return self.proj(x)  # (B, N, E)\n",
        "\n",
        "\n",
        "class MockVisionEncoder(nn.Module):\n",
        "    \"\"\"Lightweight, dependency-free visual token generator.\"\"\"\n",
        "    def __init__(self, embed_dim: int = 1024, tokens: int = 16):\n",
        "        super().__init__()\n",
        "        self.tokens = tokens\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
        "            nn.GELU(),\n",
        "            nn.AdaptiveAvgPool2d((tokens, 1)),\n",
        "        )\n",
        "        self.proj = nn.Linear(64, embed_dim)\n",
        "\n",
        "    def forward(self, img: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.mlp(img)           # (B, 64, T, 1)\n",
        "        x = x.squeeze(-1).transpose(1, 2)  # (B, T, 64)\n",
        "        return self.proj(x)         # (B, T, E)\n",
        "\n",
        "\n",
        "class TextEncoder(nn.Module):\n",
        "    \"\"\"SentencePiece tokenization + embedding + RoPE.\"\"\"\n",
        "    def __init__(self, vocab_path: str, embed_dim: int = 1024, max_len: int = 512, rope_base: float = 10000.0):\n",
        "        super().__init__()\n",
        "        assert SentencePieceProcessor is not None, \"sentencepiece is required for TextEncoder\"\n",
        "        self.tok = SentencePieceProcessor(vocab_path)\n",
        "        self.vocab_size = self.tok.get_piece_size()\n",
        "        self.embed = nn.Embedding(self.vocab_size, embed_dim)\n",
        "        self.max_len = max_len\n",
        "        self.rope_base = rope_base\n",
        "\n",
        "    def tokenize(self, texts: Union[str, List[str]]):\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "        ids = [self.tok.encode(t, out_type=int)[: self.max_len] for t in texts]\n",
        "        max_t = max(len(x) for x in ids) if ids else 1\n",
        "        pad_id = self.tok.pad_id() if hasattr(self.tok, \"pad_id\") and self.tok.pad_id() >= 0 else 0\n",
        "        toks = torch.full((len(ids), max_t), pad_id, dtype=torch.long)\n",
        "        mask = torch.zeros((len(ids), max_t), dtype=torch.bool)\n",
        "        for i, seq in enumerate(ids):\n",
        "            L = len(seq)\n",
        "            toks[i, :L] = torch.tensor(seq, dtype=torch.long)\n",
        "            mask[i, :L] = True\n",
        "        return toks, mask\n",
        "\n",
        "    def forward(self, texts: Union[str, List[str]]):\n",
        "        toks, mask = self.tokenize(texts)\n",
        "        device = self.embed.weight.device\n",
        "        toks, mask = toks.to(device), mask.to(device)\n",
        "        x = self.embed(toks)\n",
        "        T, E = x.shape[1], x.shape[2]\n",
        "        pad = False\n",
        "        if E % 2 != 0:\n",
        "            x = F.pad(x, (0, 1))\n",
        "            E += 1\n",
        "            pad = True\n",
        "        cos, sin = build_rope_cache(T, E, base=self.rope_base, device=device, dtype=x.dtype)\n",
        "        x = pair_rotate(x, cos[None, ...], sin[None, ...])\n",
        "        if pad:\n",
        "            x = x[..., : self.embed.embedding_dim]\n",
        "        return x, mask  # (B, T, E), (B, T)\n",
        "\n",
        "\n",
        "class MockTextEncoder(nn.Module):\n",
        "    \"\"\"Dependency-free text embedding with sinusoidal positions.\"\"\"\n",
        "    def __init__(self, vocab_size: int = 32000, embed_dim: int = 1024, max_len: int = 128):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def forward(self, texts: Union[str, List[str]]):\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "        toks = [[(ord(c) % 255) + 1 for c in t][: self.max_len] for t in texts]\n",
        "        max_t = max(len(x) for x in toks) if toks else 1\n",
        "        pad_id = 0\n",
        "        ids = torch.full((len(toks), max_t), pad_id, dtype=torch.long)\n",
        "        mask = torch.zeros((len(toks), max_t), dtype=torch.bool)\n",
        "        for i, seq in enumerate(toks):\n",
        "            L = len(seq)\n",
        "            ids[i, :L] = torch.tensor(seq, dtype=torch.long)\n",
        "            mask[i, :L] = True\n",
        "        x = self.embed(ids.to(self.embed.weight.device))\n",
        "        pos = torch.arange(max_t, device=x.device).float()\n",
        "        pe = torch.stack([torch.sin(pos / 10000**(2*k/x.size(-1))) if k % 2 == 0 else torch.cos(pos / 10000**(2*(k-1)/x.size(-1))) for k in range(x.size(-1))], dim=-1)\n",
        "        x = x + pe.unsqueeze(0)\n",
        "        return x, mask.to(x.device)\n",
        "\n",
        "\n",
        "# ===== Fusion and heads =====\n",
        "\n",
        "class TokenPool(nn.Module):\n",
        "    \"\"\"Simple attention pooling over tokens.\"\"\"\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.q = nn.Parameter(torch.randn(dim))\n",
        "\n",
        "    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        # x: (B, T, E), mask: (B, T)\n",
        "        q = self.q[None, None, :]            # (1,1,E)\n",
        "        attn = (x * q).sum(-1)               # (B, T)\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(~mask, -1e9)\n",
        "        w = attn.softmax(-1)\n",
        "        return (w.unsqueeze(-1) * x).sum(1)  # (B, E)\n",
        "\n",
        "class FusionObsEncoder(nn.Module):\n",
        "    \"\"\"Fuse vision and text into a fixed obs embedding.\"\"\"\n",
        "    def __init__(self, embed_dim: int = 1024, obs_dim: int = 1024):\n",
        "        super().__init__()\n",
        "        self.v_pool = TokenPool(embed_dim)\n",
        "        self.t_pool = TokenPool(embed_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.Linear(embed_dim * 2, obs_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(obs_dim, obs_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, v_tokens: torch.Tensor, t_tokens: torch.Tensor, t_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        v = self.v_pool(v_tokens, None)\n",
        "        t = self.t_pool(t_tokens, t_mask)\n",
        "        x = torch.cat([v, t], dim=-1)\n",
        "        return self.mlp(x)  # (B, obs_dim)\n",
        "\n",
        "class RewardHead(nn.Module):\n",
        "    \"\"\"Score from deterministic state h.\"\"\"\n",
        "    def __init__(self, latent: int = 256):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.LayerNorm(latent),\n",
        "            nn.Linear(latent, latent // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(latent // 2, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, h: torch.Tensor) -> torch.Tensor:\n",
        "        return self.mlp(h).squeeze(-1)  # (B,)\n",
        "\n",
        "class ObsDecoder(nn.Module):\n",
        "    \"\"\"Decode obs embedding from h and z.\"\"\"\n",
        "    def __init__(self, latent: int = 256, obs_dim: int = 1024):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LayerNorm(latent * 2),\n",
        "            nn.Linear(latent * 2, obs_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(obs_dim, obs_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, h: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(torch.cat([h, z], dim=-1))  # (B, obs_dim)\n",
        "\n",
        "\n",
        "# ===== Episodic memory =====\n",
        "\n",
        "class EpisodicMemory(nn.Module):\n",
        "    \"\"\"Cosine attention reads; EMA/ring writes (buffers, no autograd).\"\"\"\n",
        "    def __init__(self, dim: int = 1024, slots: int = 1024, temperature: float = 0.1, ema: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.dim, self.slots = dim, slots\n",
        "        self.temperature, self.ema = temperature, ema\n",
        "        self.register_buffer(\"keys\", F.normalize(torch.randn(slots, dim), dim=-1))\n",
        "        self.register_buffer(\"values\", torch.zeros(slots, dim))\n",
        "        self.register_buffer(\"age\", torch.zeros(slots, dtype=torch.long))\n",
        "        self.register_buffer(\"ptr\", torch.zeros((), dtype=torch.long))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def write(self, k: torch.Tensor, v: torch.Tensor, strategy: str = \"nearest\"):\n",
        "        k = k.unsqueeze(0) if k.dim() == 1 else k\n",
        "        v = v.unsqueeze(0) if v.dim() == 1 else v\n",
        "        k = maybe_norm(k)\n",
        "        if strategy == \"ring\":\n",
        "            for i in range(k.size(0)):\n",
        "                idx = int(self.ptr.item() % self.slots)\n",
        "                self.keys[idx] = k[i]\n",
        "                self.values[idx] = v[i]\n",
        "                self.age[idx] = 0\n",
        "                self.ptr += 1\n",
        "        else:\n",
        "            sims = (maybe_norm(self.keys) @ k.T)  # (S,B)\n",
        "            idxs = sims.argmax(dim=0)\n",
        "            for i, idx in enumerate(idxs.tolist()):\n",
        "                self.keys[idx] = F.normalize((1 - self.ema) * self.keys[idx] + self.ema * k[i], dim=-1)\n",
        "                self.values[idx] = (1 - self.ema) * self.values[idx] + self.ema * v[i]\n",
        "                self.age[idx] = 0\n",
        "        self.age += 1\n",
        "\n",
        "    def read(self, q: torch.Tensor, topk: int = 0) -> torch.Tensor:\n",
        "        single = q.dim() == 1\n",
        "        q = q.unsqueeze(0) if single else q\n",
        "        logits = (maybe_norm(q) @ maybe_norm(self.keys).T) / self.temperature\n",
        "        if topk and topk < self.slots:\n",
        "            vals, idxs = logits.topk(topk, dim=-1)\n",
        "            w = F.softmax(vals, dim=-1)\n",
        "            out = (w.unsqueeze(-1) * self.values[idxs]).sum(1)\n",
        "        else:\n",
        "            w = F.softmax(logits, dim=-1)\n",
        "            out = w @ self.values\n",
        "        return out.squeeze(0) if single else out\n",
        "\n",
        "\n",
        "# ===== RSSM =====\n",
        "\n",
        "class LatentRSSM(nn.Module):\n",
        "    \"\"\"Dreamer-style RSSM with deterministic h and stochastic z.\"\"\"\n",
        "    def __init__(self, latent: int = 256, action_dim: int = 32, obs_dim: int = 1024):\n",
        "        super().__init__()\n",
        "        self.latent, self.action_dim, self.obs_dim = latent, action_dim, obs_dim\n",
        "        self.gru = nn.GRUCell(latent + action_dim, latent)\n",
        "        self.prior = nn.Sequential(nn.LayerNorm(latent), nn.Linear(latent, 2 * latent))\n",
        "        self.post = nn.Sequential(nn.LayerNorm(latent + obs_dim), nn.Linear(latent + obs_dim, 2 * latent))\n",
        "\n",
        "    def init_state(self, batch: int, device=None):\n",
        "        device = device or default_device()\n",
        "        h = torch.zeros(batch, self.latent, device=device)\n",
        "        z = torch.zeros(batch, self.latent, device=device)\n",
        "        return h, z\n",
        "\n",
        "    def step(self, h: torch.Tensor, z: torch.Tensor, action: torch.Tensor, obs_embed: Optional[torch.Tensor] = None, rng: Optional[torch.Generator] = None):\n",
        "        x = torch.cat([z, action], dim=-1)\n",
        "        h = self.gru(x, h)\n",
        "        prior_stats = self.prior(h)\n",
        "        if obs_embed is not None:\n",
        "            post_stats = self.post(torch.cat([h, obs_embed], dim=-1))\n",
        "            z = reparam_gauss(post_stats, rng=rng)\n",
        "        else:\n",
        "            post_stats = None\n",
        "            z = reparam_gauss(prior_stats, rng=rng)\n",
        "        return h, z, prior_stats, post_stats\n",
        "\n",
        "\n",
        "# ===== Planner =====\n",
        "\n",
        "class HybridPlanner(nn.Module):\n",
        "    \"\"\"LLM-guided plan -> optional validation -> RSSM rollout prior.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        llm,\n",
        "        rssm: LatentRSSM,\n",
        "        action_fn: Callable[[str, torch.device, int], torch.Tensor],\n",
        "        reward_fn: Callable[[torch.Tensor], torch.Tensor],\n",
        "        validate_fn: Optional[Callable[[List[str]], bool]] = None,\n",
        "        max_depth: int = 5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.llm, self.rssm = llm, rssm\n",
        "        self.action_fn, self.reward_fn = action_fn, reward_fn\n",
        "        self.validate_fn, self.max_depth = validate_fn, max_depth\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def plan(self, goal_desc: str, init_h: torch.Tensor, init_z: torch.Tensor, batch: int = 1):\n",
        "        steps: List[str] = self.llm.propose_actions(goal_desc, max_steps=self.max_depth)\n",
        "        if self.validate_fn is not None and not self.validate_fn(steps):\n",
        "            steps = self.llm.revise_actions(plan=steps, max_steps=self.max_depth)\n",
        "\n",
        "        device = init_h.device\n",
        "        h, z = init_h, init_z\n",
        "        traj, total_reward = [], torch.zeros((), device=device)\n",
        "        for t, s in enumerate(steps[: self.max_depth]):\n",
        "            act = self.action_fn(s, device, self.rssm.action_dim)\n",
        "            act = act.unsqueeze(0) if act.dim() == 1 else act\n",
        "            if act.size(0) != batch:\n",
        "                act = act.expand(batch, -1)\n",
        "            h, z, prior_stats, _ = self.rssm.step(h, z, act, obs_embed=None)\n",
        "            r_t = self.reward_fn(h)  # (B,)\n",
        "            total_reward = total_reward + r_t.mean()\n",
        "            traj.append((h.clone(), act.clone(), r_t.clone()))\n",
        "        return traj, total_reward"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPucAEvJ7FIhEI2FYaMIXb7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_space_time_network_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYRQt27NAbmB"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_space_time_network_ai.py\n",
        "\n",
        "Physics-informed AI pipeline for SpaceTimeNetworkAI with NaN safety.\n",
        "\n",
        "1. Synthetic dataset: wormhole stability, warp field, temporal distortions, exotic energy, cosmic flux, spatial curvature\n",
        "2. Float32 normalization and dtype consistency\n",
        "3. MLP with LayerNorm, Dropout, ReLU\n",
        "4. Physics-informed residual with denominator clamps\n",
        "5. MC-Dropout for uncertainty quantification\n",
        "6. Training loop: AdamW, ReduceLROnPlateau, gradient clipping, NaN checks, early stopping\n",
        "7. Safe checkpoint load\n",
        "8. Visualizations: losses, scatter, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Space-Time Network Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class SpaceTimeNetworkDataset(Dataset):\n",
        "    def __init__(self, n_samples=6000, seed=0):\n",
        "        np.random.seed(seed)\n",
        "        # Features:\n",
        "        # WS ∈ [0.5,1.5], WF ∈ [1e2,1e4], TD ∈ [0,0.1], EE ∈ [1e-9,1e-7], CF ∈ [0,1], SC ∈ [0.1,1]\n",
        "        WS = np.random.uniform(0.5, 1.5,   (n_samples,1))\n",
        "        WF = np.random.uniform(1e2, 1e4,   (n_samples,1))\n",
        "        TD = np.random.uniform(0.0, 0.1,   (n_samples,1))\n",
        "        EE = np.random.uniform(1e-9,1e-7,  (n_samples,1))\n",
        "        CF = np.random.uniform(0.0, 1.0,   (n_samples,1))\n",
        "        SC = np.random.uniform(0.1, 1.0,   (n_samples,1))\n",
        "\n",
        "        X_raw = np.hstack([WS, WF, TD, EE, CF, SC]).astype(np.float64)\n",
        "\n",
        "        # Physics targets:\n",
        "        # GS = WS * CF / (TD + eps)\n",
        "        # OC = SC * WF / (EE + eps)\n",
        "        # MEC = EE * WF * SC\n",
        "        eps = 1e-6\n",
        "        GS  = WS * CF / (TD + eps)\n",
        "        OC  = SC * WF / (EE + eps)\n",
        "        MEC = EE * WF * SC\n",
        "\n",
        "        Y_raw = np.hstack([GS, OC, MEC]).astype(np.float64)\n",
        "        Y_raw += 0.01 * Y_raw.std(axis=0) * np.random.randn(*Y_raw.shape)\n",
        "\n",
        "        # Stats\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0) + 1e-8\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0) + 1e-8\n",
        "\n",
        "        # Normalize to float32\n",
        "        self.X = ((X_raw - self.X_mean) / self.X_std).astype(np.float32)\n",
        "        self.Y = ((Y_raw - self.Y_mean) / self.Y_std).astype(np.float32)\n",
        "\n",
        "        print(f\"Dataset X range {self.X.min():.3e}–{self.X.max():.3e}\")\n",
        "        print(f\"Dataset Y range {self.Y.min():.3e}–{self.Y.max():.3e}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return torch.from_numpy(self.X[i]), torch.from_numpy(self.Y[i])\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model Definition with hidden_dims int-handling\n",
        "# ------------------------------------------------------------------------------\n",
        "class SpaceTimeNetworkAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dims=(64, 64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        # Allow an int for hidden_dims\n",
        "        if isinstance(hidden_dims, int):\n",
        "            hidden_dims = (hidden_dims,)\n",
        "\n",
        "        layers, dim = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim = h\n",
        "\n",
        "        layers.append(nn.Linear(dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Loss with Clamps\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, X, stats):\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    WS, WF, TD, EE, CF, SC = X_den.t()\n",
        "    eps = 1e-4\n",
        "    GS_t  = WS * CF / torch.clamp(TD + eps, min=eps)\n",
        "    OC_t  = SC * WF / torch.clamp(EE + eps, min=eps)\n",
        "    MEC_t = EE * WF * SC\n",
        "\n",
        "    Yt = torch.stack([GS_t, OC_t, MEC_t], dim=1)\n",
        "    Yt_norm = (Yt - stats['Y_mean']) / stats['Y_std']\n",
        "    return nn.MSELoss()(pred, Yt_norm)\n",
        "\n",
        "def total_loss(pred, true, X, stats, lam=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, X, stats)\n",
        "    return mse + lam * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout Uncertainty\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    arr = torch.stack(preds, 0)\n",
        "    return arr.mean(0), arr.std(0)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop with NaN Protection & Safe Checkpoint\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, tr_ld, va_ld, stats, device,\n",
        "          lr=1e-4, wd=1e-5, lam=1.0, epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    opt   = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, patience=5)\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train': [], 'val': []}\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Training step\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for xb, yb in tr_ld:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, _, _ = total_loss(pred, yb, xb, stats, lam)\n",
        "            if torch.isnan(loss):\n",
        "                print(\"NaN loss detected. Aborting training.\")\n",
        "                return history\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            train_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        train_loss /= len(tr_ld.dataset)\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in va_ld:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred    = model(xb)\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, lam)\n",
        "                val_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        val_loss /= len(va_ld.dataset)\n",
        "        sched.step(val_loss)\n",
        "\n",
        "        history['train'].append(train_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        print(f\"Epoch {epoch:02d} ┃ Train: {train_loss:.4e} ┃ Val: {val_loss:.4e}\")\n",
        "\n",
        "        # Checkpoint & early stop\n",
        "        if val_loss < best_val - 1e-8:\n",
        "            best_val, wait = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_netai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    # Load best model if exists\n",
        "    if os.path.exists(\"best_netai.pth\"):\n",
        "        model.load_state_dict(torch.load(\"best_netai.pth\", map_location=device))\n",
        "    else:\n",
        "        print(\"No checkpoint found; using last epoch model.\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_hist(history):\n",
        "    plt.plot(history['train'], label='train')\n",
        "    plt.plot(history['val'],   label='val')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_scatter(y_true, y_pred):\n",
        "    plt.scatter(y_true, y_pred, s=5)\n",
        "    m, M = y_true.min(), y_true.max()\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Pred\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_uncertainty(model, stats, device):\n",
        "    WS = np.linspace(0.5, 1.5, 80)\n",
        "    TD = np.linspace(0.0, 0.1, 80)\n",
        "    WSm, TDm = np.meshgrid(WS, TD)\n",
        "    pts = WSm.size\n",
        "\n",
        "    grid = torch.zeros((pts, 6), device=device)\n",
        "    # Vary WS (idx 0) and TD (idx 2), fix others at mean\n",
        "    grid[:, 0] = torch.from_numpy(WSm.ravel()).to(device)\n",
        "    grid[:, 2] = torch.from_numpy(TDm.ravel()).to(device)\n",
        "    for i in (1, 3, 4, 5):\n",
        "        grid[:, i] = stats['X_mean'][i]\n",
        "\n",
        "    # Normalize\n",
        "    Xn = (grid - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout_predict(model, Xn, T=100)\n",
        "    U = std[:, 0].cpu().numpy().reshape(WSm.shape)\n",
        "\n",
        "    plt.pcolormesh(WSm, TDm, U, cmap='magma')\n",
        "    plt.colorbar(label=\"Uncertainty (σ)\")\n",
        "    plt.xlabel(\"Wormhole Stability (WS)\")\n",
        "    plt.ylabel(\"Temporal Distortion (TD)\")\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Run Everything\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare data\n",
        "    dataset = SpaceTimeNetworkDataset(n_samples=6000)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(dataset.X_mean, dtype=torch.float32, device=device),\n",
        "        'X_std' : torch.tensor(dataset.X_std,  dtype=torch.float32, device=device),\n",
        "        'Y_mean': torch.tensor(dataset.Y_mean, dtype=torch.float32, device=device),\n",
        "        'Y_std' : torch.tensor(dataset.Y_std,  dtype=torch.float32, device=device)\n",
        "    }\n",
        "\n",
        "    train_set, val_set = random_split(dataset, [len(dataset) - 1200, 1200])\n",
        "    train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "    val_loader   = DataLoader(val_set,   batch_size=256, shuffle=False)\n",
        "\n",
        "    # Build & train\n",
        "    model = SpaceTimeNetworkAI(input_dim=6, hidden_dims=32, output_dim=3).to(device)\n",
        "    history = train(model, train_loader, val_loader, stats, device)\n",
        "\n",
        "    # Visualize results\n",
        "    plot_hist(history)\n",
        "\n",
        "    X_all = torch.from_numpy(dataset.X).to(device)\n",
        "    with torch.no_grad():\n",
        "        Y_pred = model(X_all).cpu().numpy()\n",
        "\n",
        "    for i in range(3):\n",
        "        plot_scatter(dataset.Y[:, i], Y_pred[:, i])\n",
        "\n",
        "    plot_uncertainty(model, stats, device)"
      ]
    }
  ]
}
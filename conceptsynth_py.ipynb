{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOaKVI8JAWO5D6YKVbnHbCy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/conceptsynth_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6HGInJJYZ8v"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# conceptsynth.py â€” pluggable concept synthesizer scaffold\n",
        "\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Protocol, Tuple, Optional\n",
        "import hashlib\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "\n",
        "# ---------------------------\n",
        "# Interfaces (protocols)\n",
        "# ---------------------------\n",
        "\n",
        "class Encoder(Protocol):\n",
        "    def encode(self, raw: Any) -> Dict[str, Any]: ...\n",
        "\n",
        "class Symbolizer(Protocol):\n",
        "    def assign(self, concept: Dict[str, Any]) -> str: ...\n",
        "\n",
        "class Ontology(Protocol):\n",
        "    def integrate(self, symbol: str, concept: Dict[str, Any]) -> None: ...\n",
        "    def neighbors(self, symbol: str, k: int = 5) -> List[str]: ...\n",
        "\n",
        "# ---------------------------\n",
        "# Core synthesizer\n",
        "# ---------------------------\n",
        "\n",
        "@dataclass\n",
        "class ConceptSynthesizer:\n",
        "    encoder: Encoder           # e.g., CLIP-like\n",
        "    symbolizer: Symbolizer     # e.g., VQ / codebook\n",
        "    ontology: Ontology         # e.g., probabilistic hypergraph\n",
        "    trace: bool = True\n",
        "\n",
        "    def process_experience(self, raw_data: Any) -> str:\n",
        "        latent = self.encoder.encode(raw_data)\n",
        "        invariants = self.extract_invariants(latent)\n",
        "        concept = self.synthesize(latent, invariants)\n",
        "        symbol = self.symbolizer.assign(concept)\n",
        "        self.ontology.integrate(symbol, concept)\n",
        "        if self.trace:\n",
        "            print(f\"[ConceptSynth] symbol={symbol} inv={invariants} meta={concept.get('meta')}\")\n",
        "        return symbol\n",
        "\n",
        "    def extract_invariants(self, latent: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        return detect_geometric_invariants(latent)\n",
        "\n",
        "    def synthesize(self, latent: Dict[str, Any], invariants: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        return abstract_latent(latent, invariants)\n",
        "\n",
        "# ---------------------------\n",
        "# Default invariant and abstraction logic\n",
        "# ---------------------------\n",
        "\n",
        "def detect_geometric_invariants(latent: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Example: compute norm, dominant axis, coarse orientation from vector-like content.\n",
        "    Expects latent['vec']: List[float].\n",
        "    \"\"\"\n",
        "    vec = latent.get(\"vec\", [])\n",
        "    if not vec:\n",
        "        return {\"norm\": 0.0, \"axis\": None, \"orientation\": None}\n",
        "    norm = math.sqrt(sum(x*x for x in vec))\n",
        "    axis = max(range(len(vec)), key=lambda i: abs(vec[i]))\n",
        "    orientation = \"positive\" if vec[axis] >= 0 else \"negative\"\n",
        "    return {\"norm\": round(norm, 4), \"axis\": axis, \"orientation\": orientation}\n",
        "\n",
        "def abstract_latent(latent: Dict[str, Any], invariants: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Combine latent stats + invariants into a minimal concept record.\n",
        "    \"\"\"\n",
        "    concept = {\n",
        "        \"invariants\": invariants,\n",
        "        \"meta\": {\n",
        "            \"source\": latent.get(\"source\"),\n",
        "            \"hash\": latent.get(\"hash\"),\n",
        "            \"dim\": len(latent.get(\"vec\", [])),\n",
        "        }\n",
        "    }\n",
        "    # Optional: attach sparse signature (top-k indices)\n",
        "    vec = latent.get(\"vec\", [])\n",
        "    if vec:\n",
        "        k = min(4, len(vec))\n",
        "        tops = sorted(range(len(vec)), key=lambda i: abs(vec[i]), reverse=True)[:k]\n",
        "        concept[\"signature\"] = {\"top_idx\": tops, \"top_vals\": [vec[i] for i in tops]}\n",
        "    return concept\n",
        "\n",
        "# ---------------------------\n",
        "# Dummy implementations\n",
        "# ---------------------------\n",
        "\n",
        "class ToyEncoder:\n",
        "    \"\"\"\n",
        "    Maps raw string or dict to a fixed-length numeric vector with a stable hash,\n",
        "    mimicking a contrastive encoder interface.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim: int = 8, seed: int = 7) -> None:\n",
        "        self.dim = dim\n",
        "        random.seed(seed)\n",
        "\n",
        "    def encode(self, raw: Any) -> Dict[str, Any]:\n",
        "        s = json.dumps(raw, sort_keys=True) if isinstance(raw, (dict, list)) else str(raw)\n",
        "        h = hashlib.sha256(s.encode(\"utf-8\")).digest()\n",
        "        # Deterministic pseudo-vector from hash bytes\n",
        "        vec = []\n",
        "        for i in range(self.dim):\n",
        "            chunk = h[4*i:4*i+4]\n",
        "            val = int.from_bytes(chunk, \"little\", signed=False)\n",
        "            # map to [-1, 1]\n",
        "            vec.append((val % 10_000) / 5000.0 - 1.0)\n",
        "        return {\"vec\": vec, \"source\": \"toy\", \"hash\": hashlib.sha256(s.encode()).hexdigest()[:16]}\n",
        "\n",
        "class VQSymbolizer:\n",
        "    \"\"\"\n",
        "    Very simple codebook: bucket by coarse axis + sign + norm bin.\n",
        "    \"\"\"\n",
        "    def __init__(self, bins: int = 4) -> None:\n",
        "        self.bins = bins\n",
        "\n",
        "    def assign(self, concept: Dict[str, Any]) -> str:\n",
        "        inv = concept.get(\"invariants\", {})\n",
        "        axis = inv.get(\"axis\")\n",
        "        orientation = inv.get(\"orientation\")\n",
        "        norm = float(inv.get(\"norm\", 0.0))\n",
        "        bin_id = int(min(self.bins-1, max(0, norm)))  # crude bin on norm\n",
        "        return f\"CAX{axis}:{orientation}:B{bin_id}\"\n",
        "\n",
        "class HypergraphOntology:\n",
        "    \"\"\"\n",
        "    Maintains adjacency by shared signature indices and norm proximity.\n",
        "    \"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        self.nodes: Dict[str, Dict[str, Any]] = {}\n",
        "        self.edges: Dict[str, Dict[str, float]] = {}  # symbol -> neighbor -> weight\n",
        "\n",
        "    def integrate(self, symbol: str, concept: Dict[str, Any]) -> None:\n",
        "        prev = self.nodes.get(symbol)\n",
        "        self.nodes[symbol] = concept\n",
        "        self.edges.setdefault(symbol, {})\n",
        "        # Connect to neighbors by simple heuristic\n",
        "        for other, c in self.nodes.items():\n",
        "            if other == symbol:\n",
        "                continue\n",
        "            w = self._similarity(concept, c)\n",
        "            if w > 0:\n",
        "                self.edges[symbol][other] = max(self.edges[symbol].get(other, 0.0), w)\n",
        "                self.edges.setdefault(other, {})\n",
        "                self.edges[other][symbol] = max(self.edges[other].get(symbol, 0.0), w)\n",
        "\n",
        "    def _similarity(self, a: Dict[str, Any], b: Dict[str, Any]) -> float:\n",
        "        sig_a = set(a.get(\"signature\", {}).get(\"top_idx\", []))\n",
        "        sig_b = set(b.get(\"signature\", {}).get(\"top_idx\", []))\n",
        "        if not sig_a or not sig_b:\n",
        "            return 0.0\n",
        "        j = len(sig_a & sig_b) / len(sig_a | sig_b)\n",
        "        return j\n",
        "\n",
        "    def neighbors(self, symbol: str, k: int = 5) -> List[str]:\n",
        "        nbrs = self.edges.get(symbol, {})\n",
        "        return [s for s, _ in sorted(nbrs.items(), key=lambda kv: kv[1], reverse=True)[:k]]\n",
        "\n",
        "# ---------------------------\n",
        "# Demo\n",
        "# ---------------------------\n",
        "\n",
        "def demo():\n",
        "    encoder = ToyEncoder(dim=12)\n",
        "    symbolizer = VQSymbolizer(bins=5)\n",
        "    ontology = HypergraphOntology()\n",
        "    cs = ConceptSynthesizer(encoder, symbolizer, ontology, trace=True)\n",
        "\n",
        "    inputs = [\n",
        "        {\"image_id\": 1, \"caption\": \"red circle top-left\"},\n",
        "        {\"image_id\": 2, \"caption\": \"blue square bottom-right\"},\n",
        "        {\"image_id\": 3, \"caption\": \"green triangle center\"},\n",
        "        {\"image_id\": 1, \"caption\": \"red circle top-left (variant)\"},\n",
        "    ]\n",
        "    for x in inputs:\n",
        "        sym = cs.process_experience(x)\n",
        "        print(\"-> neighbors:\", ontology.neighbors(sym, k=3))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo()"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPcdjSzh5odoo+jvO1v3VwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/recursive_generalization_engine_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "san6FfA9II3h"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# recursive_generalization_engine.py\n",
        "# Ready-to-run: a safer, deduplicated, CLI-friendly recursive generalization engine\n",
        "# with a minimal plug-in stack (abstraction → theory → simulation → validation).\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, Iterable, List, Optional, Protocol, Tuple\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Protocols and data models\n",
        "# =========================\n",
        "\n",
        "class AbstractionEngine(Protocol):\n",
        "    def extract(self, input_data: Any) -> List[Dict[str, Any]]:\n",
        "        ...\n",
        "\n",
        "\n",
        "class TheoryConstructor(Protocol):\n",
        "    def build(self, candidate: Dict[str, Any]) -> \"Theory\":\n",
        "        ...\n",
        "\n",
        "\n",
        "class Simulator(Protocol):\n",
        "    def test(self, theory: \"Theory\") -> \"SimOutput\":\n",
        "        ...\n",
        "\n",
        "\n",
        "class Validator(Protocol):\n",
        "    threshold: float\n",
        "    def score(self, theory: \"Theory\", sim_output: \"SimOutput\") -> float:\n",
        "        ...\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Theory:\n",
        "    \"\"\"Simple hashable theory representation.\"\"\"\n",
        "    name: str\n",
        "    params: Tuple[Tuple[str, Any], ...]  # sorted key-value tuples for stable hashing\n",
        "\n",
        "    def key(self) -> Tuple[str, Tuple[Tuple[str, Any], ...]]:\n",
        "        return (self.name, self.params)\n",
        "\n",
        "    @staticmethod\n",
        "    def from_dict(name: str, params: Dict[str, Any]) -> \"Theory\":\n",
        "        # Sort params to ensure deterministic identity and hashing\n",
        "        items = tuple(sorted(params.items(), key=lambda kv: kv[0]))\n",
        "        return Theory(name=name, params=items)\n",
        "\n",
        "    def describe(self) -> str:\n",
        "        kv = \", \".join(f\"{k}={v}\" for k, v in self.params)\n",
        "        return f\"{self.name}({kv})\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SimOutput:\n",
        "    \"\"\"Simulation result used for scoring and (optionally) deeper recursion.\"\"\"\n",
        "    trials: int\n",
        "    accuracy: float\n",
        "    details: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# The recursive engine\n",
        "# =========================\n",
        "\n",
        "class RecursiveGeneralizationEngine:\n",
        "    def __init__(\n",
        "        self,\n",
        "        abstraction_engine: AbstractionEngine,\n",
        "        theory_constructor: TheoryConstructor,\n",
        "        simulator: Simulator,\n",
        "        validator: Validator,\n",
        "        *,\n",
        "        max_candidates_per_level: int = 16,\n",
        "        top_k_knowledge: int = 32,\n",
        "        verbose: bool = True,\n",
        "    ):\n",
        "        self.abstraction_engine = abstraction_engine\n",
        "        self.theory_constructor = theory_constructor\n",
        "        self.simulator = simulator\n",
        "        self.validator = validator\n",
        "        self.knowledge_base: List[Tuple[Theory, float, SimOutput]] = []\n",
        "        self._seen: set[Tuple[str, Tuple[Tuple[str, Any], ...]]] = set()\n",
        "        self.max_candidates_per_level = max_candidates_per_level\n",
        "        self.top_k_knowledge = top_k_knowledge\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def _log(self, depth: int, msg: str):\n",
        "        if self.verbose:\n",
        "            indent = \"  \" * depth\n",
        "            print(f\"{indent}{msg}\")\n",
        "\n",
        "    def _consider(self, theory: Theory, score: float, sim_output: SimOutput):\n",
        "        self.knowledge_base.append((theory, score, sim_output))\n",
        "        # Keep best top_k sorted by score descending, then accuracy, then trials\n",
        "        self.knowledge_base.sort(key=lambda x: (x[1], x[2].accuracy, x[2].trials), reverse=True)\n",
        "        if len(self.knowledge_base) > self.top_k_knowledge:\n",
        "            self.knowledge_base = self.knowledge_base[: self.top_k_knowledge]\n",
        "\n",
        "    def run(self, input_data: Any, depth: int = 0, max_depth: int = 3, budget: Optional[int] = None):\n",
        "        \"\"\"\n",
        "        Run recursive generalization. Returns knowledge_base [(theory, score, sim_output), ...].\n",
        "        - budget: optional global cap on total expansions (nodes).\n",
        "        \"\"\"\n",
        "        if budget is not None and budget <= 0:\n",
        "            self._log(depth, \"[HALT] Budget exhausted.\")\n",
        "            return self.knowledge_base\n",
        "\n",
        "        # STEP 1: Identify patterns/abstractions (with candidate cap)\n",
        "        candidates = self.abstraction_engine.extract(input_data)[: self.max_candidates_per_level]\n",
        "        self._log(depth, f\"[EXTRACT] {len(candidates)} candidate(s)\")\n",
        "\n",
        "        expansions_done = 0\n",
        "\n",
        "        for c in candidates:\n",
        "            if budget is not None and budget <= 0:\n",
        "                self._log(depth, \"[HALT] Budget exhausted mid-level.\")\n",
        "                break\n",
        "\n",
        "            # STEP 2: Construct candidate theory\n",
        "            try:\n",
        "                theory = self.theory_constructor.build(c)\n",
        "            except Exception as e:\n",
        "                self._log(depth, f\"[SKIP] Theory build failed: {e}\")\n",
        "                continue\n",
        "\n",
        "            if theory.key() in self._seen:\n",
        "                self._log(depth, f\"[SEEN] {theory.describe()}\")\n",
        "                continue\n",
        "            self._seen.add(theory.key())\n",
        "            self._log(depth, f\"[THEORY] {theory.describe()}\")\n",
        "\n",
        "            # STEP 3: Simulate consequences\n",
        "            try:\n",
        "                sim_output = self.simulator.test(theory)\n",
        "            except Exception as e:\n",
        "                self._log(depth, f\"[SKIP] Simulation failed: {e}\")\n",
        "                continue\n",
        "\n",
        "            # STEP 4: Evaluate generalization\n",
        "            try:\n",
        "                score = self.validator.score(theory, sim_output)\n",
        "            except Exception as e:\n",
        "                self._log(depth, f\"[SKIP] Scoring failed: {e}\")\n",
        "                continue\n",
        "\n",
        "            # STEP 5: If strong, store it\n",
        "            verdict = \"PASS\" if score >= self.validator.threshold else \"FAIL\"\n",
        "            self._log(depth, f\"[EVAL:{verdict}] score={score:.3f} acc={sim_output.accuracy:.3f} trials={sim_output.trials}\")\n",
        "            if score >= self.validator.threshold:\n",
        "                self._consider(theory, score, sim_output)\n",
        "\n",
        "            expansions_done += 1\n",
        "            if budget is not None:\n",
        "                budget -= 1\n",
        "\n",
        "            # STEP 6: Recursive generalization (feed simulation artifacts forward)\n",
        "            if depth < max_depth:\n",
        "                next_input = sim_output.details.get(\"synthetic_data\", [theory])\n",
        "                self.run(next_input, depth + 1, max_depth, budget)\n",
        "\n",
        "        return self.knowledge_base\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Minimal plug-in stack (toy domain)\n",
        "# =========================\n",
        "\n",
        "# Domain: sequences of floats. We extract trend candidates, build a theory that predicts\n",
        "# the sign of change, simulate AR(1)-like sequences with drift, and score by direction-accuracy.\n",
        "\n",
        "def _sign(x: float) -> int:\n",
        "    return 1 if x > 0 else (-1 if x < 0 else 0)\n",
        "\n",
        "def _trend_of(seq: List[float]) -> int:\n",
        "    if len(seq) < 2:\n",
        "        return 0\n",
        "    diffs = [b - a for a, b in zip(seq[:-1], seq[1:])]\n",
        "    avg = sum(diffs) / len(diffs)\n",
        "    return _sign(avg)\n",
        "\n",
        "class SimpleAbstraction:\n",
        "    def __init__(self, propose_inverse: bool = True):\n",
        "        self.propose_inverse = propose_inverse\n",
        "\n",
        "    def extract(self, input_data: Any) -> List[Dict[str, Any]]:\n",
        "        # Accept a list of sequences or a single sequence; normalize to list of sequences\n",
        "        sequences: List[List[float]] = []\n",
        "        if isinstance(input_data, dict) and \"synthetic_data\" in input_data:\n",
        "            sequences = input_data[\"synthetic_data\"]\n",
        "        elif isinstance(input_data, list) and input_data and isinstance(input_data[0], list):\n",
        "            sequences = input_data  # list of sequences\n",
        "        elif isinstance(input_data, list) and all(isinstance(x, (int, float)) for x in input_data):\n",
        "            sequences = [input_data]\n",
        "        else:\n",
        "            # Unknown shape; produce a neutral candidate\n",
        "            return [{\"trend\": 0, \"momentum\": 0.0}]\n",
        "\n",
        "        # Aggregate trend across sequences\n",
        "        trends = [_trend_of(seq) for seq in sequences]\n",
        "        net_trend = _sign(sum(trends))\n",
        "        candidates = [{\"trend\": net_trend, \"momentum\": 0.1}]\n",
        "        if self.propose_inverse:\n",
        "            candidates.append({\"trend\": -net_trend, \"momentum\": 0.1})\n",
        "        # Also propose a neutral candidate\n",
        "        candidates.append({\"trend\": 0, \"momentum\": 0.0})\n",
        "        return candidates\n",
        "\n",
        "class SimpleTheoryBuilder:\n",
        "    def build(self, candidate: Dict[str, Any]) -> Theory:\n",
        "        trend = int(candidate.get(\"trend\", 0))\n",
        "        momentum = float(candidate.get(\"momentum\", 0.1))\n",
        "        return Theory.from_dict(\"DirectionRule\", {\"trend\": trend, \"momentum\": momentum})\n",
        "\n",
        "class DriftSimulator:\n",
        "    def __init__(self, *, trials: int = 100, length: int = 50, sigma: float = 0.5, base_mu: float = 0.15, seed: int = 7):\n",
        "        self.trials = trials\n",
        "        self.length = length\n",
        "        self.sigma = sigma\n",
        "        self.base_mu = base_mu\n",
        "        self.seed = seed\n",
        "\n",
        "    def test(self, theory: Theory) -> SimOutput:\n",
        "        # Extract params\n",
        "        params = dict(theory.params)\n",
        "        trend = int(params.get(\"trend\", 0))\n",
        "        momentum = float(params.get(\"momentum\", 0.0))\n",
        "\n",
        "        rng = random.Random(self.seed + hash(theory.key()) % (10**6))\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_seqs: List[List[float]] = []\n",
        "\n",
        "        for _ in range(self.trials):\n",
        "            x = 0.0\n",
        "            seq = [x]\n",
        "            mu = self.base_mu * trend + momentum * trend\n",
        "            for _t in range(self.length):\n",
        "                noise = rng.gauss(0.0, self.sigma)\n",
        "                x_next = x + mu + noise\n",
        "                pred = _sign(mu)  # theory predicts sign of drift\n",
        "                actual = _sign(x_next - x)\n",
        "                if pred == actual:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "                x = x_next\n",
        "                seq.append(x)\n",
        "            all_seqs.append(seq)\n",
        "\n",
        "        accuracy = (correct / total) if total > 0 else 0.0\n",
        "        return SimOutput(\n",
        "            trials=self.trials,\n",
        "            accuracy=accuracy,\n",
        "            details={\"synthetic_data\": all_seqs, \"mu\": mu, \"sigma\": self.sigma}\n",
        "        )\n",
        "\n",
        "class AccuracyValidator:\n",
        "    def __init__(self, threshold: float = 0.60):\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def score(self, theory: Theory, sim_output: SimOutput) -> float:\n",
        "        # Directly use accuracy as score; could include parsimony or penalty terms\n",
        "        return sim_output.accuracy\n",
        "\n",
        "\n",
        "# =========================\n",
        "# CLI and main\n",
        "# =========================\n",
        "\n",
        "def build_parser() -> argparse.ArgumentParser:\n",
        "    p = argparse.ArgumentParser(description=\"Recursive Generalization Engine (toy domain)\")\n",
        "    p.add_argument(\"--max_depth\", type=int, default=3, help=\"Maximum recursion depth\")\n",
        "    p.add_argument(\"--budget\", type=int, default=64, help=\"Global expansion budget (nodes)\")\n",
        "    p.add_argument(\"--max_candidates_per_level\", type=int, default=8, help=\"Candidate cap per level\")\n",
        "    p.add_argument(\"--top_k_knowledge\", type=int, default=16, help=\"Top-K retained in knowledge base\")\n",
        "    p.add_argument(\"--threshold\", type=float, default=0.60, help=\"Minimum score to accept a theory\")\n",
        "    p.add_argument(\"--trials\", type=int, default=80, help=\"Simulator trials per theory\")\n",
        "    p.add_argument(\"--length\", type=int, default=40, help=\"Length of each simulated sequence\")\n",
        "    p.add_argument(\"--sigma\", type=float, default=0.5, help=\"Noise std-dev for simulator\")\n",
        "    p.add_argument(\"--base_mu\", type=float, default=0.15, help=\"Base drift magnitude\")\n",
        "    p.add_argument(\"--seed\", type=int, default=7)\n",
        "    p.add_argument(\"--verbose\", type=lambda x: str(x).lower() in {\"1\",\"true\",\"yes\",\"y\"}, default=True)\n",
        "    return p\n",
        "\n",
        "def make_initial_data(seed: int = 7, sequences: int = 4, length: int = 20) -> List[List[float]]:\n",
        "    rng = random.Random(seed)\n",
        "    data = []\n",
        "    for s in range(sequences):\n",
        "        x = 0.0\n",
        "        seq = [x]\n",
        "        drift = rng.uniform(-0.2, 0.2)\n",
        "        for _ in range(length):\n",
        "            x += drift + rng.gauss(0.0, 0.3)\n",
        "            seq.append(x)\n",
        "        data.append(seq)\n",
        "    return data\n",
        "\n",
        "def main():\n",
        "    args = build_parser().parse_args()\n",
        "    random.seed(args.seed)\n",
        "    os.environ.setdefault(\"PYTHONHASHSEED\", \"0\")\n",
        "\n",
        "    abstraction = SimpleAbstraction(propose_inverse=True)\n",
        "    theory_builder = SimpleTheoryBuilder()\n",
        "    simulator = DriftSimulator(\n",
        "        trials=args.trials, length=args.length, sigma=args.sigma, base_mu=args.base_mu, seed=args.seed\n",
        "    )\n",
        "    validator = AccuracyValidator(threshold=args.threshold)\n",
        "\n",
        "    engine = RecursiveGeneralizationEngine(\n",
        "        abstraction, theory_builder, simulator, validator,\n",
        "        max_candidates_per_level=args.max_candidates_per_level,\n",
        "        top_k_knowledge=args.top_k_knowledge,\n",
        "        verbose=args.verbose\n",
        "    )\n",
        "\n",
        "    initial_data = make_initial_data(seed=args.seed, sequences=4, length=20)\n",
        "\n",
        "    print(\"[START] Running recursive generalization\")\n",
        "    kb = engine.run(initial_data, depth=0, max_depth=args.max_depth, budget=args.budget)\n",
        "\n",
        "    print(\"\\n=== KNOWLEDGE BASE (Top theories) ===\")\n",
        "    if not kb:\n",
        "        print(\"No accepted theories (try lowering --threshold or increasing --budget).\")\n",
        "    else:\n",
        "        for i, (theory, score, sim) in enumerate(kb, 1):\n",
        "            verdict = \"PASS\" if score >= validator.threshold else \"FAIL\"\n",
        "            print(f\"{i:02d}. {theory.describe()} | score={score:.3f} | acc={sim.accuracy:.3f} | trials={sim.trials} [{verdict}]\")\n",
        "\n",
        "    print(\"\\n=== SUMMARY ===\")\n",
        "    print(f\"Depth limit: {args.max_depth} | Budget: {args.budget} | Threshold: {args.threshold:.2f}\")\n",
        "    print(f\"Candidates/level cap: {args.max_candidates_per_level} | KB top-K: {args.top_k_knowledge}\")\n",
        "    print(\"[DONE]\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}
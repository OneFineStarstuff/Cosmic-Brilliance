{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNoJzBfDZ/rkm3w8csyD4Kh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/unified_ai_memory_eem_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-t0AfqaXsjv"
      },
      "outputs": [],
      "source": [
        "# unified_ai/memory/eem.py\n",
        "from __future__ import annotations\n",
        "from typing import Optional, Tuple, Callable, Dict, Any\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def _as_complex(r: torch.Tensor, i: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "    if i is None:\n",
        "        i = torch.zeros_like(r)\n",
        "    return torch.complex(r, i)\n",
        "\n",
        "def _norm_complex(z: torch.Tensor, eps: float = 1e-6, dim: int = -1) -> torch.Tensor:\n",
        "    mag = torch.sqrt((z.real**2 + z.imag**2).sum(dim=dim, keepdim=True) + eps)\n",
        "    return z / mag\n",
        "\n",
        "def _phase_unitary(z: torch.Tensor, theta: torch.Tensor) -> torch.Tensor:\n",
        "    phase = torch.complex(torch.cos(theta), torch.sin(theta))\n",
        "    return z * phase\n",
        "\n",
        "def _stack_householder(U: torch.Tensor, v: torch.Tensor) -> torch.Tensor:\n",
        "    v = v / (v.norm() + 1e-6)\n",
        "    proj = torch.matmul(U, v)\n",
        "    return U - 2.0 * proj.unsqueeze(-1) * v\n",
        "\n",
        "class EntangledEpisodicMemory(nn.Module):\n",
        "    \"\"\"\n",
        "    Complex Hilbert-space key-value memory with measurement-based retrieval.\n",
        "\n",
        "    - keys: (S, D_c) complex (stored as real/imag)\n",
        "    - values: (S, D_v) real\n",
        "\n",
        "    Read:\n",
        "      scores: |<q,k>|^2 / tau -> softmax -> weighted sum of values\n",
        "    Write:\n",
        "      'ring' append or 'nearest' EMA into best-matching slot (no-grad).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        slots: int = 256,\n",
        "        key_dim: int = 32,\n",
        "        value_dim: int = 16,\n",
        "        temperature: float = 0.2,\n",
        "        ema: float = 0.2,\n",
        "        trainable_memory: bool = False,\n",
        "        householder_layers: int = 1,\n",
        "        dtype: torch.dtype = torch.float32,\n",
        "        device: Optional[torch.device] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.slots = slots\n",
        "        self.key_dim = key_dim\n",
        "        self.value_dim = value_dim\n",
        "        self.temperature = temperature\n",
        "        self.ema = ema\n",
        "        self.householder_layers = householder_layers\n",
        "\n",
        "        init_keys_r = F.normalize(torch.randn(slots, key_dim, dtype=dtype, device=device), dim=-1)\n",
        "        init_keys_i = F.normalize(torch.randn(slots, key_dim, dtype=dtype, device=device), dim=-1)\n",
        "        init_values = torch.zeros(slots, value_dim, dtype=dtype, device=device)\n",
        "\n",
        "        if trainable_memory:\n",
        "            self.keys_r = nn.Parameter(init_keys_r)\n",
        "            self.keys_i = nn.Parameter(init_keys_i)\n",
        "            self.values = nn.Parameter(init_values)\n",
        "        else:\n",
        "            self.register_buffer(\"keys_r\", init_keys_r)\n",
        "            self.register_buffer(\"keys_i\", init_keys_i)\n",
        "            self.register_buffer(\"values\", init_values)\n",
        "\n",
        "        self.theta = nn.Parameter(torch.zeros(key_dim, dtype=dtype, device=device))\n",
        "\n",
        "        if self.householder_layers > 0:\n",
        "            self.house_v = nn.ParameterList(\n",
        "                [nn.Parameter(F.normalize(torch.randn(2 * key_dim, dtype=dtype, device=device), dim=0))\n",
        "                 for _ in range(self.householder_layers)]\n",
        "            )\n",
        "\n",
        "        self.register_buffer(\"age\", torch.zeros(slots, dtype=torch.long, device=device))\n",
        "        self.register_buffer(\"ptr\", torch.zeros((), dtype=torch.long, device=device))\n",
        "\n",
        "    def _apply_unitary(self, z_c: torch.Tensor) -> torch.Tensor:\n",
        "        z_c = _phase_unitary(z_c, self.theta)\n",
        "        if self.householder_layers > 0:\n",
        "            re, im = z_c.real, z_c.imag\n",
        "            cat = torch.cat([re, im], dim=-1)\n",
        "            for v in self.house_v:\n",
        "                cat = _stack_householder(cat, v)\n",
        "            D = z_c.size(-1)\n",
        "            z_c = torch.complex(cat[..., :D], cat[..., D:])\n",
        "        return z_c\n",
        "\n",
        "    def _similarity(self, q_c: torch.Tensor, k_c: torch.Tensor) -> torch.Tensor:\n",
        "        qn = _norm_complex(q_c)\n",
        "        kn = _norm_complex(k_c)\n",
        "        # (B,1,D) @ (1,D,S) -> (B,1,S) -> (B,S)\n",
        "        scores = torch.abs(qn.unsqueeze(1) @ torch.conj(kn).unsqueeze(0).transpose(-1, -2)) ** 2\n",
        "        return scores.squeeze(1)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def write(self, k: torch.Tensor, v: torch.Tensor, strategy: str = \"nearest\"):\n",
        "        single = k.dim() == 1\n",
        "        if single:\n",
        "            k = k.unsqueeze(0); v = v.unsqueeze(0)\n",
        "        k_c = k if torch.is_complex(k) else _as_complex(k)\n",
        "        k_c = _norm_complex(self._apply_unitary(k_c))\n",
        "        mem_c = _as_complex(self.keys_r, self.keys_i)\n",
        "\n",
        "        if strategy == \"ring\":\n",
        "            for i in range(k_c.size(0)):\n",
        "                idx = int(self.ptr.item() % self.slots)\n",
        "                self.keys_r[idx] = k_c[i].real\n",
        "                self.keys_i[idx] = k_c[i].imag\n",
        "                self.values[idx] = v[i]\n",
        "                self.age[idx] = 0\n",
        "                self.ptr += 1\n",
        "        elif strategy == \"nearest\":\n",
        "            sims = self._similarity(k_c, mem_c)  # (B,S)\n",
        "            idxs = sims.argmax(dim=-1)\n",
        "            for i, idx in enumerate(idxs.tolist()):\n",
        "                self.keys_r[idx] = F.normalize((1 - self.ema) * self.keys_r[idx] + self.ema * k_c[i].real, dim=-1)\n",
        "                self.keys_i[idx] = F.normalize((1 - self.ema) * self.keys_i[idx] + self.ema * k_c[i].imag, dim=-1)\n",
        "                self.values[idx] = (1 - self.ema) * self.values[idx] + self.ema * v[i]\n",
        "                self.age[idx] = 0\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown write strategy: {strategy}\")\n",
        "\n",
        "        self.age += 1\n",
        "\n",
        "    def read(self, q: torch.Tensor, topk: int = 0, return_weights: bool = False):\n",
        "        single = q.dim() == 1\n",
        "        if single: q = q.unsqueeze(0)\n",
        "        q_c = q if torch.is_complex(q) else _as_complex(q)\n",
        "        q_c = self._apply_unitary(q_c)\n",
        "        k_c = _as_complex(self.keys_r, self.keys_i)\n",
        "\n",
        "        scores = self._similarity(q_c, k_c) / max(self.temperature, 1e-6)\n",
        "        if topk and topk < self.slots:\n",
        "            vals, idxs = scores.topk(topk, dim=-1)\n",
        "            w = torch.softmax(vals, dim=-1)\n",
        "            gathered = self.values[idxs]\n",
        "            out = (w.unsqueeze(-1) * gathered).sum(dim=1)\n",
        "            weights = w\n",
        "        else:\n",
        "            w = torch.softmax(scores, dim=-1)\n",
        "            out = w @ self.values\n",
        "            weights = w\n",
        "\n",
        "        if single:\n",
        "            out = out.squeeze(0)\n",
        "            if return_weights:\n",
        "                weights = weights.squeeze(0)\n",
        "        return (out, weights) if return_weights else (out, None)"
      ]
    }
  ]
}
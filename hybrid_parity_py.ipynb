{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMU45iGr2J6J0SIdHW6EcoW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/hybrid_parity_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pennylane torch tqdm"
      ],
      "metadata": {
        "id": "EdZNZXHoXHpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPKoRNpHWzYM"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "hybrid_parity.py\n",
        "\n",
        "A self-contained PyTorch + PennyLane script to train a 4-bit parity classifier\n",
        "using a hybrid quantum-classical model with:\n",
        "  - Angle data embedding\n",
        "  - BasicEntanglerLayers variational circuit (8 layers, full entanglement)\n",
        "  - Classical residual block (no in-place ops)\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "\n",
        "# 1. Configuration\n",
        "n_qubits = 4\n",
        "n_layers = 8\n",
        "\n",
        "# Built-in device\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "\n",
        "# 2. QNode (must name first arg \"inputs\" for TorchLayer)\n",
        "@qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
        "def parity_qnode(inputs, weights):\n",
        "    # AngleEmbedding only\n",
        "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits), rotation=\"X\")\n",
        "\n",
        "    # Full-entangling variational circuit\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "\n",
        "    # Measure Z on each qubit\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "\n",
        "# Wrap into a TorchLayer\n",
        "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
        "qlayer = qml.qnn.TorchLayer(parity_qnode, weight_shapes)\n",
        "\n",
        "\n",
        "# 3. Hybrid model with a classical residual block (no in-place add)\n",
        "class HybridParityModel(nn.Module):\n",
        "    def __init__(self, hidden_dim: int = 32):\n",
        "        super().__init__()\n",
        "        self.qlayer     = qlayer\n",
        "        self.res_fc1    = nn.Linear(n_qubits, hidden_dim)\n",
        "        self.res_fc2    = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.classifier = nn.Linear(hidden_dim, 2)\n",
        "        self.relu       = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Quantum feature map\n",
        "        q_out = self.qlayer(x)\n",
        "\n",
        "        # Classical residual block\n",
        "        h      = self.relu(self.res_fc1(q_out))\n",
        "        h_res  = self.relu(self.res_fc2(h))\n",
        "        h      = h + h_res       # <- out-of-place addition\n",
        "\n",
        "        # Return two-class logits\n",
        "        return self.classifier(h)\n",
        "\n",
        "\n",
        "# 4. Parity dataset generator\n",
        "def generate_parity_data(n_samples: int = 1024):\n",
        "    X = np.random.randint(0, 2, size=(n_samples, n_qubits))\n",
        "    X = 2 * X - 1                  # map {0,1} â†’ {-1,+1}\n",
        "    y = (np.sum(X == 1, axis=1) % 2).astype(int)\n",
        "    return (\n",
        "        torch.tensor(X, dtype=torch.float32),\n",
        "        torch.tensor(y, dtype=torch.long),\n",
        "    )\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Instantiate model, optimizer, criterion\n",
        "    model     = HybridParityModel(hidden_dim=32)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Prepare data\n",
        "    X_train, y_train = generate_parity_data(2000)\n",
        "    X_test,  y_test  = generate_parity_data(500)\n",
        "\n",
        "    train_loader = DataLoader(TensorDataset(X_train, y_train),\n",
        "                              batch_size=32, shuffle=True)\n",
        "    test_loader  = DataLoader(TensorDataset(X_test, y_test),\n",
        "                              batch_size=64)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(1, 51):\n",
        "        model.train()\n",
        "        total_loss, correct = 0.0, 0\n",
        "\n",
        "        for Xb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(Xb)\n",
        "            loss   = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * Xb.size(0)\n",
        "            correct    += (logits.argmax(dim=1) == yb).sum().item()\n",
        "\n",
        "        train_acc  = correct / len(train_loader.dataset)\n",
        "        train_loss = total_loss / len(train_loader.dataset)\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        test_correct = 0\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in test_loader:\n",
        "                preds        = model(Xb).argmax(dim=1)\n",
        "                test_correct += (preds == yb).sum().item()\n",
        "        test_acc = test_correct / len(test_loader.dataset)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:2d} | \"\n",
        "            f\"Train Loss: {train_loss:.4f} | \"\n",
        "            f\"Train Acc: {train_acc:.3f} | \"\n",
        "            f\"Test Acc: {test_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ]
    }
  ]
}
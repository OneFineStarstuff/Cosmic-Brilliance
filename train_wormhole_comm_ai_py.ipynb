{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNX6vlUxSB1fe0LYTMByvyq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_wormhole_comm_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehnGZ0W457yW"
      },
      "outputs": [],
      "source": [
        "pip install torch numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_wormhole_comm_ai.py\n",
        "\n",
        "Physics-informed AI pipeline for optimizing wormhole communication stability:\n",
        "\n",
        "1. Synthetic dataset of 5 wormhole parameters → 3 stability metrics\n",
        "2. Normalize so means/stds are 1D arrays, avoiding shape‐mismatch\n",
        "3. MLP with LayerNorm & Dropout to capture uncertainty\n",
        "4. Physics‐informed residual enforcing empirical time‐delay law\n",
        "5. MC-Dropout inference for predictive confidence\n",
        "6. Training loop with AdamW, LR scheduler & early stopping\n",
        "7. Visualizations: loss curves, true vs predicted, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Wormhole Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class WormholeCommDataset(Dataset):\n",
        "    def __init__(self, n_samples=5000, seed=42):\n",
        "        np.random.seed(seed)\n",
        "        # Input ranges\n",
        "        d_exotic   = np.random.uniform(0.1, 10.0, (n_samples,1)).astype(np.float32)\n",
        "        r_throat   = np.random.uniform(1.0, 10.0, (n_samples,1)).astype(np.float32)\n",
        "        k_curv     = np.random.uniform(-0.5,0.5,  (n_samples,1)).astype(np.float32)\n",
        "        z_factor   = np.random.uniform(0.5, 5.0,   (n_samples,1)).astype(np.float32)\n",
        "        sigma_aniso= np.random.uniform(0.0, 1.0,   (n_samples,1)).astype(np.float32)\n",
        "\n",
        "        X_raw = np.hstack([d_exotic, r_throat, k_curv, z_factor, sigma_aniso])\n",
        "\n",
        "        # Empirical targets\n",
        "        td = (r_throat / (d_exotic * (1 + z_factor) + 1e-6)).astype(np.float32)\n",
        "        att = np.exp(- d_exotic * sigma_aniso).astype(np.float32)\n",
        "        st = (d_exotic / (np.abs(k_curv) + 1.0)).astype(np.float32)\n",
        "\n",
        "        Y_raw = np.hstack([td, att, st])\n",
        "        Y_raw += 0.02 * np.random.randn(*Y_raw.shape).astype(np.float32)\n",
        "\n",
        "        # 1D normalization stats\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0)  + 1e-6\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0)  + 1e-6\n",
        "\n",
        "        # normalized arrays\n",
        "        self.X = (X_raw - self.X_mean) / self.X_std\n",
        "        self.Y = (Y_raw - self.Y_mean) / self.Y_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. MLP with Dropout & LayerNorm\n",
        "# ------------------------------------------------------------------------------\n",
        "class WormholeCommAI(nn.Module):\n",
        "    def __init__(self, input_dim=5, hidden_dims=(64,64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers, in_dim = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(in_dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            in_dim = h\n",
        "        layers.append(nn.Linear(in_dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Residual Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, inp, stats):\n",
        "    # Denormalize inputs & prediction\n",
        "    X = inp * stats['X_std'] + stats['X_mean']\n",
        "    d_ex, r_th, _, z, _ = X[:,0], X[:,1], X[:,2], X[:,3], X[:,4]\n",
        "    td_pred = pred[:,0] * stats['Y_std'][0] + stats['Y_mean'][0]\n",
        "\n",
        "    # Empirical law\n",
        "    t_phys = r_th / (d_ex * (1 + z) + 1e-6)\n",
        "    return torch.mean((td_pred - t_phys)**2)\n",
        "\n",
        "def total_loss(pred, true, inp, stats, lambda_phys=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, inp, stats)\n",
        "    return mse + lambda_phys * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout Inference\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, x, n_samples=50):\n",
        "    model.train()  # keep dropout active\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            preds.append(model(x).cpu().numpy())\n",
        "    arr = np.stack(preds, 0)\n",
        "    return arr.mean(0), arr.std(0)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-3, wd=1e-5, lambda_phys=1.0,\n",
        "          epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    opt   = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, patience=5)\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train':[], 'val':[]}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # — train\n",
        "        model.train()\n",
        "        t_loss = 0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, _, _ = total_loss(pred, yb, xb, stats, lambda_phys)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            t_loss += loss.item() * xb.size(0)\n",
        "        t_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # — validate\n",
        "        model.eval()\n",
        "        v_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, lambda_phys)\n",
        "                v_loss += loss.item() * xb.size(0)\n",
        "        v_loss /= len(val_loader.dataset)\n",
        "\n",
        "        sched.step(v_loss)\n",
        "        history['train'].append(t_loss)\n",
        "        history['val'].append(v_loss)\n",
        "        print(f\"Epoch {ep:03d} | Train {t_loss:.4e} | Val {v_loss:.4e}\")\n",
        "\n",
        "        # early stopping\n",
        "        if v_loss < best_val - 1e-6:\n",
        "            best_val, wait = v_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_wormhole_comm_ai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(\"best_wormhole_comm_ai.pth\"))\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_losses(hist):\n",
        "    plt.figure()\n",
        "    plt.plot(hist['train'], label='Train')\n",
        "    plt.plot(hist['val'],   label='Val')\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "    plt.legend(); plt.title(\"Training Curve\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_scatter(true, pred, name):\n",
        "    plt.figure()\n",
        "    plt.scatter(true, pred, s=5, alpha=0.5)\n",
        "    m, M = true.min(), true.max()\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.xlabel(f\"True {name}\"); plt.ylabel(f\"Pred {name}\")\n",
        "    plt.title(name)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_uncertainty_heatmap(model, stats_np, device):\n",
        "    vals = np.linspace(0.1,10.0,100)\n",
        "    D, R = np.meshgrid(vals, vals)\n",
        "    grid = np.zeros((D.size,5), dtype=np.float32)\n",
        "    grid[:,0], grid[:,1] = D.ravel(), R.ravel()\n",
        "    grid[:,2] = 0.0\n",
        "    grid[:,3] = stats_np['X_mean'][3]\n",
        "    grid[:,4] = stats_np['X_mean'][4]\n",
        "\n",
        "    Xn = (grid - stats_np['X_mean']) / stats_np['X_std']\n",
        "    Xt = torch.from_numpy(Xn).to(device)\n",
        "    _, std = mc_dropout_predict(model, Xt, n_samples=50)\n",
        "    std_map = std[:,0].reshape(D.shape)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.pcolormesh(vals, vals, std_map, cmap='plasma', shading='auto')\n",
        "    plt.colorbar(label=\"Std(time_delay)\")\n",
        "    plt.xlabel(\"Exotic Density\"); plt.ylabel(\"Throat Radius\")\n",
        "    plt.title(\"Uncertainty in Time Delay\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    ds = WormholeCommDataset(n_samples=8000)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, device=device),\n",
        "        'X_std':  torch.tensor(ds.X_std,  device=device),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, device=device),\n",
        "        'Y_std':  torch.tensor(ds.Y_std,  device=device),\n",
        "    }\n",
        "    stats_np = {\n",
        "        'X_mean': ds.X_mean,\n",
        "        'X_std':  ds.X_std,\n",
        "        'Y_mean': ds.Y_mean,\n",
        "        'Y_std':  ds.Y_std,\n",
        "    }\n",
        "\n",
        "    # Split & loaders\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    tr_ds, va_ds = random_split(ds, [len(ds)-n_val, n_val])\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=64, shuffle=True)\n",
        "    va_ld = DataLoader(va_ds, batch_size=128)\n",
        "\n",
        "    # Build, train & visualize\n",
        "    model   = WormholeCommAI().to(device)\n",
        "    history = train(model, tr_ld, va_ld, stats, device)\n",
        "\n",
        "    plot_losses(history)\n",
        "\n",
        "    # scatter plots\n",
        "    X_all = torch.from_numpy(ds.X).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        Yp_n = model(X_all).cpu().numpy()\n",
        "    Yt_n = ds.Y\n",
        "    Yp = Yp_n * ds.Y_std + ds.Y_mean\n",
        "    Yt = Yt_n * ds.Y_std + ds.Y_mean\n",
        "    names = [\"Time Delay\", \"Attenuation\", \"Stability Margin\"]\n",
        "    for i, nm in enumerate(names):\n",
        "        plot_scatter(Yt[:,i], Yp[:,i], nm)\n",
        "\n",
        "    # uncertainty heatmap\n",
        "    plot_uncertainty_heatmap(model, stats_np, device)"
      ],
      "metadata": {
        "id": "C4y-ZKwf7Cgi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
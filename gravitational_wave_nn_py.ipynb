{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOZbbczstE6cFo5voh3IsHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/gravitational_wave_nn_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2mIp18ke-UL"
      },
      "outputs": [],
      "source": [
        "pip install numpy matplotlib tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# filename: gw_regression_keras.py\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Quieter logs + more deterministic behavior (set before TF import)\n",
        "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")\n",
        "os.environ.setdefault(\"TF_DETERMINISTIC_OPS\", \"1\")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "\n",
        "def generate_gravitational_wave_data(samples: int = 1000, random_state: int = 42, noise: float = 0.0):\n",
        "    \"\"\"\n",
        "    Simulated inputs: (Mass, Distance, Energy) in [0, 1].\n",
        "    Target: Y = sin(Mass) + cos(Distance) * exp(-Energy) + noise\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    X = rng.random((samples, 3), dtype=np.float32)\n",
        "    Y = np.sin(X[:, 0]) + np.cos(X[:, 1]) * np.exp(-X[:, 2])\n",
        "    if noise > 0.0:\n",
        "        Y = Y + rng.normal(0.0, noise, size=samples)\n",
        "    Y = Y.astype(np.float32)\n",
        "    return X, Y.reshape(-1, 1)  # (N, 3), (N, 1)\n",
        "\n",
        "\n",
        "def make_datasets(X, Y, val_ratio: float, batch_size: int, seed: int = 42):\n",
        "    n = X.shape[0]\n",
        "    idx = np.arange(n)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    rng.shuffle(idx)\n",
        "\n",
        "    n_val = max(1, int(val_ratio * n))\n",
        "    val_idx = idx[:n_val]\n",
        "    train_idx = idx[n_val:]\n",
        "\n",
        "    X_train, Y_train = X[train_idx], Y[train_idx]\n",
        "    X_val, Y_val = X[val_idx], Y[val_idx]\n",
        "\n",
        "    train_ds = (\n",
        "        tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "        .shuffle(buffer_size=X_train.shape[0], seed=seed, reshuffle_each_iteration=True)\n",
        "        .batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "    val_ds = (\n",
        "        tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
        "        .batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "    return train_ds, val_ds, (X_train, Y_train, X_val, Y_val)\n",
        "\n",
        "\n",
        "def build_model(hidden1: int = 64, hidden2: int = 32, activation: str = \"relu\", learning_rate: float = 1e-3):\n",
        "    model = Sequential(\n",
        "        [\n",
        "            Dense(hidden1, activation=activation, input_shape=(3,)),\n",
        "            Dense(hidden2, activation=activation),\n",
        "            Dense(1, activation=\"linear\"),  # regression\n",
        "        ]\n",
        "    )\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "def ensure_outdir(path: str) -> None:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "def save_artifacts(outdir: str, model: tf.keras.Model, config: dict, history: dict, metrics: dict, save_model: bool):\n",
        "    ensure_outdir(outdir)\n",
        "    if save_model:\n",
        "        # Save the final model (Keras v3 native format)\n",
        "        final_path = os.path.join(outdir, \"model.keras\")\n",
        "        model.save(final_path)\n",
        "    with open(os.path.join(outdir, \"run_summary.json\"), \"w\") as f:\n",
        "        json.dump({\"config\": config, \"history\": history, \"metrics\": metrics}, f, indent=2)\n",
        "\n",
        "\n",
        "def str2bool(v: str) -> bool:\n",
        "    if isinstance(v, bool):\n",
        "        return v\n",
        "    v = v.strip().lower()\n",
        "    if v in (\"yes\", \"true\", \"t\", \"1\", \"y\"):\n",
        "        return True\n",
        "    if v in (\"no\", \"false\", \"f\", \"0\", \"n\"):\n",
        "        return False\n",
        "    raise argparse.ArgumentTypeError(f\"Boolean value expected, got: {v}\")\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Keras regression on synthetic gravitational wave toy data (Jupyter/Colab-safe).\",\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
        "    )\n",
        "    parser.add_argument(\"--samples\", type=int, default=1000, help=\"Number of synthetic samples.\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=100, help=\"Max training epochs.\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32, help=\"Mini-batch size.\")\n",
        "    parser.add_argument(\"--val_ratio\", type=float, default=0.2, help=\"Validation split ratio.\")\n",
        "    parser.add_argument(\"--noise\", type=float, default=0.0, help=\"Stddev of Gaussian noise on target.\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=1e-3, help=\"Adam learning rate.\")\n",
        "    parser.add_argument(\"--hidden1\", type=int, default=64, help=\"Units in first hidden layer.\")\n",
        "    parser.add_argument(\"--hidden2\", type=int, default=32, help=\"Units in second hidden layer.\")\n",
        "    parser.add_argument(\"--activation\", type=str, default=\"relu\", help=\"Hidden activation.\")\n",
        "    parser.add_argument(\"--patience\", type=int, default=20, help=\"Early stopping patience (epochs).\")\n",
        "    parser.add_argument(\"--random_state\", type=int, default=42, help=\"Random seed.\")\n",
        "    parser.add_argument(\"--outdir\", type=str, default=\"outputs_tf\", help=\"Directory to save artifacts.\")\n",
        "    parser.add_argument(\"--save_model\", type=str, default=\"true\", help=\"Whether to save model artifacts (true/false).\")\n",
        "    parser.add_argument(\n",
        "        \"--test_input\",\n",
        "        type=float,\n",
        "        nargs=3,\n",
        "        metavar=(\"MASS\", \"DIST\", \"ENERGY\"),\n",
        "        help=\"Three feature values to run a single prediction after training.\",\n",
        "    )\n",
        "    # Important: ignore unknown args (e.g., -f <kernel.json> from notebooks)\n",
        "    args, _ = parser.parse_known_args()\n",
        "    args.save_model = str2bool(args.save_model)\n",
        "    return args\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    set_seed(args.random_state)\n",
        "\n",
        "    # Data\n",
        "    X, Y = generate_gravitational_wave_data(\n",
        "        samples=args.samples, random_state=args.random_state, noise=args.noise\n",
        "    )\n",
        "    train_ds, val_ds, (X_train, Y_train, X_val, Y_val) = make_datasets(\n",
        "        X, Y, val_ratio=args.val_ratio, batch_size=args.batch_size, seed=args.random_state\n",
        "    )\n",
        "\n",
        "    # Model\n",
        "    model = build_model(\n",
        "        hidden1=args.hidden1,\n",
        "        hidden2=args.hidden2,\n",
        "        activation=args.activation,\n",
        "        learning_rate=args.learning_rate,\n",
        "    )\n",
        "    model.summary()\n",
        "\n",
        "    # Callbacks\n",
        "    cbs = [\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=args.patience, restore_best_weights=True, verbose=1),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor=\"val_loss\",\n",
        "            factor=0.5,\n",
        "            patience=max(5, args.patience // 2),\n",
        "            min_lr=1e-6,\n",
        "            verbose=1,\n",
        "        ),\n",
        "    ]\n",
        "    if args.save_model:\n",
        "        ensure_outdir(args.outdir)\n",
        "        cbs.append(\n",
        "            ModelCheckpoint(\n",
        "                filepath=os.path.join(args.outdir, \"best.keras\"),\n",
        "                monitor=\"val_loss\",\n",
        "                save_best_only=True,\n",
        "                save_weights_only=False,\n",
        "                verbose=1,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=args.epochs,\n",
        "        verbose=1,\n",
        "        callbacks=cbs,\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_mae = model.evaluate(val_ds, verbose=0)\n",
        "    print(f\"Validation â€” MSE: {val_loss:.6f}, MAE: {val_mae:.6f}\")\n",
        "\n",
        "    # Optional single prediction\n",
        "    test_pred = None\n",
        "    if args.test_input is not None:\n",
        "        test_vec = np.array(args.test_input, dtype=np.float32).reshape(1, 3)\n",
        "        pred = model.predict(test_vec, verbose=0).item()\n",
        "        test_pred = {\"input\": list(map(float, args.test_input)), \"prediction\": float(pred)}\n",
        "        print(f\"Test input: {test_pred['input']} -> predicted distortion: {test_pred['prediction']:.6f}\")\n",
        "\n",
        "    # Save artifacts\n",
        "    config = {\n",
        "        \"samples\": args.samples,\n",
        "        \"epochs\": args.epochs,\n",
        "        \"batch_size\": args.batch_size,\n",
        "        \"val_ratio\": args.val_ratio,\n",
        "        \"noise\": args.noise,\n",
        "        \"learning_rate\": args.learning_rate,\n",
        "        \"hidden1\": args.hidden1,\n",
        "        \"hidden2\": args.hidden2,\n",
        "        \"activation\": args.activation,\n",
        "        \"patience\": args.patience,\n",
        "        \"random_state\": args.random_state,\n",
        "        \"outdir\": args.outdir,\n",
        "    }\n",
        "    metrics = {\"val_mse\": float(val_loss), \"val_mae\": float(val_mae)}\n",
        "    if test_pred is not None:\n",
        "        metrics[\"test_prediction\"] = test_pred\n",
        "\n",
        "    save_artifacts(args.outdir, model, config=config, history=history.history, metrics=metrics, save_model=args.save_model)\n",
        "    print(f\"Artifacts saved to: {args.outdir}\")\n",
        "    print(\"Done.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "XeulSEUCe_kR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
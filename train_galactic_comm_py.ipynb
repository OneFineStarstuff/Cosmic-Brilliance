{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP+k+aDa96hf2KfF4EOZF6i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_galactic_comm_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCAJmJ2uOnp6"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_galactic_comm.py\n",
        "\n",
        "AI pipeline for Type-III civilization resource management:\n",
        "\n",
        "1. Synthetic dataset:\n",
        "   (energy, logistics, distribution, population, growth, colonization, tech)\n",
        "   → (econ_balance, energy_stability, resource_efficiency)\n",
        "2. Domain-informed loss enforcing econ_balance = energy*distribution/population\n",
        "3. MLP with LayerNorm & Dropout\n",
        "4. MC-Dropout inference for uncertainty\n",
        "5. Training loop with AdamW, ReduceLROnPlateau, gradient clipping\n",
        "6. Visualizations: loss curves, scatter plots, uncertainty map\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Synthetic Dataset\n",
        "class GalacticDataset(Dataset):\n",
        "    def __init__(self, n=8000, seed=42):\n",
        "        np.random.seed(seed)\n",
        "        # Features\n",
        "        E = np.random.uniform(1e5, 1e8,   (n,1)).astype(np.float32)  # energy prod\n",
        "        L = np.random.uniform(0.5, 1.0,   (n,1)).astype(np.float32)  # logistics eff\n",
        "        R = np.random.uniform(0.1, 1.0,   (n,1)).astype(np.float32)  # distribution index\n",
        "        P = np.random.uniform(1e9,1e12,   (n,1)).astype(np.float32)  # population\n",
        "        G = np.random.uniform(0.001,0.02, (n,1)).astype(np.float32)  # growth rate\n",
        "        C = np.random.uniform(0.0,0.1,    (n,1)).astype(np.float32)  # colonization rate\n",
        "        T = np.random.uniform(1.0,10.0,   (n,1)).astype(np.float32)  # tech level\n",
        "\n",
        "        X = np.hstack([E, L, R, P, G, C, T])\n",
        "\n",
        "        # Targets via simple domain formulas\n",
        "        econ_balance       = E * R / P\n",
        "        energy_stability   = (E * L) / (P * G + 1e6)\n",
        "        resource_efficiency= (R * L * T) / (C + 0.1)\n",
        "        Y = np.hstack([econ_balance, energy_stability, resource_efficiency])\n",
        "\n",
        "        # add noise\n",
        "        Y += 0.01 * Y.std(axis=0) * np.random.randn(*Y.shape)\n",
        "\n",
        "        # normalization\n",
        "        self.X_mean, self.X_std = X.mean(0), X.std(0) + 1e-6\n",
        "        self.Y_mean, self.Y_std = Y.mean(0), Y.std(0) + 1e-6\n",
        "        self.X = (X - self.X_mean) / self.X_std\n",
        "        self.Y = (Y - self.Y_mean) / self.Y_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.from_numpy(self.X[idx]),\n",
        "            torch.from_numpy(self.Y[idx])\n",
        "        )\n",
        "\n",
        "# 2. Model Definition\n",
        "class GalacticAI(nn.Module):\n",
        "    def __init__(self, in_dim=7, hid=64, out=3, p=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hid),\n",
        "            nn.LayerNorm(hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p),\n",
        "            nn.Linear(hid, hid),\n",
        "            nn.LayerNorm(hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p),\n",
        "            nn.Linear(hid, out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 3. Domain-Informed Loss\n",
        "def phys_loss(pred, X, stats):\n",
        "    # Denormalize\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    E, L, R, P, G, C, T = X_den.t()\n",
        "    Y_den = pred * stats['Y_std'] + stats['Y_mean']\n",
        "    econ_pred = Y_den[:,0]\n",
        "    econ_true = E * R / P\n",
        "    return nn.MSELoss()(econ_pred, econ_true)\n",
        "\n",
        "def total_loss(pred, truth, X, stats, lam=1.0):\n",
        "    mse = nn.MSELoss()(pred, truth)\n",
        "    pl  = phys_loss(pred, X, stats)\n",
        "    return mse + lam*pl, mse, pl\n",
        "\n",
        "# 4. MC-Dropout for Uncertainty Quantification\n",
        "def mc_dropout(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    stacked = torch.stack(preds, dim=0)\n",
        "    return stacked.mean(0), stacked.std(0)\n",
        "\n",
        "# 5. Training Loop\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-3, wd=1e-5, lam=1.0, max_epochs=100, patience=10):\n",
        "\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=wd\n",
        "    )\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    best_val = float('inf')\n",
        "    wait = 0\n",
        "    history = {'train_loss':[], 'val_loss':[]}\n",
        "\n",
        "    for epoch in range(1, max_epochs+1):\n",
        "        model.train()\n",
        "        running_train = 0.0\n",
        "        for Xb, Yb in train_loader:\n",
        "            Xb, Yb = Xb.to(device), Yb.to(device)\n",
        "            preds = model(Xb)\n",
        "            loss, mse, pl = total_loss(preds, Yb, Xb, stats, lam)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            running_train += loss.item() * Xb.size(0)\n",
        "        running_train /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        running_val = 0.0\n",
        "        with torch.no_grad():\n",
        "            for Xb, Yb in val_loader:\n",
        "                Xb, Yb = Xb.to(device), Yb.to(device)\n",
        "                preds = model(Xb)\n",
        "                loss, mse, pl = total_loss(preds, Yb, Xb, stats, lam)\n",
        "                running_val += loss.item() * Xb.size(0)\n",
        "        running_val /= len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(running_val)\n",
        "        history['train_loss'].append(running_train)\n",
        "        history['val_loss'].append(running_val)\n",
        "        print(f\"Epoch {epoch:03d} – Train: {running_train:.4e}, Val: {running_val:.4e}\")\n",
        "\n",
        "        if running_val < best_val - 1e-6:\n",
        "            best_val, wait = running_val, 0\n",
        "            torch.save(model.state_dict(), 'best_galactic.pth')\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load('best_galactic.pth'))\n",
        "    return history\n",
        "\n",
        "# 6. Visualization Helpers\n",
        "def plot_history(hist):\n",
        "    plt.plot(hist['train_loss'], label='Train')\n",
        "    plt.plot(hist['val_loss'],   label='Val')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "    plt.legend(); plt.show()\n",
        "\n",
        "def scatter_compare(y_true, y_pred, name):\n",
        "    plt.scatter(y_true, y_pred, s=5, alpha=0.6)\n",
        "    m, M = y_true.min(), y_true.max()\n",
        "    plt.plot([m,M],[m,M],'r--')\n",
        "    plt.title(name)\n",
        "    plt.xlabel('True'); plt.ylabel('Pred')\n",
        "    plt.show()\n",
        "\n",
        "def plot_uncertainty_map(model, stats, device):\n",
        "    # Sweep Energy vs Population\n",
        "    Es = torch.linspace(1e5,1e8,50,device=device)\n",
        "    Ps = torch.linspace(1e9,1e12,50,device=device)\n",
        "    Em, Pm = torch.meshgrid(Es, Ps, indexing='xy')\n",
        "\n",
        "    # Build grid tensor\n",
        "    grid = torch.zeros(Em.numel(), 7, device=device)\n",
        "    grid[:,0] = Em.reshape(-1)\n",
        "    grid[:,3] = Pm.reshape(-1)\n",
        "    # fix others at their means\n",
        "    for i in (1,2,4,5,6):\n",
        "        grid[:,i] = stats['X_mean'][i]\n",
        "\n",
        "    Xn = (grid - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout(model, Xn, T=100)\n",
        "    U = std[:,0].cpu().numpy().reshape(Em.shape)\n",
        "\n",
        "    plt.pcolormesh(\n",
        "        Em.cpu().numpy(),\n",
        "        Pm.cpu().numpy(),\n",
        "        U,\n",
        "        cmap='inferno'\n",
        "    )\n",
        "    plt.colorbar(label='std of econ_balance')\n",
        "    plt.xlabel('Energy Production'); plt.ylabel('Population')\n",
        "    plt.show()\n",
        "\n",
        "# 7. Main\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Prepare data & stats\n",
        "    dataset = GalacticDataset()\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(dataset.X_mean, device=device),\n",
        "        'X_std':  torch.tensor(dataset.X_std,  device=device),\n",
        "        'Y_mean': torch.tensor(dataset.Y_mean, device=device),\n",
        "        'Y_std':  torch.tensor(dataset.Y_std,  device=device),\n",
        "    }\n",
        "\n",
        "    # Split & loaders\n",
        "    train_ds, val_ds = random_split(dataset, [len(dataset)-1600, 1600])\n",
        "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=256)\n",
        "\n",
        "    # Initialize & train\n",
        "    model   = GalacticAI().to(device)\n",
        "    history = train(\n",
        "        model, train_loader, val_loader,\n",
        "        stats, device,\n",
        "        lr=1e-3, wd=1e-5, lam=1.0,\n",
        "        max_epochs=100, patience=10\n",
        "    )\n",
        "\n",
        "    # Plot training history\n",
        "    plot_history(history)\n",
        "\n",
        "    # True vs. Predicted for each metric\n",
        "    with torch.no_grad():\n",
        "        X_all = torch.from_numpy(dataset.X).to(device)\n",
        "        Y_pred = model(X_all).cpu().numpy()\n",
        "    for i, name in enumerate(['econ_balance','energy_stability','resource_efficiency']):\n",
        "        scatter_compare(dataset.Y[:,i], Y_pred[:,i], name)\n",
        "\n",
        "    # Uncertainty heatmap\n",
        "    plot_uncertainty_map(model, stats, device)"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPjHoT8yawJS30T1YNHhXdo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/Complete_Enhanced_Unified_AI_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CfxQuTDhAiD"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "# !pip install transformers torch pillow numpy gym requests\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Patch: Alias np.bool8 to avoid AttributeError in Gym's checker\n",
        "# -------------------------------------------------------------------\n",
        "if not hasattr(np, \"bool8\"):\n",
        "    np.bool8 = np.bool_\n",
        "\n",
        "from io import BytesIO\n",
        "from collections import deque\n",
        "from PIL import Image\n",
        "from transformers import pipeline\n",
        "import gym\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. NLP: Question-Answering Module\n",
        "# ------------------------------------------------------------------------------\n",
        "class QAModule:\n",
        "    def __init__(self, model_name=\"distilbert-base-cased-distilled-squad\"):\n",
        "        self.qa_pipeline = pipeline(\n",
        "            \"question-answering\", model=model_name, device=-1\n",
        "        )\n",
        "\n",
        "    def answer_questions(self, context, questions):\n",
        "        answers = {}\n",
        "        for q in questions:\n",
        "            try:\n",
        "                res = self.qa_pipeline(question=q, context=context)\n",
        "                if isinstance(res, dict) and \"answer\" in res:\n",
        "                    answers[q] = res[\"answer\"]\n",
        "                else:\n",
        "                    answers[q] = str(res)\n",
        "            except Exception as e:\n",
        "                answers[q] = f\"[Error: {e}]\"\n",
        "        return answers\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Vision: Image Captioning with Caching & Cross-Modal Retrieval\n",
        "# ------------------------------------------------------------------------------\n",
        "class VisionModule:\n",
        "    def __init__(self, model_name=\"Salesforce/blip-image-captioning-base\", cache_dir=\"image_cache\"):\n",
        "        self.caption_pipeline = pipeline(\n",
        "            \"image-to-text\", model=model_name, device=-1\n",
        "        )\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "        self.cache_dir = cache_dir\n",
        "        self.headers = {\n",
        "            \"User-Agent\": \"MyUnifiedAI/1.0 (kyaw@example.com) Python-requests\"\n",
        "        }\n",
        "\n",
        "    def _cache_path(self, url):\n",
        "        return os.path.join(self.cache_dir, url.split(\"/\")[-1])\n",
        "\n",
        "    def load_image(self, url):\n",
        "        path = self._cache_path(url)\n",
        "        if not os.path.exists(path):\n",
        "            resp = requests.get(url, headers=self.headers)\n",
        "            resp.raise_for_status()\n",
        "            with open(path, \"wb\") as f:\n",
        "                f.write(resp.content)\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "\n",
        "    def caption_image(self, url):\n",
        "        img = self.load_image(url)\n",
        "        out = self.caption_pipeline(img)\n",
        "        return out[0][\"generated_text\"]\n",
        "\n",
        "    def caption_and_qa(self, url, qa_module):\n",
        "        caption = self.caption_image(url)\n",
        "        qa_res = qa_module.answer_questions(\n",
        "            context=caption,\n",
        "            questions=[\"What is shown in the image?\"]\n",
        "        )\n",
        "        return caption, qa_res.get(\"What is shown in the image?\", \"[No answer]\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Symbolic Reasoning: Unification & Backward Chaining\n",
        "# ------------------------------------------------------------------------------\n",
        "class SymbolicModule:\n",
        "    def __init__(self, rules):\n",
        "        self.rules = [r.strip().rstrip('.') for r in rules]\n",
        "\n",
        "    def _parse(self, expr):\n",
        "        head, *body = expr.split(\":-\")\n",
        "        pred, args = head.split(\"(\")\n",
        "        args = args[:-1].split(\",\") if args[:-1] else []\n",
        "        body_preds = [b.strip() for b in body[0].split(\",\")] if body else []\n",
        "        return pred.strip(), [a.strip() for a in args], body_preds\n",
        "\n",
        "    def _unify(self, query, fact, theta=None):\n",
        "        if theta is None:\n",
        "            theta = {}\n",
        "        p1, a1, _ = self._parse(query)\n",
        "        p2, a2, _ = self._parse(fact)\n",
        "        if p1 != p2 or len(a1) != len(a2):\n",
        "            return None\n",
        "        theta = theta.copy()\n",
        "        for x, y in zip(a1, a2):\n",
        "            if x[0].isupper():\n",
        "                theta[x] = y\n",
        "            elif y[0].isupper():\n",
        "                theta[y] = x\n",
        "            elif x != y:\n",
        "                return None\n",
        "        return theta\n",
        "\n",
        "    def _backward_chain(self, query, theta=None, visited=None):\n",
        "        if visited is None:\n",
        "            visited = set()\n",
        "        key = (query, frozenset((theta or {}).items()))\n",
        "        if key in visited:\n",
        "            return False\n",
        "        visited.add(key)\n",
        "\n",
        "        for rule in self.rules:\n",
        "            pred, args, body = self._parse(rule)\n",
        "            head = f\"{pred}({','.join(args)})\"\n",
        "            subst = self._unify(query, head, theta)\n",
        "            if subst is None:\n",
        "                continue\n",
        "            if not body:\n",
        "                return True\n",
        "            if all(self._backward_chain(b, subst, visited) for b in body):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def query(self, q):\n",
        "        return self._backward_chain(q)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. Reinforcement Learning: Q-Learning with Experience Replay\n",
        "# ------------------------------------------------------------------------------\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity=1000):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, t): self.buffer.append(t)\n",
        "    def sample(self, n): return random.sample(self.buffer, min(n, len(self.buffer)))\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, n_states, actions, lr=0.1, gamma=0.9, epsilon=0.1,\n",
        "                 buffer_size=1000, batch_size=32):\n",
        "        self.n_states = n_states\n",
        "        self.actions = actions\n",
        "        self.lr, self.gamma, self.epsilon = lr, gamma, epsilon\n",
        "        self.q_table = {}\n",
        "        self.replay = ReplayBuffer(buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def _encode(self, s):\n",
        "        return tuple(np.eye(self.n_states)[s].tolist())\n",
        "\n",
        "    def _ensure(self, s):\n",
        "        if s not in self.q_table:\n",
        "            self.q_table[s] = {a: 0.0 for a in self.actions}\n",
        "\n",
        "    def get_action(self, state):\n",
        "        s = self._encode(state)\n",
        "        self._ensure(s)\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice(self.actions)\n",
        "        return max(self.q_table[s], key=self.q_table[s].get)\n",
        "\n",
        "    def update(self, s, a, r, ns):\n",
        "        self.replay.push((s, a, r, ns))\n",
        "        batch = self.replay.sample(self.batch_size)\n",
        "        for s0, a0, r0, s1 in batch:\n",
        "            e0, e1 = self._encode(s0), self._encode(s1)\n",
        "            self._ensure(e0); self._ensure(e1)\n",
        "            q0 = self.q_table[e0][a0]\n",
        "            self.q_table[e0][a0] = q0 + self.lr * (\n",
        "                r0 + self.gamma * max(self.q_table[e1].values()) - q0\n",
        "            )\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Unified AI System\n",
        "# ------------------------------------------------------------------------------\n",
        "class UnifiedAISystem:\n",
        "    def __init__(self):\n",
        "        self.qa = QAModule()\n",
        "        self.vision = VisionModule()\n",
        "        self.symbolic = SymbolicModule([\n",
        "            \"mortal(X) :- human(X)\",\n",
        "            \"human(Socrates).\"\n",
        "        ])\n",
        "        self.env = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
        "        n = self.env.observation_space.n\n",
        "        self.rl = QLearningAgent(n_states=n, actions=list(range(self.env.action_space.n)))\n",
        "\n",
        "    def run_nlp(self):\n",
        "        ctx = (\"France is a country in Western Europe. \"\n",
        "               \"Its capital, Paris, is known for art and culture.\")\n",
        "        out = self.qa.answer_questions(ctx, [\n",
        "            \"What is the capital of France?\",\n",
        "            \"Where is France located?\"\n",
        "        ])\n",
        "        for q, a in out.items():\n",
        "            print(f\"NLP Q&A — {q} → {a}\")\n",
        "\n",
        "    def run_vision(self):\n",
        "        url = (\n",
        "            \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/\"\n",
        "            \"Tour_Eiffel_Wikimedia_Commons.jpg/\"\n",
        "            \"320px-Tour_Eiffel_Wikimedia_Commons.jpg\"\n",
        "        )\n",
        "        cap, ans = self.vision.caption_and_qa(url, self.qa)\n",
        "        print(f\"Vision — Caption: {cap}\")\n",
        "        print(f\"Vision+NLP — What is shown? → {ans}\")\n",
        "\n",
        "    def run_symbolic(self):\n",
        "        q = \"mortal(Socrates)\"\n",
        "        print(f\"Symbolic — Query: {q} → {self.symbolic.query(q)}\")\n",
        "\n",
        "    def run_rl(self, episodes=100, steps=50):\n",
        "        rewards = []\n",
        "        for _ in range(episodes):\n",
        "            state = self.env.reset()\n",
        "            total = 0\n",
        "            for __ in range(steps):\n",
        "                action = self.rl.get_action(state)\n",
        "                step_out = self.env.step(action)\n",
        "                # Handle both 4-tuple and 5-tuple APIs\n",
        "                if len(step_out) == 5:\n",
        "                    next_state, reward, terminated, truncated, _ = step_out\n",
        "                    done = terminated or truncated\n",
        "                else:\n",
        "                    next_state, reward, done, _ = step_out\n",
        "\n",
        "                self.rl.update(state, action, reward, next_state)\n",
        "                total += reward\n",
        "                state = next_state\n",
        "                if done:\n",
        "                    break\n",
        "            rewards.append(total)\n",
        "        avg = np.mean(rewards)\n",
        "        print(f\"RL — Average Reward over {episodes} episodes: {avg:.2f}\")\n",
        "\n",
        "    def run_all(self):\n",
        "        print(\"\\n--- NLP Module ---\")\n",
        "        self.run_nlp()\n",
        "        print(\"\\n--- Vision Module ---\")\n",
        "        self.run_vision()\n",
        "        print(\"\\n--- Symbolic Module ---\")\n",
        "        self.run_symbolic()\n",
        "        print(\"\\n--- RL Module ---\")\n",
        "        self.run_rl()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    UnifiedAISystem().run_all()"
      ]
    }
  ]
}
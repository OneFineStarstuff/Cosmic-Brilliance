{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM68AgTvEctTdDgOl/gCARv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/warp_bubble_pinn_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ns4awy-Dayv"
      },
      "outputs": [],
      "source": [
        "pip install torch numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "warp_bubble_pinn.py\n",
        "\n",
        "End‐to‐end physics‐informed WarpBubbleAI pipeline:\n",
        "  1. Synthetic dataset: (energy_density, curvature) → (bubble_radius, thickness)\n",
        "  2. PINN loss: data MSE + physics residual enforcing volume‐to‐energy ratio\n",
        "  3. MLP with Dropout & LayerNorm for uncertainty\n",
        "  4. MC‐Dropout inference for predictive uncertainty\n",
        "  5. Training loop with AdamW, ReduceLROnPlateau, early stopping\n",
        "  6. Evaluation: scatter plots, training curves, and uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Data Generator\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def true_warp_params(energy, curvature):\n",
        "    \"\"\"\n",
        "    Toy mapping:\n",
        "      bubble_radius = (energy * curvature)**0.4\n",
        "      thickness     = log(1 + energy/curvature)\n",
        "    \"\"\"\n",
        "    R = (energy * curvature)**0.4\n",
        "    T = np.log1p(energy/curvature)\n",
        "    return R, T\n",
        "\n",
        "class SyntheticWarpBubbleDataset(Dataset):\n",
        "    def __init__(self, n_samples=10000, seed=0):\n",
        "        np.random.seed(seed)\n",
        "        # energy_density ∈ [0.1, 10], curvature ∈ [0.1, 10]\n",
        "        E = np.random.uniform(0.1, 10.0, size=(n_samples,)).astype(np.float32)\n",
        "        C = np.random.uniform(0.1, 10.0, size=(n_samples,)).astype(np.float32)\n",
        "        R, T = true_warp_params(E, C)\n",
        "        Y = np.stack([R, T], axis=1).astype(np.float32)\n",
        "\n",
        "        # Normalize inputs and outputs\n",
        "        self.X = torch.from_numpy(\n",
        "            np.stack([\n",
        "                (E - E.mean())/E.std(),\n",
        "                (C - C.mean())/C.std()\n",
        "            ], axis=1)\n",
        "        )\n",
        "        self.Y = torch.from_numpy(\n",
        "            np.stack([\n",
        "                (R - R.mean())/R.std(),\n",
        "                (T - T.mean())/T.std()\n",
        "            ], axis=1)\n",
        "        )\n",
        "        # Store normalization stats for later inverse-transform\n",
        "        self.stats = {\n",
        "            'E_mean': E.mean(), 'E_std': E.std(),\n",
        "            'C_mean': C.mean(), 'C_std': C.std(),\n",
        "            'R_mean': R.mean(), 'R_std': R.std(),\n",
        "            'T_mean': T.mean(), 'T_std': T.std()\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model Definition: WarpBubbleAI\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class WarpBubbleAI(nn.Module):\n",
        "    def __init__(self, input_dim=2, hidden_dims=[64,64], output_dim=2, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        dim = input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim = h\n",
        "        layers.append(nn.Linear(dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics‐Informed Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def physics_residual(pred, inputs, stats):\n",
        "    \"\"\"\n",
        "    Enforce bubble volume ∝ energy/curvature:\n",
        "      V = 4/3 π R^3\n",
        "      target_ratio = energy / curvature\n",
        "      residual = (V_pred - k*target_ratio)^2\n",
        "    We absorb constants into λ_phys.\n",
        "    \"\"\"\n",
        "    # Un-normalize R and T\n",
        "    R = pred[:,0] * stats['R_std'] + stats['R_mean']\n",
        "    # compute volume\n",
        "    V_pred = (4/3) * np.pi * R.pow(3)\n",
        "    # recover energy and curvature\n",
        "    E = inputs[:,0] * stats['E_std'] + stats['E_mean']\n",
        "    C = inputs[:,1] * stats['C_std'] + stats['C_mean']\n",
        "    ratio = E / C\n",
        "    # physics loss\n",
        "    return nn.MSELoss()(V_pred, ratio)\n",
        "\n",
        "def total_loss(pred, true, inputs, stats, λ_phys=1.0):\n",
        "    mse = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, inputs, stats)\n",
        "    return mse + λ_phys*phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC‐Dropout Inference\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def mc_dropout_predict(model, x, n_samples=50):\n",
        "    model.train()  # keep dropout active\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            preds.append(model(x).cpu().numpy())\n",
        "    arr = np.stack(preds, axis=0)\n",
        "    mean = arr.mean(axis=0)\n",
        "    std  = arr.std(axis=0)\n",
        "    model.eval()\n",
        "    return mean, std\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def train_model(model, train_loader, val_loader, stats,\n",
        "                lr=1e-3, weight_decay=1e-5, λ_phys=1.0,\n",
        "                max_epochs=200, patience=20, device='cpu'):\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    best_val = float('inf')\n",
        "    wait = 0\n",
        "    history = {'train_loss': [], 'val_loss': []}\n",
        "\n",
        "    for epoch in range(1, max_epochs+1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, mse_l, phys_l = total_loss(pred, yb, xb, stats, λ_phys)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * xb.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss, mse_l, phys_l = total_loss(pred, yb, xb, stats, λ_phys)\n",
        "                val_loss += loss.item() * xb.size(0)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch:03d} | Train {train_loss:.4e} | Val {val_loss:.4e}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            torch.save(model.state_dict(), \"best_warpbubble_ai.pth\")\n",
        "            wait = 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    # Load best weights\n",
        "    model.load_state_dict(torch.load(\"best_warpbubble_ai.pth\"))\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Evaluation & Plots\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def plot_training(history):\n",
        "    plt.figure()\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'],   label='Val Loss')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "    plt.legend(); plt.title('Training Curve')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_scatter(true, pred, name):\n",
        "    plt.figure()\n",
        "    plt.scatter(true, pred, s=5, alpha=0.3)\n",
        "    m, M = true.min(), true.max()\n",
        "    plt.plot([m,M],[m,M],'r--')\n",
        "    plt.xlabel(f\"True {name}\"); plt.ylabel(f\"Pred {name}\")\n",
        "    plt.title(f\"{name}: True vs Pred\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_uncertainty_heatmap(model, stats, device):\n",
        "    # grid over energy and curvature\n",
        "    E_vals = np.linspace(0.1, 10.0, 100)\n",
        "    C_vals = np.linspace(0.1, 10.0, 100)\n",
        "    EE, CC = np.meshgrid(E_vals, C_vals)\n",
        "    X = np.stack([(EE - stats['E_mean'])/stats['E_std'],\n",
        "                  (CC - stats['C_mean'])/stats['C_std']], axis=-1)\n",
        "    X_tensor = torch.from_numpy(X.reshape(-1,2)).float().to(device)\n",
        "    mean, std = mc_dropout_predict(model, X_tensor, n_samples=100)\n",
        "    R_std = std[:,0].reshape(CC.shape)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.pcolormesh(EE, CC, R_std, shading='auto', cmap='magma')\n",
        "    plt.colorbar(label=\"Std of R_pred\")\n",
        "    plt.xlabel(\"Energy\"); plt.ylabel(\"Curvature\")\n",
        "    plt.title(\"Uncertainty Heatmap for Bubble Radius\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare data\n",
        "    ds = SyntheticWarpBubbleDataset(n_samples=12000)\n",
        "    stats = ds.stats\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    n_trn = len(ds) - n_val\n",
        "    trn_ds, val_ds = random_split(ds, [n_trn, n_val])\n",
        "    trn_ld = DataLoader(trn_ds, batch_size=128, shuffle=True)\n",
        "    val_ld = DataLoader(val_ds, batch_size=256)\n",
        "\n",
        "    # Build model\n",
        "    model = WarpBubbleAI(input_dim=2).to(device)\n",
        "\n",
        "    # Train\n",
        "    history = train_model(\n",
        "        model, trn_ld, val_ld, stats,\n",
        "        lr=1e-3, weight_decay=1e-5, λ_phys=1.0,\n",
        "        max_epochs=200, patience=20, device=device\n",
        "    )\n",
        "\n",
        "    # Plots\n",
        "    plot_training(history)\n",
        "\n",
        "    # Scatter true vs pred\n",
        "    # Collect full dataset predictions\n",
        "    X_all = ds.X.to(device)\n",
        "    Y_all = ds.Y.numpy()\n",
        "    with torch.no_grad():\n",
        "        Y_pred = model(X_all).cpu().numpy()\n",
        "    # inverse‐transform\n",
        "    R_true = Y_all[:,0] * stats['R_std'] + stats['R_mean']\n",
        "    T_true = Y_all[:,1] * stats['T_std'] + stats['T_mean']\n",
        "    R_pred = Y_pred[:,0] * stats['R_std'] + stats['R_mean']\n",
        "    T_pred = Y_pred[:,1] * stats['T_std'] + stats['T_mean']\n",
        "\n",
        "    plot_scatter(R_true, R_pred, \"Bubble Radius\")\n",
        "    plot_scatter(T_true, T_pred, \"Thickness\")\n",
        "\n",
        "    # Uncertainty heatmap\n",
        "    plot_uncertainty_heatmap(model, stats, device)"
      ],
      "metadata": {
        "id": "9eX1Tt1aDgnO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
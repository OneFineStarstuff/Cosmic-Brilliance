{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPhy4gOPE63tGublRaNEakR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_multiversal_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJXhDoC-Ogpt"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_multiversal_ai.py\n",
        "\n",
        "Physics‐informed AI pipeline for MultiversalAI:\n",
        "\n",
        "1. Synthetic dataset of 6 “multiversal decision” features → 3 decision metrics\n",
        "2. Float32 normalization and dtype consistency\n",
        "3. MLP with LayerNorm & Dropout (accepts int hidden_dims)\n",
        "4. Physics‐informed residual enforcing toy “multiverse” laws in normalized space\n",
        "5. MC‐Dropout for uncertainty quantification\n",
        "6. Training loop with AdamW, ReduceLROnPlateau, gradient clipping, NaN checks, early stopping\n",
        "7. Safe checkpoint load\n",
        "8. Visualizations: loss curves, scatter plots, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Multiversal Decision Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class MultiversalDataset(Dataset):\n",
        "    def __init__(self, n_samples=6000, seed=0):\n",
        "        np.random.seed(seed)\n",
        "        # Features:\n",
        "        # ev_p: event probability ∈ [0,1]\n",
        "        # ev_v: event variance    ∈ [0,1]\n",
        "        # ent_b: entropy balance  ∈ [0.1,10.0]\n",
        "        # caus_m: causality metric∈ [0,1]\n",
        "        # temp_c: temporal coherence ∈ [0,1]\n",
        "        # res_idx: resource index ∈ [1,100]\n",
        "        ev_p   = np.random.rand(n_samples,1).astype(np.float64)\n",
        "        ev_v   = np.random.rand(n_samples,1).astype(np.float64)\n",
        "        ent_b  = np.random.uniform(0.1, 10.0,  (n_samples,1)).astype(np.float64)\n",
        "        caus_m = np.random.rand(n_samples,1).astype(np.float64)\n",
        "        temp_c = np.random.rand(n_samples,1).astype(np.float64)\n",
        "        res_i  = np.random.uniform(1.0, 100.0, (n_samples,1)).astype(np.float64)\n",
        "\n",
        "        X_raw = np.hstack([ev_p, ev_v, ent_b, caus_m, temp_c, res_i])\n",
        "\n",
        "        # Toy “multiverse” targets:\n",
        "        eps = 1e-6\n",
        "        # 1. reality_stability\n",
        "        rs = (ev_p * (1 - ev_v) + caus_m) * temp_c / (ent_b + eps)\n",
        "        # 2. decision_impact\n",
        "        di = ev_p * ev_v * res_i / (1 + ent_b)\n",
        "        # 3. entropy_cost\n",
        "        ec = ent_b * di / (res_i + eps)\n",
        "\n",
        "        Y_raw = np.hstack([rs, di, ec]).astype(np.float64)\n",
        "        # add 1% relative noise\n",
        "        Y_raw += 0.01 * Y_raw.std(axis=0) * np.random.randn(*Y_raw.shape)\n",
        "\n",
        "        # Compute normalization stats\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0) + 1e-8\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0) + 1e-8\n",
        "\n",
        "        # Standardize to float32\n",
        "        self.X = ((X_raw - self.X_mean) / self.X_std).astype(np.float32)\n",
        "        self.Y = ((Y_raw - self.Y_mean) / self.Y_std).astype(np.float32)\n",
        "\n",
        "        print(f\"X range: {self.X.min():.3e}–{self.X.max():.3e}\")\n",
        "        print(f\"Y range: {self.Y.min():.3e}–{self.Y.max():.3e}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model Definition (accepts int hidden_dims)\n",
        "# ------------------------------------------------------------------------------\n",
        "class MultiversalAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dims=(64,64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        # allow integer for hidden_dims\n",
        "        if isinstance(hidden_dims, int):\n",
        "            hidden_dims = (hidden_dims,)\n",
        "\n",
        "        layers, dim = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim = h\n",
        "        layers.append(nn.Linear(dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Residual & Total Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, X, stats):\n",
        "    # Denormalize inputs\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    ev_p, ev_v, ent_b, caus_m, temp_c, res_i = X_den.t()\n",
        "    eps = 1e-4\n",
        "\n",
        "    # True targets\n",
        "    rs_t = (ev_p * (1 - ev_v) + caus_m) * temp_c / torch.clamp(ent_b + eps, min=eps)\n",
        "    di_t = ev_p * ev_v * res_i / (1.0 + ent_b)\n",
        "    ec_t = ent_b * di_t / torch.clamp(res_i + eps, min=eps)\n",
        "\n",
        "    Yt = torch.stack([rs_t, di_t, ec_t], dim=1)\n",
        "    Yt_norm = (Yt - stats['Y_mean']) / stats['Y_std']\n",
        "    return nn.MSELoss()(pred, Yt_norm)\n",
        "\n",
        "def total_loss(pred, true, X, stats, lam=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, X, stats)\n",
        "    return mse + lam * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout Uncertainty Quantification\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    stacked = torch.stack(preds, 0)\n",
        "    return stacked.mean(0), stacked.std(0)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop with NaN Safety & Early Stopping\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-4, wd=1e-5, lam=1.0, epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                     mode='min',\n",
        "                                                     factor=0.5,\n",
        "                                                     patience=5)\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train': [], 'val': []}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # -- Train --\n",
        "        model.train()\n",
        "        run_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, mse, phys = total_loss(pred, yb, xb, stats, lam)\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"NaN loss at epoch {ep}. Aborting.\")\n",
        "                return history\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            run_loss += loss.item() * xb.size(0)\n",
        "        train_loss = run_loss / len(train_loader.dataset)\n",
        "\n",
        "        # -- Validate --\n",
        "        model.eval()\n",
        "        run_val = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, lam)\n",
        "                run_val += loss.item() * xb.size(0)\n",
        "        val_loss = run_val / len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        history['train'].append(train_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        print(f\"Epoch {ep:03d} | Train {train_loss:.4e} | Val {val_loss:.4e}\")\n",
        "\n",
        "        # Checkpoint & early stop\n",
        "        if val_loss < best_val - 1e-8:\n",
        "            best_val, wait = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_multiversal_ai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    # Safe load\n",
        "    if os.path.exists(\"best_multiversal_ai.pth\"):\n",
        "        model.load_state_dict(torch.load(\"best_multiversal_ai.pth\",\n",
        "                                         map_location=device))\n",
        "    else:\n",
        "        print(\"No checkpoint found; using last model state.\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_history(history):\n",
        "    plt.figure()\n",
        "    plt.plot(history['train'], label='Train')\n",
        "    plt.plot(history['val'],   label='Val')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_scatter(y_true, y_pred, title):\n",
        "    plt.figure()\n",
        "    plt.scatter(y_true, y_pred, s=5, alpha=0.6)\n",
        "    m, M = y_true.min(), y_true.max()\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_uncertainty(model, stats, device):\n",
        "    # Vary ev_p (idx=0) vs ev_v (idx=1)\n",
        "    ev_p_vals = np.linspace(0,1,100, dtype=np.float32)\n",
        "    ev_v_vals = np.linspace(0,1,100, dtype=np.float32)\n",
        "    P, V = np.meshgrid(ev_p_vals, ev_v_vals)\n",
        "    pts = P.size\n",
        "\n",
        "    grid = torch.zeros((pts,6), device=device)\n",
        "    grid[:,0] = torch.from_numpy(P.ravel()).to(device)\n",
        "    grid[:,1] = torch.from_numpy(V.ravel()).to(device)\n",
        "    for i in (2,3,4,5):\n",
        "        grid[:,i] = stats['X_mean'][i]\n",
        "\n",
        "    Xn = (grid - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout_predict(model, Xn, T=100)\n",
        "    sigma = std[:,0].cpu().numpy().reshape(P.shape)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.pcolormesh(P, V, sigma, cmap='magma', shading='auto')\n",
        "    plt.colorbar(label=\"Std Stability\")\n",
        "    plt.xlabel(\"Event Probability\")\n",
        "    plt.ylabel(\"Event Variance\")\n",
        "    plt.title(\"Uncertainty Heatmap: Reality Stability\")\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare dataset & stats\n",
        "    ds = MultiversalDataset(n_samples=6000)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, dtype=torch.float32, device=device),\n",
        "        'X_std' : torch.tensor(ds.X_std,  dtype=torch.float32, device=device),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, dtype=torch.float32, device=device),\n",
        "        'Y_std' : torch.tensor(ds.Y_std,  dtype=torch.float32, device=device),\n",
        "    }\n",
        "\n",
        "    # Data loaders\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    tr_ds, va_ds = random_split(ds, [len(ds)-n_val, n_val])\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=128, shuffle=True)\n",
        "    va_ld = DataLoader(va_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    # Model instantiation with single int hidden_dim\n",
        "    model = MultiversalAI(input_dim=6, hidden_dims=32, output_dim=3).to(device)\n",
        "\n",
        "    # Train\n",
        "    history = train(model, tr_ld, va_ld, stats, device,\n",
        "                    lr=1e-4, wd=1e-5, lam=1.0,\n",
        "                    epochs=100, patience=10)\n",
        "\n",
        "    # Visualize\n",
        "    plot_history(history)\n",
        "\n",
        "    # Scatter plots for each target\n",
        "    X_all = torch.from_numpy(ds.X).to(device)\n",
        "    with torch.no_grad():\n",
        "        Yp_norm = model(X_all).cpu().numpy()\n",
        "    Yp = Yp_norm * ds.Y_std + ds.Y_mean\n",
        "    Yt = ds.Y * ds.Y_std + ds.Y_mean\n",
        "    names = [\"Reality Stability\", \"Decision Impact\", \"Entropy Cost\"]\n",
        "    for i, nm in enumerate(names):\n",
        "        plot_scatter(Yt[:,i], Yp[:,i], nm)\n",
        "\n",
        "    # Uncertainty heatmap for stability\n",
        "    plot_uncertainty(model, stats, device)"
      ]
    }
  ]
}
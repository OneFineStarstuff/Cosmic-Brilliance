{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM6+jEWKdoTMhl39OW+Iufw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_blackhole_stability_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td9XM_J-y2HZ"
      },
      "outputs": [],
      "source": [
        "pip install torch numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_blackhole_stability.py\n",
        "\n",
        "Physics-Informed AI pipeline for predicting artificial black hole stability and\n",
        "event horizon radius from input energy, mass, quantum fluctuations, and spin.\n",
        "\n",
        "Pipeline steps:\n",
        " 1. Synthetic dataset of (E, M, Q, a) → (Stability, Horizon Radius)\n",
        " 2. Physics-informed loss enforcing analytic Kerr–Schwarzschild relations\n",
        " 3. MLP with LayerNorm & Dropout for uncertainty estimation\n",
        " 4. MC-Dropout inference to quantify predictive variance\n",
        " 5. Training loop with AdamW, ReduceLROnPlateau, early stopping\n",
        " 6. Visualizations: loss curves, true vs predicted, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class BlackHoleDataset(Dataset):\n",
        "    def __init__(self, n_samples=8000, seed=0):\n",
        "        np.random.seed(seed)\n",
        "        # Sample inputs\n",
        "        E  = np.random.uniform(0.5, 5.0, size=(n_samples,1)).astype(np.float32)\n",
        "        M  = np.random.uniform(1.0, 10.0, size=(n_samples,1)).astype(np.float32)\n",
        "        Q  = np.random.uniform(0.0, 1.0, size=(n_samples,1)).astype(np.float32)\n",
        "        a  = np.random.uniform(-1.0, 1.0, size=(n_samples,1)).astype(np.float32)\n",
        "        # Ensure |a| <= M\n",
        "        a  = a * (M / np.maximum(np.abs(a), 1e-3))\n",
        "\n",
        "        X_raw = np.hstack([E, M, Q, a])\n",
        "\n",
        "        # Analytic targets (with noise)\n",
        "        S_true  = (E * M) / (Q + 1.0)\n",
        "        rh_true = M + np.sqrt(np.maximum(M**2 - a**2, 1e-4))\n",
        "        Y_raw   = np.hstack([S_true, rh_true])\n",
        "        Y_raw  += 0.02 * np.random.randn(*Y_raw.shape).astype(np.float32)\n",
        "\n",
        "        # Compute normalization stats\n",
        "        self.X_mean, self.X_std = X_raw.mean(0), X_raw.std(0)\n",
        "        self.Y_mean, self.Y_std = Y_raw.mean(0), Y_raw.std(0)\n",
        "\n",
        "        # Normalize\n",
        "        self.X = (X_raw - self.X_mean) / self.X_std\n",
        "        self.Y = (Y_raw - self.Y_mean) / self.Y_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.X[idx])\n",
        "        y = torch.from_numpy(self.Y[idx])\n",
        "        return x, y\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model Architecture\n",
        "# ------------------------------------------------------------------------------\n",
        "class BlackHoleAI(nn.Module):\n",
        "    def __init__(self, input_dim=4, hidden_dims=(64,64), output_dim=2, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        dim = input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim = h\n",
        "        layers.append(nn.Linear(dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, inp, stats):\n",
        "    # Denormalize inputs\n",
        "    E = inp[:,0] * stats['X_std'][0] + stats['X_mean'][0]\n",
        "    M = inp[:,1] * stats['X_std'][1] + stats['X_mean'][1]\n",
        "    Q = inp[:,2] * stats['X_std'][2] + stats['X_mean'][2]\n",
        "    a = inp[:,3] * stats['X_std'][3] + stats['X_mean'][3]\n",
        "\n",
        "    # True analytic values (torch)\n",
        "    S_true  = (E * M) / (Q + 1.0)\n",
        "    rh_true = M + torch.sqrt(torch.clamp(M**2 - a**2, min=1e-4))\n",
        "\n",
        "    # Denormalize predictions\n",
        "    S_pred  = pred[:,0] * stats['Y_std'][0] + stats['Y_mean'][0]\n",
        "    rh_pred = pred[:,1] * stats['Y_std'][1] + stats['Y_mean'][1]\n",
        "\n",
        "    # Residual loss\n",
        "    loss_S  = nn.MSELoss()(S_pred,  S_true)\n",
        "    loss_rh = nn.MSELoss()(rh_pred, rh_true)\n",
        "    return loss_S + loss_rh\n",
        "\n",
        "def total_loss(pred, true, inp, stats, λ=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, inp, stats)\n",
        "    return mse + λ * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout Inference\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, x, n_samples=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            preds.append(model(x).cpu().numpy())\n",
        "    arr = np.stack(preds, axis=0)\n",
        "    return arr.mean(0), arr.std(0)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-3, wd=1e-5, λ=1.0, max_epochs=150, patience=15):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train':[], 'val':[]}\n",
        "\n",
        "    for epoch in range(1, max_epochs+1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, _, _ = total_loss(pred, yb, xb, stats, λ)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * xb.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, λ)\n",
        "                val_loss += loss.item() * xb.size(0)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        history['train'].append(train_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        print(f\"Epoch {epoch:03d} | Train {train_loss:.4e} | Val {val_loss:.4e}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val, wait = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_blackhole_ai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(\"best_blackhole_ai.pth\"))\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_losses(history):\n",
        "    plt.figure()\n",
        "    plt.plot(history['train'], label='Train')\n",
        "    plt.plot(history['val'],   label='Val')\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "    plt.legend(); plt.title(\"Loss Curve\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_scatter(true, pred, name):\n",
        "    plt.figure()\n",
        "    plt.scatter(true, pred, s=4, alpha=0.6)\n",
        "    m, M = true.min(), true.max()\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.xlabel(f\"True {name}\"); plt.ylabel(f\"Pred {name}\")\n",
        "    plt.title(f\"{name}: True vs Pred\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load dataset and stats\n",
        "    ds = BlackHoleDataset(n_samples=8000)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, device=device),\n",
        "        'X_std':  torch.tensor(ds.X_std,  device=device),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, device=device),\n",
        "        'Y_std':  torch.tensor(ds.Y_std,  device=device),\n",
        "    }\n",
        "\n",
        "    # Train/val split\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    trn_ds, val_ds = random_split(ds, [len(ds)-n_val, n_val])\n",
        "    trn_ld = DataLoader(trn_ds, batch_size=128, shuffle=True)\n",
        "    val_ld = DataLoader(val_ds, batch_size=256)\n",
        "\n",
        "    # Initialize and train\n",
        "    model   = BlackHoleAI().to(device)\n",
        "    history = train(model, trn_ld, val_ld, stats, device)\n",
        "\n",
        "    # Plot losses\n",
        "    plot_losses(history)\n",
        "\n",
        "    # Evaluate full dataset\n",
        "    X_all = torch.from_numpy(ds.X).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        y_pred_n = model(X_all).cpu().numpy()\n",
        "\n",
        "    # Denormalize\n",
        "    y_true = (ds.Y * ds.Y_std + ds.Y_mean)\n",
        "    y_pred = y_pred_n * ds.Y_std + ds.Y_mean\n",
        "\n",
        "    # Scatter plots\n",
        "    plot_scatter(y_true[:,0], y_pred[:,0], \"Stability\")\n",
        "    plot_scatter(y_true[:,1], y_pred[:,1], \"Horizon Radius\")\n",
        "\n",
        "    # Uncertainty heatmap over E vs M (fixed Q=0.5, a=0)\n",
        "    E_vals = np.linspace(0.5, 5.0, 100)\n",
        "    M_vals = np.linspace(1.0, 10.0, 100)\n",
        "    EE, MM = np.meshgrid(E_vals, M_vals)\n",
        "    QQ = np.full_like(EE, 0.5)\n",
        "    aa = np.zeros_like(EE)\n",
        "    grid = np.stack([EE, MM, QQ, aa], axis=-1)\n",
        "    Xg = (grid - ds.X_mean) / ds.X_std\n",
        "    Xt = torch.from_numpy(Xg.reshape(-1,4)).float().to(device)\n",
        "    _, stds = mc_dropout_predict(model, Xt, n_samples=50)\n",
        "    std_map = stds[:,0].reshape(EE.shape)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.pcolormesh(EE, MM, std_map, cmap='magma', shading='auto')\n",
        "    plt.colorbar(label=\"Std(Stability)\")\n",
        "    plt.xlabel(\"Energy\"); plt.ylabel(\"Mass\")\n",
        "    plt.title(\"Uncertainty Heatmap for Stability\")\n",
        "    plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "i1pQ9JVx0UFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
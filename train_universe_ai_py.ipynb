{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOLt9RhyqtxxBXGi22JaRWV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_universe_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GuqW1bgkO8o"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_universe_ai.py\n",
        "\n",
        "End-to-end pipeline for UniverseAI:\n",
        "1. Synthetic dataset of 6 “universe” features → 3 physics targets\n",
        "2. Float32 normalization\n",
        "3. MLP with LayerNorm, Dropout & ReLU\n",
        "4. Physics-informed constraint enforcing toy balance laws\n",
        "5. MC-Dropout for uncertainty quantification\n",
        "6. Training loop with AdamW, ReduceLROnPlateau, gradient clipping, NaN checks, early stopping\n",
        "7. Checkpointing and safe loading\n",
        "8. Visualizations: loss curves, scatter plots, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Universe Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class UniverseDataset(Dataset):\n",
        "    def __init__(self, n_samples=5000, seed=42):\n",
        "        np.random.seed(seed)\n",
        "        # Features:\n",
        "        # TF: time flow rate ∈ [0.5, 2.0]\n",
        "        # SE: space expansion factor ∈ [0.1, 3.0]\n",
        "        # FF: fundamental forces balance metric ∈ [0.1, 1.0]\n",
        "        # GC: gravitational constant factor ∈ [0.1, 2.0]\n",
        "        # CC: cosmological constant ∈ [1e-12, 1e-10]\n",
        "        # IE: initial entropy ∈ [1.0, 100.0]\n",
        "        TF = np.random.uniform(0.5, 2.0,   (n_samples,1))\n",
        "        SE = np.random.uniform(0.1, 3.0,   (n_samples,1))\n",
        "        FF = np.random.uniform(0.1, 1.0,   (n_samples,1))\n",
        "        GC = np.random.uniform(0.1, 2.0,   (n_samples,1))\n",
        "        CC = np.random.uniform(1e-12,1e-10,(n_samples,1))\n",
        "        IE = np.random.uniform(1.0, 100.0, (n_samples,1))\n",
        "\n",
        "        X_raw = np.hstack([TF, SE, FF, GC, CC, IE]).astype(np.float64)\n",
        "\n",
        "        # Toy physics targets:\n",
        "        # UC: universe coherence ∝ TF * FF / (CC + eps)\n",
        "        # ES: entropy stability ∝ IE / (SE + eps)\n",
        "        # TB: time-energy balance ∝ TF * IE / (GC + eps)\n",
        "        eps = 1e-12\n",
        "        UC = TF * FF / (CC + eps)\n",
        "        ES = IE / (SE + eps)\n",
        "        TB = TF * IE / (GC + eps)\n",
        "\n",
        "        Y_raw = np.hstack([UC, ES, TB]).astype(np.float64)\n",
        "        # add small noise\n",
        "        Y_raw += 0.02 * Y_raw.std(axis=0) * np.random.randn(*Y_raw.shape)\n",
        "\n",
        "        # compute normalization stats\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0) + 1e-8\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0) + 1e-8\n",
        "\n",
        "        # normalize and cast to float32\n",
        "        self.X = ((X_raw - self.X_mean) / self.X_std).astype(np.float32)\n",
        "        self.Y = ((Y_raw - self.Y_mean) / self.Y_std).astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. UniverseAI Model Definition\n",
        "# ------------------------------------------------------------------------------\n",
        "class UniverseAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dims=(64,64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers, dim = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim = h\n",
        "        layers.append(nn.Linear(dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Constraint & Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_constraint(pred, X, stats):\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    TF, SE, FF, GC, CC, IE = X_den.t()\n",
        "    eps = 1e-12\n",
        "\n",
        "    UC_t = TF * FF / (CC + eps)\n",
        "    ES_t = IE / (SE + eps)\n",
        "    TB_t = TF * IE / (GC + eps)\n",
        "\n",
        "    Yt = torch.stack([UC_t, ES_t, TB_t], dim=1)\n",
        "    Yt_norm = (Yt - stats['Y_mean']) / stats['Y_std']\n",
        "    return nn.MSELoss()(pred, Yt_norm)\n",
        "\n",
        "def total_loss(pred, true, X, stats, weight=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_constraint(pred, X, stats)\n",
        "    return mse + weight * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout for Uncertainty Quantification\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    arr = torch.stack(preds, dim=0)\n",
        "    return arr.mean(0), arr.std(0)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop with Safety & Checkpointing\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-4, wd=1e-5, epochs=100, patience=10, phys_weight=1.0):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train_loss': [], 'val_loss': []}\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, _, _ = total_loss(pred, yb, xb, stats, phys_weight)\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"NaN encountered at epoch {epoch}, stopping.\")\n",
        "                return history\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader.dataset)\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, phys_weight)\n",
        "                total_val_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        val_loss = total_val_loss / len(val_loader.dataset)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        print(f\"Epoch {epoch:03d} → Train: {train_loss:.4e}, Val: {val_loss:.4e}\")\n",
        "\n",
        "        # checkpoint & early stop\n",
        "        if val_loss < best_val - 1e-8:\n",
        "            best_val, wait = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_universe_ai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    if os.path.exists(\"best_universe_ai.pth\"):\n",
        "        model.load_state_dict(torch.load(\"best_universe_ai.pth\", map_location=device))\n",
        "\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Utilities\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'],   label='Val Loss')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Training History\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_scatter(y_true, y_pred, name):\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.scatter(y_true, y_pred, alpha=0.6, s=8)\n",
        "    m, M = y_true.min(), y_true.max()\n",
        "    plt.plot([m,M],[m,M],'r--')\n",
        "    plt.title(name)\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_uncertainty_heatmap(model, stats, device):\n",
        "    grid = 100\n",
        "    SE_space = np.linspace(0.1, 3.0, grid, dtype=np.float32)\n",
        "    IE_space = np.linspace(1.0, 100.0, grid, dtype=np.float32)\n",
        "    G1, G2 = np.meshgrid(SE_space, IE_space)\n",
        "    points = G1.size\n",
        "\n",
        "    Xg = torch.zeros((points, 6), device=device)\n",
        "    for i in (0,2,3,4):  # TF, FF, GC, CC = mean\n",
        "        Xg[:,i] = stats['X_mean'][i]\n",
        "    Xg[:,1] = torch.from_numpy(G1.ravel()).to(device)  # SE\n",
        "    Xg[:,5] = torch.from_numpy(G2.ravel()).to(device)  # IE\n",
        "\n",
        "    Xn = (Xg - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout_predict(model, Xn, T=100)\n",
        "    U = std[:,0].cpu().reshape(G1.shape)\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.pcolormesh(G1, G2, U, cmap='magma', shading='auto')\n",
        "    plt.colorbar(label='Uncertainty: Universe Coherence')\n",
        "    plt.xlabel('Space Expansion Factor')\n",
        "    plt.ylabel('Initial Entropy')\n",
        "    plt.title('Uncertainty Heatmap')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    dataset = UniverseDataset(n_samples=5000, seed=42)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(dataset.X_mean, dtype=torch.float32, device=device),\n",
        "        'X_std' : torch.tensor(dataset.X_std,  dtype=torch.float32, device=device),\n",
        "        'Y_mean': torch.tensor(dataset.Y_mean, dtype=torch.float32, device=device),\n",
        "        'Y_std' : torch.tensor(dataset.Y_std,  dtype=torch.float32, device=device),\n",
        "    }\n",
        "\n",
        "    n_val = int(0.2 * len(dataset))\n",
        "    train_ds, val_ds = random_split(dataset, [len(dataset)-n_val, n_val])\n",
        "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = UniverseAI(input_dim=6, hidden_dims=(32,32), output_dim=3, p_drop=0.1).to(device)\n",
        "    history = train(model, train_loader, val_loader, stats, device,\n",
        "                    lr=1e-4, wd=1e-5, epochs=100, patience=10, phys_weight=1.0)\n",
        "\n",
        "    plot_history(history)\n",
        "\n",
        "    X_all = torch.from_numpy(dataset.X).to(device)\n",
        "    with torch.no_grad():\n",
        "        Yp_norm = model(X_all).cpu().numpy()\n",
        "    Yp = Yp_norm * dataset.Y_std + dataset.Y_mean\n",
        "    Yt = dataset.Y * dataset.Y_std + dataset.Y_mean\n",
        "\n",
        "    names = [\"Universe Coherence\", \"Entropy Stability\", \"Time-Energy Balance\"]\n",
        "    for i, nm in enumerate(names):\n",
        "        plot_scatter(Yt[:,i], Yp[:,i], nm)\n",
        "\n",
        "    plot_uncertainty_heatmap(model, stats, device)"
      ]
    }
  ]
}
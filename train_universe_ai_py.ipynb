{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOU6OmHLtyeryT/YcF4eygC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_universe_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_universe_ai.py\n",
        "\n",
        "End‐to‐end pipeline for UniverseAI:\n",
        "\n",
        "1. Generate synthetic “universe” dataset of 6 inputs → 3 targets\n",
        "2. Float32 normalization and dtype consistency\n",
        "3. MLP with LayerNorm, Dropout & ReLU (accepts int hidden_dims)\n",
        "4. Physics‐informed residual enforcing toy universe laws\n",
        "5. MC‐Dropout for uncertainty quantification\n",
        "6. Training loop with AdamW, ReduceLROnPlateau, gradient clipping, NaN checks, early stopping\n",
        "7. Safe checkpoint loading\n",
        "8. Visualization: loss curves, true vs. predicted scatter, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Universe Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class UniverseDataset(Dataset):\n",
        "    def __init__(self, n_samples=5000, seed=0):\n",
        "        np.random.seed(seed)\n",
        "        # Features: TFR, SEF, GS, EC, SF, DED\n",
        "        TFR = np.random.uniform(0.8, 1.2,    (n_samples,1))\n",
        "        SEF = np.random.uniform(0.5, 1.5,    (n_samples,1))\n",
        "        GS  = np.random.uniform(0.1, 2.0,    (n_samples,1))\n",
        "        EC  = np.random.uniform(0.1, 2.0,    (n_samples,1))\n",
        "        SF  = np.random.uniform(0.1, 2.0,    (n_samples,1))\n",
        "        DED = np.random.uniform(1e-12, 1e-10,(n_samples,1))\n",
        "\n",
        "        X_raw = np.hstack([TFR, SEF, GS, EC, SF, DED]).astype(np.float64)\n",
        "\n",
        "        # Toy “universe laws” targets\n",
        "        eps = 1e-12\n",
        "        UC  = TFR * SEF / (GS + eps)                 # coherence\n",
        "        ES  = SEF * (EC + SF) / (DED + eps)          # entropy stability\n",
        "        TEB = TFR * DED / (EC + eps)                 # time‐energy balance\n",
        "\n",
        "        Y_raw = np.hstack([UC, ES, TEB]).astype(np.float64)\n",
        "        Y_raw += 0.01 * Y_raw.std(axis=0) * np.random.randn(*Y_raw.shape)\n",
        "\n",
        "        # Compute normalization stats\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0) + 1e-8\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0) + 1e-8\n",
        "\n",
        "        # Normalize and cast to float32\n",
        "        self.X = ((X_raw - self.X_mean) / self.X_std).astype(np.float32)\n",
        "        self.Y = ((Y_raw - self.Y_mean) / self.Y_std).astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. UniverseAI Model Definition\n",
        "# ------------------------------------------------------------------------------\n",
        "class UniverseAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dims=(64,64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        if isinstance(hidden_dims, int):\n",
        "            hidden_dims = (hidden_dims,)\n",
        "        layers, dim = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim = h\n",
        "        layers.append(nn.Linear(dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics‐informed Residual & Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, X, stats):\n",
        "    # Denormalize inputs\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    TFR, SEF, GS, EC, SF, DED = X_den.t()\n",
        "    eps = 1e-12\n",
        "\n",
        "    UC_t  = TFR * SEF / (GS + eps)\n",
        "    ES_t  = SEF * (EC + SF) / (DED + eps)\n",
        "    TEB_t = TFR * DED / (EC + eps)\n",
        "\n",
        "    Yt = torch.stack([UC_t, ES_t, TEB_t], dim=1)\n",
        "    Yt_norm = (Yt - stats['Y_mean']) / stats['Y_std']\n",
        "    return nn.MSELoss()(pred, Yt_norm)\n",
        "\n",
        "def total_loss(pred, true, X, stats, lam=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, X, stats)\n",
        "    return mse + lam * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC‐Dropout Uncertainty Quantification\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, X, T=50):\n",
        "    model.train()\n",
        "    samples = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            samples.append(model(X))\n",
        "    stacked = torch.stack(samples, dim=0)\n",
        "    return stacked.mean(0), stacked.std(0)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop with NaN Safety & Checkpointing\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, tr_loader, va_loader, stats, device,\n",
        "          lr=1e-4, wd=1e-5, lam=1.0, epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train': [], 'val': []}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # training\n",
        "        model.train()\n",
        "        run = 0.0\n",
        "        for xb, yb in tr_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, _, _ = total_loss(pred, yb, xb, stats, lam)\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"NaN loss at epoch {ep}, aborting.\")\n",
        "                return history\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            run += loss.item() * xb.size(0)\n",
        "        tr_loss = run / len(tr_loader.dataset)\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        run = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in va_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, lam)\n",
        "                run += loss.item() * xb.size(0)\n",
        "        va_loss = run / len(va_loader.dataset)\n",
        "\n",
        "        scheduler.step(va_loss)\n",
        "        history['train'].append(tr_loss)\n",
        "        history['val'].append(va_loss)\n",
        "        print(f\"Epoch {ep:03d} | Train {tr_loss:.4e} | Val {va_loss:.4e}\")\n",
        "\n",
        "        # checkpoint & early stop\n",
        "        if va_loss < best_val - 1e-8:\n",
        "            best_val, wait = va_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_universe_ai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    # load best checkpoint\n",
        "    if os.path.exists(\"best_universe_ai.pth\"):\n",
        "        model.load_state_dict(torch.load(\"best_universe_ai.pth\", map_location=device))\n",
        "    else:\n",
        "        print(\"No checkpoint found; using last model.\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_history(history):\n",
        "    plt.figure()\n",
        "    plt.plot(history['train'], label='Train')\n",
        "    plt.plot(history['val'],   label='Val')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_scatter(y_true, y_pred, title):\n",
        "    plt.figure()\n",
        "    plt.scatter(y_true, y_pred, s=5, alpha=0.6)\n",
        "    m, M = y_true.min(), y_true.max()\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_uncertainty_heatmap(model, stats, device):\n",
        "    grid = 100\n",
        "    TFR = np.linspace(0.8, 1.2, grid, dtype=np.float32)\n",
        "    SEF = np.linspace(0.5, 1.5, grid, dtype=np.float32)\n",
        "    G1, G2 = np.meshgrid(TFR, SEF)\n",
        "    pts = G1.size\n",
        "\n",
        "    Xg = torch.zeros((pts,6), device=device)\n",
        "    # GS, EC, SF, DED = mean\n",
        "    for i in (2,3,4,5):\n",
        "        Xg[:,i] = stats['X_mean'][i]\n",
        "    Xg[:,0] = torch.from_numpy(G1.ravel()).to(device)\n",
        "    Xg[:,1] = torch.from_numpy(G2.ravel()).to(device)\n",
        "\n",
        "    Xn = (Xg - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout_predict(model, Xn, T=100)\n",
        "    U = std[:,0].cpu().reshape(G1.shape)\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.pcolormesh(G1, G2, U, cmap='magma', shading='auto')\n",
        "    plt.colorbar(label='Std(Coherence)')\n",
        "    plt.xlabel('Time Flow Rate')\n",
        "    plt.ylabel('Space Expansion Factor')\n",
        "    plt.title('Uncertainty Heatmap: Universe Coherence')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    ds = UniverseDataset(n_samples=5000, seed=0)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, dtype=torch.float32, device=device),\n",
        "        'X_std' : torch.tensor(ds.X_std,  dtype=torch.float32, device=device),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, dtype=torch.float32, device=device),\n",
        "        'Y_std' : torch.tensor(ds.Y_std,  dtype=torch.float32, device=device),\n",
        "    }\n",
        "\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    tr_ds, va_ds = random_split(ds, [len(ds)-n_val, n_val])\n",
        "    tr_loader = DataLoader(tr_ds, batch_size=128, shuffle=True)\n",
        "    va_loader = DataLoader(va_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = UniverseAI(input_dim=6, hidden_dims=32, output_dim=3, p_drop=0.1).to(device)\n",
        "    history = train(model, tr_loader, va_loader, stats, device,\n",
        "                    lr=1e-4, wd=1e-5, lam=1.0, epochs=100, patience=10)\n",
        "\n",
        "    plot_history(history)\n",
        "\n",
        "    X_all = torch.from_numpy(ds.X).to(device)\n",
        "    with torch.no_grad():\n",
        "        Yp_norm = model(X_all).cpu().numpy()\n",
        "    Yp = Yp_norm * ds.Y_std + ds.Y_mean\n",
        "    Yt = ds.Y * ds.Y_std + ds.Y_mean\n",
        "\n",
        "    names = [\"Universe Coherence\", \"Entropy Stability\", \"Time‐Energy Balance\"]\n",
        "    for i, nm in enumerate(names):\n",
        "        plot_scatter(Yt[:,i], Yp[:,i], nm)\n",
        "\n",
        "    plot_uncertainty_heatmap(model, stats, device)"
      ],
      "metadata": {
        "id": "8Rm7L7mRZU-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
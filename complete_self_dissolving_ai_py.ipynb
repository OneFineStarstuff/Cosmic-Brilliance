{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNpMAujcshNfqi+jESGJWvK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/complete_self_dissolving_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INOnTGbF5NIH"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "complete_self_dissolving_ai.py\n",
        "\n",
        "- Defines a SelfDissolvingAI with non-trainable dissolution_rate.\n",
        "- Generates synthetic data (linear mapping + noise).\n",
        "- Trains with MSE loss, decays dissolution_rate each step.\n",
        "- Logs loss and dissolution trajectory.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class SelfDissolvingAI(nn.Module):\n",
        "    \"\"\"\n",
        "    A neural network whose output is scaled by a self-nullifying buffer.\n",
        "    dissolution_rate starts at 1.0 and decays towards 0 via a manual scheduler.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        # Register as buffer so optimizer ignores it\n",
        "        self.register_buffer(\"dissolution_rate\", torch.tensor(1.0))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        h   = self.relu(self.fc1(x))\n",
        "        out = self.fc2(h) * self.dissolution_rate\n",
        "        return out\n",
        "\n",
        "\n",
        "def synthetic_data(batch_size=32, input_dim=6, output_dim=3):\n",
        "    \"\"\"\n",
        "    Returns a generator function that yields (x, y) pairs.\n",
        "    y = x @ A + Gaussian noise.\n",
        "    \"\"\"\n",
        "    A = torch.randn(input_dim, output_dim)\n",
        "\n",
        "    def _gen():\n",
        "        x = torch.randn(batch_size, input_dim)\n",
        "        y = x @ A + 0.05 * torch.randn(batch_size, output_dim)\n",
        "        return x, y\n",
        "\n",
        "    return _gen\n",
        "\n",
        "\n",
        "def train(\n",
        "    model: nn.Module,\n",
        "    data_gen,\n",
        "    lr: float = 1e-3,\n",
        "    steps: int = 100_000,\n",
        "    log_interval: int = 20_000\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Trains the model on synthetic data, decaying dissolution_rate each step.\n",
        "    \"\"\"\n",
        "    optimizer = optim.Adam(\n",
        "        [p for n, p in model.named_parameters()],\n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    for step in range(1, steps + 1):\n",
        "        optimizer.zero_grad()\n",
        "        x, y = data_gen()\n",
        "        pred = model(x)\n",
        "        loss = ((pred - y) ** 2).mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Decay dissolution_rate buffer (clamped to [0,1])\n",
        "        with torch.no_grad():\n",
        "            model.dissolution_rate.mul_(0.999999).clamp_(0.0, 1.0)\n",
        "\n",
        "        if step % log_interval == 0 or step == 1:\n",
        "            rate = model.dissolution_rate.item()\n",
        "            print(f\"Step {step:6d} | Loss {loss.item():.4f} | Rate {rate:.6e}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Hyperparameters\n",
        "    input_dim, hidden_dim, output_dim = 6, 32, 3\n",
        "    batch_size = 32\n",
        "    lr = 1e-3\n",
        "    steps = 100_000\n",
        "    log_interval = steps // 5\n",
        "\n",
        "    # Setup\n",
        "    model = SelfDissolvingAI(input_dim, hidden_dim, output_dim)\n",
        "    data_gen = synthetic_data(batch_size, input_dim, output_dim)\n",
        "\n",
        "    # Train\n",
        "    train(model, data_gen, lr=lr, steps=steps, log_interval=log_interval)\n",
        "\n",
        "    # Final state\n",
        "    final_rate = model.dissolution_rate.item()\n",
        "    print(f\"\\nFinal Dissolution Rate: {final_rate:.6e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}
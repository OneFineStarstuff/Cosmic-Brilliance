{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOfx8WjZhA3WQ12gKqToeEu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_universe_creation_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2en2Yqml90-9"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_universe_creation_ai.py\n",
        "\n",
        "Physics-informed AI pipeline for UniverseCreationAI with NaN‐safe training.\n",
        "\n",
        "1. Synthetic dataset with range prints\n",
        "2. Float32 normalization and dtype consistency\n",
        "3. MLP with LayerNorm, Dropout, ReLU\n",
        "4. Physics-informed residual with denominator clamps\n",
        "5. MC-Dropout for uncertainty quantification\n",
        "6. Training loop: AdamW, ReduceLROnPlateau, gradient clipping, NaN checks, early stopping\n",
        "7. Safe checkpoint load\n",
        "8. Visualizations: losses, scatter, uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Universe Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class UniverseDataset(Dataset):\n",
        "    def __init__(self, n_samples=5000, seed=123):\n",
        "        np.random.seed(seed)\n",
        "        # Feature ranges\n",
        "        ve = np.random.uniform(1e-12, 1e-10, (n_samples,1))\n",
        "        si = np.random.uniform(1e50,   1e52,   (n_samples,1))\n",
        "        ir = np.random.uniform(50,     70,     (n_samples,1))\n",
        "        de = np.random.uniform(0.6,    0.8,    (n_samples,1))\n",
        "        md = np.random.uniform(0.2,    0.4,    (n_samples,1))\n",
        "        cp = np.random.uniform(0.0,    1.0,    (n_samples,1))\n",
        "\n",
        "        X_raw = np.hstack([ve, si, ir, de, md, cp]).astype(np.float64)\n",
        "\n",
        "        # Toy cosmic‐law targets\n",
        "        eps = 1e-12\n",
        "        us = ir / (ve + eps)\n",
        "        ec = de * md\n",
        "        qc = cp * si**(-1)\n",
        "\n",
        "        Y_raw = np.hstack([us, ec, qc]).astype(np.float64)\n",
        "        Y_raw += 0.01 * Y_raw.std(axis=0) * np.random.randn(*Y_raw.shape)\n",
        "\n",
        "        # Compute stats\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0) + 1e-8\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0) + 1e-8\n",
        "\n",
        "        # Standardize to float32\n",
        "        self.X = ((X_raw - self.X_mean) / self.X_std).astype(np.float32)\n",
        "        self.Y = ((Y_raw - self.Y_mean) / self.Y_std).astype(np.float32)\n",
        "\n",
        "        # Print ranges for debug\n",
        "        print(f\"X range: {self.X.min():.3e} to {self.X.max():.3e}\")\n",
        "        print(f\"Y range: {self.Y.min():.3e} to {self.Y.max():.3e}\")\n",
        "        print(f\"X_std stats: {self.X_std}\")\n",
        "        print(f\"Y_std stats: {self.Y_std}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model Definition\n",
        "# ------------------------------------------------------------------------------\n",
        "class UniverseCreationAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dims=(64,64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers, dim = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim = h\n",
        "        layers.append(nn.Linear(dim, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Residual & Total Loss (with clamps)\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, X, stats):\n",
        "    # Denormalize\n",
        "    X_den = X * stats['X_std'] + stats['X_mean']\n",
        "    ve, si, ir, de, md, cp = X_den.t()\n",
        "    eps = 1e-6  # larger clamp to avoid tiny denominators\n",
        "\n",
        "    us_t = ir / torch.clamp(ve + eps, min=eps)\n",
        "    ec_t = de * md\n",
        "    qc_t = cp * si.pow(-1).clamp(max=1e12)\n",
        "    Yt   = torch.stack([us_t, ec_t, qc_t], dim=1)\n",
        "\n",
        "    Yt_norm = (Yt - stats['Y_mean']) / stats['Y_std']\n",
        "    return nn.MSELoss()(pred, Yt_norm)\n",
        "\n",
        "def total_loss(pred, true, X, stats, lam=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, X, stats)\n",
        "    return mse + lam * phys, mse, phys\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout for Uncertainty Quantification\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, X, T=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(T):\n",
        "            preds.append(model(X))\n",
        "    arr = torch.stack(preds, dim=0)\n",
        "    return arr.mean(0), arr.std(0)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop with NaN Checks\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-4, wd=1e-5, lam=1.0, epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train': [], 'val': []}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        run_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, mse, phys = total_loss(pred, yb, xb, stats, lam)\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"NaN detected at epoch {ep}, batch aborting.\")\n",
        "                return history\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            run_loss += loss.item() * xb.size(0)\n",
        "        train_loss = run_loss / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_run = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, lam)\n",
        "                val_run += loss.item() * xb.size(0)\n",
        "        val_loss = val_run / len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        history['train'].append(train_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        print(f\"Epoch {ep:03d} | Train {train_loss:.4e} | Val {val_loss:.4e}\")\n",
        "\n",
        "        # Checkpoint\n",
        "        if val_loss < best_val - 1e-8:\n",
        "            best_val, wait = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_universe_ai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    # Safe load\n",
        "    if os.path.exists(\"best_universe_ai.pth\"):\n",
        "        model.load_state_dict(torch.load(\"best_universe_ai.pth\", map_location=device))\n",
        "    else:\n",
        "        print(\"Warning: no checkpoint found, using last model state.\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_losses(hist):\n",
        "    plt.figure()\n",
        "    plt.plot(hist['train'], label='Train')\n",
        "    plt.plot(hist['val'],   label='Val')\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.show()\n",
        "\n",
        "def plot_scatter(y_true, y_pred, name):\n",
        "    plt.figure()\n",
        "    plt.scatter(y_true, y_pred, s=5, alpha=0.6)\n",
        "    m, M = y_true.min(), y_true.max()\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.title(name); plt.xlabel(\"True\"); plt.ylabel(\"Pred\"); plt.show()\n",
        "\n",
        "def plot_uncertainty(model, stats, device):\n",
        "    ve_vals = np.linspace(1e-12, 1e-10, 100, dtype=np.float32)\n",
        "    ir_vals = np.linspace(50, 70,        100, dtype=np.float32)\n",
        "    VE, IR   = np.meshgrid(ve_vals, ir_vals)\n",
        "    pts = VE.size\n",
        "\n",
        "    grid = torch.zeros((pts, 6), device=device)\n",
        "    grid[:,0] = torch.from_numpy(VE.ravel()).to(device)\n",
        "    grid[:,2] = torch.from_numpy(IR.ravel()).to(device)\n",
        "    for i in (1,3,4,5):\n",
        "        grid[:,i] = stats['X_mean'][i]\n",
        "\n",
        "    Xn = (grid - stats['X_mean']) / stats['X_std']\n",
        "    _, std = mc_dropout_predict(model, Xn, T=100)\n",
        "    U = std[:,0].cpu().numpy().reshape(VE.shape)\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.pcolormesh(VE, IR, U, cmap='viridis', shading='auto')\n",
        "    plt.colorbar(label='Std Stability')\n",
        "    plt.xlabel('Vacuum Energy Density'); plt.ylabel('Inflation Rate')\n",
        "    plt.title('Uncertainty Heatmap: Universe Stability'); plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Dataset & stats\n",
        "    ds = UniverseDataset(n_samples=5000)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, dtype=torch.float32, device=device),\n",
        "        'X_std':  torch.tensor(ds.X_std,  dtype=torch.float32, device=device),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, dtype=torch.float32, device=device),\n",
        "        'Y_std':  torch.tensor(ds.Y_std,  dtype=torch.float32, device=device),\n",
        "    }\n",
        "\n",
        "    # Data loaders\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    tr_ds, va_ds = random_split(ds, [len(ds)-n_val, n_val])\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=128, shuffle=True)\n",
        "    va_ld = DataLoader(va_ds, batch_size=256)\n",
        "\n",
        "    # Model & train\n",
        "    model   = UniverseCreationAI(input_dim=6, hidden_dims=(64,64), output_dim=3, p_drop=0.1)\n",
        "    history = train(model, tr_ld, va_ld, stats, device,\n",
        "                    lr=1e-4, wd=1e-5, lam=1.0, epochs=100, patience=10)\n",
        "\n",
        "    # Visualize\n",
        "    plot_losses(history)\n",
        "\n",
        "    X_all = torch.from_numpy(ds.X).to(device)\n",
        "    with torch.no_grad():\n",
        "        Yp_norm = model(X_all).cpu().numpy()\n",
        "    Yp = Yp_norm * ds.Y_std + ds.Y_mean\n",
        "    Yt = ds.Y    * ds.Y_std + ds.Y_mean\n",
        "\n",
        "    names = [\"Universe Stability\", \"Expansion Consistency\", \"Quantum Coherence\"]\n",
        "    for i, nm in enumerate(names):\n",
        "        plot_scatter(Yt[:,i], Yp[:,i], nm)\n",
        "\n",
        "    plot_uncertainty(model, stats, device)"
      ]
    }
  ]
}
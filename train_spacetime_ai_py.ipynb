{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNS2AJ2b/475GcNwjtiA1bX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/train_spacetime_ai_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALmW9PaR-A7f"
      },
      "outputs": [],
      "source": [
        "pip install torch numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "train_spacetime_ai.py\n",
        "\n",
        "Physics-informed AI pipeline for space-time curvature control:\n",
        "\n",
        "1. Generate synthetic dataset of 6 inputs → 3 curvature outputs\n",
        "2. Normalize with 1D mean/std vectors\n",
        "3. Build MLP with LayerNorm & Dropout\n",
        "4. Physics-informed loss enforcing R ≈ κ·(energy_density - tension)\n",
        "5. MC-Dropout for uncertainty estimation\n",
        "6. Training loop with AdamW, LR scheduler, early stopping\n",
        "7. Plot losses, scatter, and uncertainty heatmap\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. Synthetic Dataset\n",
        "# ------------------------------------------------------------------------------\n",
        "class SpaceTimeDataset(Dataset):\n",
        "    def __init__(self, n_samples=6000, seed=1):\n",
        "        np.random.seed(seed)\n",
        "        # Inputs: quantum_fluc, exotic_density, energy_density,\n",
        "        # tension_anisotropy, curvature_perturb, control_field\n",
        "        qf  = np.random.uniform(0.0, 1.0, (n_samples,1)).astype(np.float32)\n",
        "        ed  = np.random.uniform(0.1, 10.0,(n_samples,1)).astype(np.float32)\n",
        "        en  = np.random.uniform(0.5, 20.0,(n_samples,1)).astype(np.float32)\n",
        "        ta  = np.random.uniform(0.0, 1.0, (n_samples,1)).astype(np.float32)\n",
        "        cp  = np.random.uniform(-0.5,0.5,(n_samples,1)).astype(np.float32)\n",
        "        cf  = np.random.uniform(0.0, 5.0, (n_samples,1)).astype(np.float32)\n",
        "\n",
        "        X_raw = np.hstack([qf, ed, en, ta, cp, cf])\n",
        "\n",
        "        # Targets: local_curvature, global_curvature, warp_factor\n",
        "        # local_curvature ∝ κ*(energy_density - tension_anisotropy)\n",
        "        κ = 8.0 * np.pi\n",
        "        lc = (κ * (en - ta)).astype(np.float32)\n",
        "        # global_curvature ∝ control_field / (1 + exotic_density)\n",
        "        gc = (cf / (1.0 + ed)).astype(np.float32)\n",
        "        # warp_factor ∝ exp(-quantum_fluc * curvature_perturb)\n",
        "        wf = np.exp(- qf * np.abs(cp)).astype(np.float32)\n",
        "\n",
        "        Y_raw = np.hstack([lc, gc, wf])\n",
        "        Y_raw += 0.01 * np.random.randn(*Y_raw.shape).astype(np.float32)\n",
        "\n",
        "        # 1D normalization stats\n",
        "        self.X_mean = X_raw.mean(axis=0)\n",
        "        self.X_std  = X_raw.std(axis=0) + 1e-6\n",
        "        self.Y_mean = Y_raw.mean(axis=0)\n",
        "        self.Y_std  = Y_raw.std(axis=0) + 1e-6\n",
        "\n",
        "        # normalized tensors\n",
        "        self.X = (X_raw - self.X_mean) / self.X_std\n",
        "        self.Y = (Y_raw - self.Y_mean) / self.Y_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Model Architecture\n",
        "# ------------------------------------------------------------------------------\n",
        "class SpaceTimeAI(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dims=(64,64), output_dim=3, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        layers, dim_in = [], input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [\n",
        "                nn.Linear(dim_in, h),\n",
        "                nn.LayerNorm(h),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p_drop)\n",
        "            ]\n",
        "            dim_in = h\n",
        "        layers.append(nn.Linear(dim_in, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Physics-Informed Loss\n",
        "# ------------------------------------------------------------------------------\n",
        "def physics_residual(pred, inp, stats):\n",
        "    \"\"\"\n",
        "    Enforce an Einstein-like relation:\n",
        "    R_pred ≈ κ*(energy_density - tension_anisotropy)\n",
        "    \"\"\"\n",
        "    # Denormalize\n",
        "    X = inp * stats['X_std'] + stats['X_mean']\n",
        "    en = X[:,2]\n",
        "    ta = X[:,3]\n",
        "    κ = 8.0 * np.pi\n",
        "\n",
        "    # Predicted local curvature\n",
        "    lc_pred = pred[:,0] * stats['Y_std'][0] + stats['Y_mean'][0]\n",
        "    lc_phys = κ * (en - ta)\n",
        "    return torch.mean((lc_pred - lc_phys)**2)\n",
        "\n",
        "def total_loss(pred, true, inp, stats, lambda_phys=1.0):\n",
        "    mse  = nn.MSELoss()(pred, true)\n",
        "    phys = physics_residual(pred, inp, stats)\n",
        "    return mse + lambda_phys * phys, mse, phys\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. MC-Dropout Inference\n",
        "# ------------------------------------------------------------------------------\n",
        "def mc_dropout_predict(model, x, n_samples=50):\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            preds.append(model(x).cpu().numpy())\n",
        "    arr = np.stack(preds, axis=0)\n",
        "    return arr.mean(0), arr.std(0)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Training Loop\n",
        "# ------------------------------------------------------------------------------\n",
        "def train(model, train_loader, val_loader, stats, device,\n",
        "          lr=1e-3, wd=1e-5, lambda_phys=1.0,\n",
        "          epochs=100, patience=10):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    best_val, wait = float('inf'), 0\n",
        "    history = {'train': [], 'val': []}\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Training step\n",
        "        model.train()\n",
        "        total_train = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss, _, _ = total_loss(pred, yb, xb, stats, lambda_phys)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train += loss.item() * xb.size(0)\n",
        "        avg_train = total_train / len(train_loader.dataset)\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        total_val = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                pred = model(xb)\n",
        "                loss, _, _ = total_loss(pred, yb, xb, stats, lambda_phys)\n",
        "                total_val += loss.item() * xb.size(0)\n",
        "        avg_val = total_val / len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(avg_val)\n",
        "        history['train'].append(avg_train)\n",
        "        history['val'].append(avg_val)\n",
        "        print(f\"Epoch {epoch:03d} | Train {avg_train:.4e} | Val {avg_val:.4e}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if avg_val < best_val - 1e-6:\n",
        "            best_val, wait = avg_val, 0\n",
        "            torch.save(model.state_dict(), \"best_spacetime_ai.pth\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(\"best_spacetime_ai.pth\"))\n",
        "    return history\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Visualization Helpers\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_losses(history):\n",
        "    plt.figure()\n",
        "    plt.plot(history['train'], label='Train')\n",
        "    plt.plot(history['val'],   label='Val')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_scatter(true_vals, pred_vals, name):\n",
        "    plt.figure()\n",
        "    plt.scatter(true_vals, pred_vals, s=5, alpha=0.5)\n",
        "    m, M = true_vals.min(), true_vals.max()\n",
        "    plt.plot([m, M], [m, M], 'r--')\n",
        "    plt.xlabel(f\"True {name}\")\n",
        "    plt.ylabel(f\"Pred {name}\")\n",
        "    plt.title(f\"{name}: True vs Pred\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_uncertainty_heatmap(model, stats_np, device):\n",
        "    # Vary energy_density vs control_field, fix others at mean\n",
        "    vals = np.linspace(0.1, 20.0, 100)\n",
        "    ED, CF = np.meshgrid(vals, vals)\n",
        "    grid = np.zeros((ED.size, 6), dtype=np.float32)\n",
        "    grid[:,2] = ED.ravel()  # energy_density\n",
        "    grid[:,5] = CF.ravel()  # control_field\n",
        "    # fix quantum_fluc, exotic_density, tension, curvature_perturb\n",
        "    for i in [0,1,3,4]:\n",
        "        grid[:,i] = stats_np['X_mean'][i]\n",
        "\n",
        "    Xn = (grid - stats_np['X_mean']) / stats_np['X_std']\n",
        "    Xt = torch.from_numpy(Xn).float().to(device)\n",
        "    _, std = mc_dropout_predict(model, Xt, n_samples=50)\n",
        "    std_map = std[:,0].reshape(ED.shape)  # uncertainty in local_curvature\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.pcolormesh(vals, vals, std_map, cmap='viridis', shading='auto')\n",
        "    plt.colorbar(label=\"Std(local_curvature)\")\n",
        "    plt.xlabel(\"Energy Density\")\n",
        "    plt.ylabel(\"Control Field\")\n",
        "    plt.title(\"Uncertainty Heatmap for Local Curvature\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Main Execution\n",
        "# ------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Prepare dataset\n",
        "    ds = SpaceTimeDataset(n_samples=8000)\n",
        "    stats = {\n",
        "        'X_mean': torch.tensor(ds.X_mean, device=device),\n",
        "        'X_std':  torch.tensor(ds.X_std,  device=device),\n",
        "        'Y_mean': torch.tensor(ds.Y_mean, device=device),\n",
        "        'Y_std':  torch.tensor(ds.Y_std,  device=device),\n",
        "    }\n",
        "    stats_np = {\n",
        "        'X_mean': ds.X_mean,\n",
        "        'X_std':  ds.X_std,\n",
        "        'Y_mean': ds.Y_mean,\n",
        "        'Y_std':  ds.Y_std,\n",
        "    }\n",
        "\n",
        "    # Split into train/validation\n",
        "    n_val = int(0.2 * len(ds))\n",
        "    tr_ds, va_ds = random_split(ds, [len(ds) - n_val, n_val])\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=64, shuffle=True)\n",
        "    va_ld = DataLoader(va_ds, batch_size=128)\n",
        "\n",
        "    # Build and train model\n",
        "    model   = SpaceTimeAI().to(device)\n",
        "    history = train(model, tr_ld, va_ld, stats, device)\n",
        "\n",
        "    # Visualizations\n",
        "    plot_losses(history)\n",
        "\n",
        "    # Scatter plots for outputs\n",
        "    X_all = torch.from_numpy(ds.X).float().to(device)\n",
        "    with torch.no_grad():\n",
        "        Y_pred_n = model(X_all).cpu().numpy()\n",
        "    Y_true_n = ds.Y\n",
        "    Y_pred = Y_pred_n * ds.Y_std + ds.Y_mean\n",
        "    Y_true = Y_true_n * ds.Y_std + ds.Y_mean\n",
        "    names = [\"Local Curvature\", \"Global Curvature\", \"Warp Factor\"]\n",
        "    for i, nm in enumerate(names):\n",
        "        plot_scatter(Y_true[:,i], Y_pred[:,i], nm)\n",
        "\n",
        "    # Uncertainty heatmap\n",
        "    plot_uncertainty_heatmap(model, stats_np, device)"
      ],
      "metadata": {
        "id": "u3KB40kp-9GM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOv/MbptKt3Mb00RjQk/EEO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/meta_intelligence_end_to_end_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhmBDJHH6MV9"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "meta_intelligence_end_to_end.py\n",
        "\n",
        "A notebook/Colab-safe end-to-end script for training, evaluating, and\n",
        "predicting with a compact MLP on synthetic blobs, supporting:\n",
        "- Self-supervised (consistency) training\n",
        "- Supervised training\n",
        "- Hybrid (self + supervised) training\n",
        "\n",
        "Artifacts:\n",
        "- <run_dir>/config.json\n",
        "- <run_dir>/metrics.csv\n",
        "- <run_dir>/model.pt\n",
        "- <run_dir>/metrics.png        (if matplotlib available)\n",
        "- <run_dir>/boundary.png       (if dim == 2 and matplotlib available)\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import csv\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Optional plotting (script runs without it)\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    _HAS_MPL = True\n",
        "except Exception:\n",
        "    _HAS_MPL = False\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Notebook-safe CLI utilities\n",
        "# ----------------------------\n",
        "\n",
        "def sanitize_argv(argv: Optional[List[str]] = None) -> List[str]:\n",
        "    \"\"\"Strip Jupyter/Colab's '-f <kernel.json>' and stray kernel json args.\"\"\"\n",
        "    if argv is None:\n",
        "        argv = sys.argv[1:]\n",
        "    cleaned, skip = [], False\n",
        "    for a in argv:\n",
        "        if skip:\n",
        "            skip = False\n",
        "            continue\n",
        "        if a == \"-f\":\n",
        "            skip = True\n",
        "            continue\n",
        "        if a.endswith(\".json\") and (\"jupyter\" in a or \"kernel\" in a):\n",
        "            continue\n",
        "        cleaned.append(a)\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Reproducibility and misc\n",
        "# ----------------------------\n",
        "\n",
        "def set_seed(seed: int) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def ts() -> str:\n",
        "    return time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "\n",
        "def ensure_dir(path: str) -> None:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Data generation (synthetic blobs)\n",
        "# ----------------------------\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    dim: int = 2\n",
        "    n_classes: int = 2\n",
        "    radius: float = 3.0\n",
        "    spread: float = 1.0\n",
        "    extra_noise: float = 0.5  # for dims > 2\n",
        "\n",
        "\n",
        "def make_dataset(n_samples: int, cfg: DataConfig, seed: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Two-class blobs on a circle in 2D, padded with noise for higher dims.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n0 = n_samples // 2\n",
        "    n1 = n_samples - n0\n",
        "\n",
        "    ang0, ang1 = 0.0, math.pi\n",
        "    c0 = np.array([cfg.radius * math.cos(ang0), cfg.radius * math.sin(ang0)], dtype=np.float32)\n",
        "    c1 = np.array([cfg.radius * math.cos(ang1), cfg.radius * math.sin(ang1)], dtype=np.float32)\n",
        "\n",
        "    x0 = rng.normal(0, cfg.spread, size=(n0, 2)).astype(np.float32) + c0\n",
        "    x1 = rng.normal(0, cfg.spread, size=(n1, 2)).astype(np.float32) + c1\n",
        "    X = np.vstack([x0, x1])\n",
        "\n",
        "    if cfg.dim > 2:\n",
        "        extra = rng.normal(0, cfg.extra_noise, size=(n_samples, cfg.dim - 2)).astype(np.float32)\n",
        "        X = np.hstack([X, extra])\n",
        "\n",
        "    y = np.concatenate([np.zeros(n0, dtype=np.int64), np.ones(n1, dtype=np.int64)], axis=0)\n",
        "\n",
        "    idx = rng.permutation(n_samples)\n",
        "    return X[idx], y[idx]\n",
        "\n",
        "\n",
        "def split_dataset(X: np.ndarray, y: np.ndarray, val_ratio: float, test_ratio: float, seed: int):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = X.shape[0]\n",
        "    idx = rng.permutation(n)\n",
        "    n_test = int(test_ratio * n)\n",
        "    n_val = int(val_ratio * n)\n",
        "\n",
        "    test_idx = idx[:n_test]\n",
        "    val_idx = idx[n_test:n_test + n_val]\n",
        "    train_idx = idx[n_test + n_val:]\n",
        "\n",
        "    return (X[train_idx], y[train_idx],\n",
        "            X[val_idx], y[val_idx],\n",
        "            X[test_idx], y[test_idx])\n",
        "\n",
        "\n",
        "def to_tensor(x: np.ndarray, y: Optional[np.ndarray], device: torch.device):\n",
        "    xt = torch.tensor(x, dtype=torch.float32, device=device)\n",
        "    yt = None if y is None else torch.tensor(y, dtype=torch.long, device=device)\n",
        "    return xt, yt\n",
        "\n",
        "\n",
        "def augment_noise(x: torch.Tensor, sigma: float = 0.25) -> torch.Tensor:\n",
        "    return x + sigma * torch.randn_like(x)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Model\n",
        "# ----------------------------\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim: int, n_classes: int, hidden: int = 64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Loss helpers and metrics\n",
        "# ----------------------------\n",
        "\n",
        "def entropy_from_logits(logits: torch.Tensor) -> torch.Tensor:\n",
        "    p = logits.softmax(dim=-1).clamp_min(1e-12)\n",
        "    return (-(p * p.log()).sum(dim=-1)).mean()\n",
        "\n",
        "\n",
        "def cross_entropy_soft_targets(logits: torch.Tensor, target_probs: torch.Tensor) -> torch.Tensor:\n",
        "    logp = logits.log_softmax(dim=-1)\n",
        "    return (-(target_probs * logp).sum(dim=-1)).mean()\n",
        "\n",
        "\n",
        "def one_hot(n_classes: int, labels: torch.Tensor) -> torch.Tensor:\n",
        "    return F.one_hot(labels, num_classes=n_classes).float()\n",
        "\n",
        "\n",
        "def label_smooth(target_one_hot: torch.Tensor, smoothing: float) -> torch.Tensor:\n",
        "    if smoothing <= 0.0:\n",
        "        return target_one_hot\n",
        "    K = target_one_hot.shape[-1]\n",
        "    u = torch.full_like(target_one_hot, 1.0 / K)\n",
        "    return (1.0 - smoothing) * target_one_hot + smoothing * u\n",
        "\n",
        "\n",
        "def consistency_kl(logits_a: torch.Tensor, logits_b: torch.Tensor) -> torch.Tensor:\n",
        "    pa = logits_a.softmax(dim=-1).clamp_min(1e-8)\n",
        "    pb = logits_b.softmax(dim=-1).clamp_min(1e-8)\n",
        "    kl_ab = (pa * (pa.log() - pb.log())).sum(dim=-1)\n",
        "    kl_ba = (pb * (pb.log() - pa.log())).sum(dim=-1)\n",
        "    return 0.5 * (kl_ab + kl_ba).mean()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(logits: torch.Tensor, y: torch.Tensor) -> float:\n",
        "    pred = logits.argmax(dim=-1)\n",
        "    return (pred == y).float().mean().item()\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Training + evaluation\n",
        "# ----------------------------\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    mode: str\n",
        "    steps: int\n",
        "    batch_size: int\n",
        "    lr: float\n",
        "    wd: float\n",
        "    entropy_bonus: float\n",
        "    label_sharpen: float\n",
        "    seed: int\n",
        "    outdir: str\n",
        "    log_every: int\n",
        "    dim: int\n",
        "    n_classes: int\n",
        "    train_size: int\n",
        "    val_ratio: float\n",
        "    test_ratio: float\n",
        "    device: str = \"auto\"\n",
        "\n",
        "    def device_obj(self) -> torch.device:\n",
        "        if self.device == \"cpu\":\n",
        "            return torch.device(\"cpu\")\n",
        "        if self.device == \"cuda\":\n",
        "            return torch.device(\"cuda\")\n",
        "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def make_run_dir(cfg: TrainConfig) -> str:\n",
        "    run_dir = os.path.join(cfg.outdir, f\"{ts()}_{cfg.mode}_seed{cfg.seed}_dim{cfg.dim}\")\n",
        "    ensure_dir(run_dir)\n",
        "    with open(os.path.join(run_dir, \"config.json\"), \"w\") as f:\n",
        "        json.dump(asdict(cfg), f, indent=2)\n",
        "    return run_dir\n",
        "\n",
        "\n",
        "def train_run(cfg: TrainConfig) -> str:\n",
        "    set_seed(cfg.seed)\n",
        "    device = cfg.device_obj()\n",
        "    run_dir = make_run_dir(cfg)\n",
        "\n",
        "    # Data\n",
        "    X, y = make_dataset(cfg.train_size + 2048, DataConfig(cfg.dim, cfg.n_classes), seed=cfg.seed)\n",
        "    Xtr, ytr, Xval, yval, Xte, yte = split_dataset(X, y, cfg.val_ratio, cfg.test_ratio, seed=cfg.seed + 1)\n",
        "    Xtr_t, ytr_t = to_tensor(Xtr, ytr, device)\n",
        "    Xval_t, yval_t = to_tensor(Xval, yval, device)\n",
        "\n",
        "    model = MLP(cfg.dim, cfg.n_classes, hidden=64).to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.wd)\n",
        "\n",
        "    csv_path = os.path.join(run_dir, \"metrics.csv\")\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow([\"step\", \"loss\", \"sup\", \"ssl\", \"entropy\", \"val_acc\"])\n",
        "\n",
        "    n = Xtr_t.shape[0]\n",
        "    for step in range(1, cfg.steps + 1):\n",
        "        model.train()\n",
        "        idx = np.random.randint(0, n, size=(cfg.batch_size,))\n",
        "        xb = Xtr_t[idx]\n",
        "        yb = ytr_t[idx]\n",
        "\n",
        "        logits = model(xb)\n",
        "\n",
        "        loss_sup = torch.tensor(0.0, device=device)\n",
        "        loss_ssl = torch.tensor(0.0, device=device)\n",
        "\n",
        "        if cfg.mode in (\"supervised\", \"hybrid\"):\n",
        "            y1h = one_hot(cfg.n_classes, yb)\n",
        "            ysoft = label_smooth(y1h, cfg.label_sharpen)\n",
        "            loss_sup = cross_entropy_soft_targets(logits, ysoft)\n",
        "\n",
        "        if cfg.mode in (\"self\", \"hybrid\"):\n",
        "            xa = augment_noise(xb, 0.25)\n",
        "            xb2 = augment_noise(xb, 0.25)\n",
        "            la = model(xa)\n",
        "            lb = model(xb2)\n",
        "            loss_ssl = consistency_kl(la, lb)\n",
        "\n",
        "        ent = entropy_from_logits(logits)\n",
        "        total = loss_sup + loss_ssl - cfg.entropy_bonus * ent\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        total.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if step % cfg.log_every == 0 or step in (1, cfg.steps):\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_acc = accuracy(model(Xval_t), yval_t)\n",
        "            with open(csv_path, \"a\", newline=\"\") as f:\n",
        "                csv.writer(f).writerow([\n",
        "                    step,\n",
        "                    f\"{float(total):.6f}\",\n",
        "                    f\"{float(loss_sup):.6f}\",\n",
        "                    f\"{float(loss_ssl):.6f}\",\n",
        "                    f\"{float(ent):.6f}\",\n",
        "                    f\"{val_acc:.4f}\",\n",
        "                ])\n",
        "            print(f\"[{step:5d}/{cfg.steps}] mode={cfg.mode} \"\n",
        "                  f\"loss={float(total):.4f} sup={float(loss_sup):.4f} ssl={float(loss_ssl):.4f} \"\n",
        "                  f\"ent={float(ent):.4f} val_acc={val_acc:.3f}\")\n",
        "\n",
        "    # Save model and a tiny eval set for convenience\n",
        "    torch.save({\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"in_dim\": cfg.dim,\n",
        "        \"n_classes\": cfg.n_classes,\n",
        "        \"config\": asdict(cfg),\n",
        "    }, os.path.join(run_dir, \"model.pt\"))\n",
        "\n",
        "    # Optional plots\n",
        "    if _HAS_MPL:\n",
        "        try_plot_metrics(csv_path, os.path.join(run_dir, \"metrics.png\"))\n",
        "        if cfg.dim == 2:\n",
        "            try_plot_boundary(model, Xte, yte, os.path.join(run_dir, \"boundary.png\"), device)\n",
        "\n",
        "    print(f\"Done. Outputs saved to: {run_dir}\")\n",
        "    return run_dir\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_run(ckpt_path: str) -> None:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    payload = torch.load(ckpt_path, map_location=device)\n",
        "    in_dim = payload[\"in_dim\"]\n",
        "    n_classes = payload[\"n_classes\"]\n",
        "    cfg = payload[\"config\"]\n",
        "\n",
        "    model = MLP(in_dim, n_classes, hidden=64).to(device)\n",
        "    model.load_state_dict(payload[\"model_state\"])\n",
        "    model.eval()\n",
        "\n",
        "    X, y = make_dataset(4096, DataConfig(in_dim, n_classes), seed=cfg[\"seed\"] + 999)\n",
        "    Xt, yt = to_tensor(X, y, device)\n",
        "    logits = model(Xt)\n",
        "    acc = accuracy(logits, yt)\n",
        "    print(f\"Eval accuracy on fresh synthetic test set: {acc:.4f}\")\n",
        "\n",
        "    # Plot boundary if 2D\n",
        "    if _HAS_MPL and in_dim == 2:\n",
        "        try_plot_boundary(model, X, y, os.path.join(os.path.dirname(ckpt_path), \"boundary_eval.png\"), device)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_run(ckpt_path: str, points_csv: Optional[str], points_inline: Optional[str]) -> None:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    payload = torch.load(ckpt_path, map_location=device)\n",
        "    in_dim = payload[\"in_dim\"]\n",
        "    n_classes = payload[\"n_classes\"]\n",
        "\n",
        "    model = MLP(in_dim, n_classes, hidden=64).to(device)\n",
        "    model.load_state_dict(payload[\"model_state\"])\n",
        "    model.eval()\n",
        "\n",
        "    pts = []\n",
        "    if points_csv:\n",
        "        import pandas as pd  # optional; pip install pandas if needed\n",
        "        df = pd.read_csv(points_csv, header=None)\n",
        "        pts = df.values.astype(np.float32).tolist()\n",
        "    elif points_inline:\n",
        "        # format: \"x1,x2; y1,y2; ...\"\n",
        "        for chunk in points_inline.split(\";\"):\n",
        "            row = [float(t) for t in chunk.strip().split(\",\") if t.strip() != \"\"]\n",
        "            if len(row) != in_dim:\n",
        "                raise ValueError(f\"Each point must have {in_dim} values.\")\n",
        "            pts.append(row)\n",
        "    else:\n",
        "        raise ValueError(\"Provide --points-csv or --points-inline.\")\n",
        "\n",
        "    Xt = torch.tensor(np.array(pts, dtype=np.float32), device=device)\n",
        "    logits = model(Xt)\n",
        "    probs = logits.softmax(dim=-1).cpu().numpy()\n",
        "    preds = probs.argmax(axis=-1).tolist()\n",
        "\n",
        "    out = [{\"x\": p, \"pred\": int(c), \"probs\": [float(q) for q in pr]} for p, c, pr in zip(pts, preds, probs)]\n",
        "    print(json.dumps(out, indent=2))\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Plotting helpers\n",
        "# ----------------------------\n",
        "\n",
        "def try_plot_metrics(csv_path: str, out_png: str) -> None:\n",
        "    if not os.path.exists(csv_path):\n",
        "        return\n",
        "    steps, loss, sup, ssl, ent, acc = [], [], [], [], [], []\n",
        "    with open(csv_path, \"r\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for r in reader:\n",
        "            steps.append(int(r[\"step\"]))\n",
        "            loss.append(float(r[\"loss\"]))\n",
        "            sup.append(float(r[\"sup\"]))\n",
        "            ssl.append(float(r[\"ssl\"]))\n",
        "            ent.append(float(r[\"entropy\"]))\n",
        "            acc.append(float(r[\"val_acc\"]))\n",
        "    if not steps:\n",
        "        return\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
        "    ax.plot(steps, loss, label=\"total\")\n",
        "    ax.plot(steps, sup, label=\"supervised\")\n",
        "    ax.plot(steps, ssl, label=\"self\")\n",
        "    ax.plot(steps, ent, label=\"entropy\")\n",
        "    ax.plot(steps, acc, label=\"val_acc\")\n",
        "    ax.set_title(\"Training metrics\")\n",
        "    ax.set_xlabel(\"step\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out_png, dpi=140)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def try_plot_boundary(model: nn.Module, X: np.ndarray, y: np.ndarray, out_png: str, device: torch.device) -> None:\n",
        "    \"\"\"2D decision boundary + points.\"\"\"\n",
        "    if X.shape[1] != 2:\n",
        "        return\n",
        "    x_min, x_max = X[:, 0].min() - 1.5, X[:, 0].max() + 1.5\n",
        "    y_min, y_max = X[:, 1].min() - 1.5, X[:, 1].max() + 1.5\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 400), np.linspace(y_min, y_max, 400))\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()].astype(np.float32)\n",
        "    with torch.no_grad():\n",
        "        logits = model(torch.tensor(grid, device=device))\n",
        "        Z = logits.softmax(dim=-1)[:, 1].cpu().numpy().reshape(xx.shape)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
        "    cs = ax.contourf(xx, yy, Z, levels=30, cmap=\"coolwarm\", alpha=0.8)\n",
        "    fig.colorbar(cs, ax=ax, label=\"P(class=1)\")\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=\"bwr\", edgecolor=\"k\", s=12, alpha=0.8)\n",
        "    ax.set_title(\"Decision boundary\")\n",
        "    ax.set_xlabel(\"x1\")\n",
        "    ax.set_ylabel(\"x2\")\n",
        "    ax.grid(True, alpha=0.2)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out_png, dpi=140)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# CLI\n",
        "# ----------------------------\n",
        "\n",
        "def build_parser() -> argparse.ArgumentParser:\n",
        "    p = argparse.ArgumentParser(description=\"MetaIntelligence end-to-end toolkit (notebook/Colab-safe)\")\n",
        "    sub = p.add_subparsers(dest=\"cmd\")\n",
        "\n",
        "    # Train\n",
        "    t = sub.add_parser(\"train\", help=\"Train a model (self/supervised/hybrid)\")\n",
        "    t.add_argument(\"--mode\", choices=[\"self\", \"supervised\", \"hybrid\"], default=\"supervised\")\n",
        "    t.add_argument(\"--steps\", type=int, default=500)\n",
        "    t.add_argument(\"--batch-size\", type=int, default=128)\n",
        "    t.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    t.add_argument(\"--wd\", type=float, default=0.0)\n",
        "    t.add_argument(\"--entropy-bonus\", type=float, default=0.0)\n",
        "    t.add_argument(\"--label-sharpen\", type=float, default=0.0)\n",
        "    t.add_argument(\"--seed\", type=int, default=42)\n",
        "    t.add_argument(\"--outdir\", type=str, default=\"runs\")\n",
        "    t.add_argument(\"--log-every\", type=int, default=50)\n",
        "    t.add_argument(\"--dim\", type=int, default=2)\n",
        "    t.add_argument(\"--n-classes\", type=int, default=2)\n",
        "    t.add_argument(\"--train-size\", type=int, default=8192)\n",
        "    t.add_argument(\"--val-ratio\", type=float, default=0.15)\n",
        "    t.add_argument(\"--test-ratio\", type=float, default=0.15)\n",
        "    t.add_argument(\"--device\", type=str, default=\"auto\", choices=[\"auto\", \"cpu\", \"cuda\"])\n",
        "\n",
        "    # Eval\n",
        "    e = sub.add_parser(\"eval\", help=\"Evaluate a saved checkpoint on a fresh synthetic test set\")\n",
        "    e.add_argument(\"--ckpt\", type=str, required=True, help=\"Path to model.pt\")\n",
        "\n",
        "    # Predict\n",
        "    p2 = sub.add_parser(\"predict\", help=\"Predict for given points\")\n",
        "    p2.add_argument(\"--ckpt\", type=str, required=True, help=\"Path to model.pt\")\n",
        "    p2.add_argument(\"--points-csv\", type=str, default=None, help=\"CSV file without header, each row is a point\")\n",
        "    p2.add_argument(\"--points-inline\", type=str, default=None,\n",
        "                    help='Inline points, e.g., \"x1,x2; y1,y2\" (must match input dim)')\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "def main(argv: Optional[List[str]] = None) -> None:\n",
        "    argv = sanitize_argv(argv)\n",
        "    parser = build_parser()\n",
        "    if not argv:\n",
        "        parser.print_help()\n",
        "        return\n",
        "    args, _ = parser.parse_known_args(argv)\n",
        "\n",
        "    if args.cmd == \"train\":\n",
        "        cfg = TrainConfig(\n",
        "            mode=args.mode,\n",
        "            steps=args.steps,\n",
        "            batch_size=args.batch_size,\n",
        "            lr=args.lr,\n",
        "            wd=args.wd,\n",
        "            entropy_bonus=args.entropy_bonus,\n",
        "            label_sharpen=args.label_sharpen,\n",
        "            seed=args.seed,\n",
        "            outdir=args.outdir,\n",
        "            log_every=args.log_every,\n",
        "            dim=args.dim,\n",
        "            n_classes=args.n_classes,\n",
        "            train_size=args.train_size,\n",
        "            val_ratio=args.val_ratio,\n",
        "            test_ratio=args.test_ratio,\n",
        "            device=args.device,\n",
        "        )\n",
        "        train_run(cfg)\n",
        "    elif args.cmd == \"eval\":\n",
        "        eval_run(args.ckpt)\n",
        "    elif args.cmd == \"predict\":\n",
        "        predict_run(args.ckpt, args.points_csv, args.points_inline)\n",
        "    else:\n",
        "        parser.print_help()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except SystemExit:\n",
        "        # Friendlier in notebooks\n",
        "        print(\"Use 'exit', 'quit', or Ctrl-D to exit.\", file=sys.stderr)\n",
        "        raise"
      ]
    }
  ]
}
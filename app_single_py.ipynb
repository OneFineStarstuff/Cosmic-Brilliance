{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOs5MTbpQZtANQ/uonpUgPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/app_single_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn2vfvUfBNzY"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# app_single.py\n",
        "# A complete end-to-end single-file platform: FastAPI backend, OAuth, dashboard UI,\n",
        "# multimodal AI suite with demo fallbacks, blob storage, Γ-universe simulation, metrics,\n",
        "# and a typed client. Designed for local-first operation and production hardening.\n",
        "\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "import time\n",
        "import base64\n",
        "import hashlib\n",
        "import secrets\n",
        "import logging\n",
        "import datetime as dt\n",
        "from typing import List, Optional, Dict, Any, Tuple\n",
        "from urllib.parse import urlencode\n",
        "\n",
        "from fastapi import FastAPI, Depends, File, UploadFile, Form, HTTPException, status, Request, Response, Body, Query\n",
        "from fastapi.responses import HTMLResponse, JSONResponse, RedirectResponse, PlainTextResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from pydantic import BaseModel, BaseSettings, Field, AnyUrl\n",
        "from starlette.middleware.sessions import SessionMiddleware\n",
        "from starlette.background import BackgroundTasks\n",
        "\n",
        "# Optional heavy deps are imported lazily in production paths\n",
        "# NLP: transformers; Vision: ultralytics; Speech: whisper\n",
        "import httpx\n",
        "from itsdangerous import URLSafeSerializer\n",
        "\n",
        "try:\n",
        "    from rich.logging import RichHandler\n",
        "    RICH = True\n",
        "except Exception:\n",
        "    RICH = False\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "    from PIL import Image\n",
        "except Exception:\n",
        "    np = None\n",
        "    Image = None\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Settings and configuration\n",
        "# ---------------------------\n",
        "\n",
        "class Settings(BaseSettings):\n",
        "    DEMO_MODE: bool = Field(default=True)\n",
        "    SECRET_KEY: str = Field(default=\"change-me\")\n",
        "    SESSION_COOKIE_NAME: str = Field(default=\"session\")\n",
        "    FASTAPI_BASE_URL: str = Field(default=\"http://127.0.0.1:8000\")\n",
        "    BLOB_DIR: str = Field(default=\"./blobs\")\n",
        "    MAX_UPLOAD_MB: int = Field(default=50)\n",
        "\n",
        "    # OAuth\n",
        "    OAUTH_REDIRECT_BASE: Optional[str] = None  # e.g., http://127.0.0.1:8000\n",
        "    GOOGLE_CLIENT_ID: Optional[str] = None\n",
        "    GOOGLE_CLIENT_SECRET: Optional[str] = None\n",
        "    GITHUB_CLIENT_ID: Optional[str] = None\n",
        "    GITHUB_CLIENT_SECRET: Optional[str] = None\n",
        "    MS_CLIENT_ID: Optional[str] = None\n",
        "    MS_CLIENT_SECRET: Optional[str] = None\n",
        "\n",
        "    # Models\n",
        "    NLP_MODEL: str = Field(default=\"google/flan-t5-base\")\n",
        "    YOLO_MODEL: str = Field(default=\"yolov8n.pt\")\n",
        "    WHISPER_MODEL: str = Field(default=\"base\")\n",
        "\n",
        "    class Config:\n",
        "        env_file = \".env\"\n",
        "        case_sensitive = False\n",
        "\n",
        "settings = Settings()\n",
        "\n",
        "# ---------------------------\n",
        "# Logging\n",
        "# ---------------------------\n",
        "\n",
        "LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"INFO\").upper()\n",
        "logging.basicConfig(\n",
        "    level=getattr(logging, LOG_LEVEL, logging.INFO),\n",
        "    format=\"%(asctime)s %(levelname)s %(name)s - %(message)s\",\n",
        "    handlers=[RichHandler(markup=True)] if RICH else None,\n",
        ")\n",
        "log = logging.getLogger(\"platform\")\n",
        "\n",
        "# ---------------------------\n",
        "# App init\n",
        "# ---------------------------\n",
        "\n",
        "app = FastAPI(title=\"Multimodal AI + Γ-Universe Platform\", version=\"1.0.0\")\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"], allow_credentials=True,\n",
        "    allow_methods=[\"*\"], allow_headers=[\"*\"],\n",
        ")\n",
        "app.add_middleware(SessionMiddleware, secret_key=settings.SECRET_KEY, session_cookie=settings.SESSION_COOKIE_NAME)\n",
        "\n",
        "# Templates in-memory (single-file). We'll mount a dyn loader.\n",
        "templates = Jinja2Templates(directory=\".\")\n",
        "\n",
        "# Ensure blob dir\n",
        "os.makedirs(settings.BLOB_DIR, exist_ok=True)\n",
        "\n",
        "# URL signer for blob download tokens\n",
        "signer = URLSafeSerializer(settings.SECRET_KEY, salt=\"blob-url\")\n",
        "\n",
        "# ---------------------------\n",
        "# In-memory stores\n",
        "# ---------------------------\n",
        "\n",
        "ACTIVITY: List[Dict[str, Any]] = []\n",
        "METRICS: Dict[str, Any] = {\n",
        "    \"start_time\": time.time(),\n",
        "    \"requests_total\": 0,\n",
        "    \"errors_total\": 0,\n",
        "    \"nlp_calls\": 0,\n",
        "    \"vision_calls\": 0,\n",
        "    \"speech_calls\": 0,\n",
        "    \"blob_uploads\": 0,\n",
        "    \"sim_runs\": 0,\n",
        "}\n",
        "\n",
        "def record(event: str, detail: Dict[str, Any] = None, user: Optional[str] = None):\n",
        "    entry = {\n",
        "        \"ts\": dt.datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"event\": event,\n",
        "        \"detail\": detail or {},\n",
        "        \"user\": user,\n",
        "        \"demo\": settings.DEMO_MODE,\n",
        "    }\n",
        "    ACTIVITY.append(entry)\n",
        "    if len(ACTIVITY) > 1000:\n",
        "        del ACTIVITY[:200]\n",
        "    log.info(f\"{event}: {detail}\")\n",
        "\n",
        "# ---------------------------\n",
        "# OAuth setup\n",
        "# ---------------------------\n",
        "\n",
        "# Minimal OAuth via manual endpoints to avoid extra deps\n",
        "OAUTH_PROVIDERS = {\n",
        "    \"google\": {\n",
        "        \"auth_url\": \"https://accounts.google.com/o/oauth2/v2/auth\",\n",
        "        \"token_url\": \"https://oauth2.googleapis.com/token\",\n",
        "        \"userinfo_url\": \"https://openidconnect.googleapis.com/v1/userinfo\",\n",
        "        \"scope\": \"openid email profile\",\n",
        "        \"client_id\": settings.GOOGLE_CLIENT_ID,\n",
        "        \"client_secret\": settings.GOOGLE_CLIENT_SECRET,\n",
        "    },\n",
        "    \"github\": {\n",
        "        \"auth_url\": \"https://github.com/login/oauth/authorize\",\n",
        "        \"token_url\": \"https://github.com/login/oauth/access_token\",\n",
        "        \"userinfo_url\": \"https://api.github.com/user\",\n",
        "        \"scope\": \"read:user user:email\",\n",
        "        \"client_id\": settings.GITHUB_CLIENT_ID,\n",
        "        \"client_secret\": settings.GITHUB_CLIENT_SECRET,\n",
        "    },\n",
        "    \"microsoft\": {\n",
        "        \"auth_url\": \"https://login.microsoftonline.com/common/oauth2/v2.0/authorize\",\n",
        "        \"token_url\": \"https://login.microsoftonline.com/common/oauth2/v2.0/token\",\n",
        "        \"userinfo_url\": \"https://graph.microsoft.com/oidc/userinfo\",\n",
        "        \"scope\": \"openid email profile\",\n",
        "        \"client_id\": settings.MS_CLIENT_ID,\n",
        "        \"client_secret\": settings.MS_CLIENT_SECRET,\n",
        "    },\n",
        "}\n",
        "\n",
        "def oauth_enabled(provider: str) -> bool:\n",
        "    cfg = OAUTH_PROVIDERS.get(provider)\n",
        "    return bool(cfg and cfg[\"client_id\"] and cfg[\"client_secret\"] and settings.OAUTH_REDIRECT_BASE)\n",
        "\n",
        "def get_user(request: Request) -> Optional[Dict[str, Any]]:\n",
        "    return request.session.get(\"user\")\n",
        "\n",
        "def require_user(request: Request) -> Dict[str, Any]:\n",
        "    user = get_user(request)\n",
        "    if not user:\n",
        "        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n",
        "    return user\n",
        "\n",
        "# ---------------------------\n",
        "# Utilities\n",
        "# ---------------------------\n",
        "\n",
        "def file_size_ok(upload: UploadFile):\n",
        "    # Not perfect for streams; for demo we allow check via header if present\n",
        "    return True\n",
        "\n",
        "def now_iso():\n",
        "    return dt.datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def b64png(image_bytes: bytes) -> str:\n",
        "    return \"data:image/png;base64,\" + base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "\n",
        "def safe_int(v, d=0):\n",
        "    try:\n",
        "        return int(v)\n",
        "    except Exception:\n",
        "        return d\n",
        "\n",
        "# ---------------------------\n",
        "# Models and schemas\n",
        "# ---------------------------\n",
        "\n",
        "class Health(BaseModel):\n",
        "    status: str\n",
        "    uptime_seconds: float\n",
        "    demo_mode: bool\n",
        "    version: str\n",
        "\n",
        "class NLPRequest(BaseModel):\n",
        "    task: str = Field(description=\"summarize|translate|classify|generate\")\n",
        "    input_text: str\n",
        "\n",
        "class NLPResponse(BaseModel):\n",
        "    task: str\n",
        "    output_text: str\n",
        "    model: str\n",
        "    demo: bool\n",
        "    latency_ms: int\n",
        "\n",
        "class VisionResponse(BaseModel):\n",
        "    detections: List[Dict[str, Any]]\n",
        "    model: str\n",
        "    demo: bool\n",
        "    latency_ms: int\n",
        "\n",
        "class SpeechResponse(BaseModel):\n",
        "    text: str\n",
        "    model: str\n",
        "    demo: bool\n",
        "    latency_ms: int\n",
        "\n",
        "class BlobUploadResponse(BaseModel):\n",
        "    name: str\n",
        "    size: int\n",
        "    url: str\n",
        "    demo: bool\n",
        "\n",
        "class SimRequest(BaseModel):\n",
        "    seed: Dict[str, Any]\n",
        "    steps: int = 10\n",
        "    novelty_limit: float = 0.3\n",
        "    coherence_floor: float = 0.5\n",
        "    snapshot_every: int = 5\n",
        "\n",
        "class SimSnapshot(BaseModel):\n",
        "    step: int\n",
        "    state: Dict[str, Any]\n",
        "    provenance: List[Dict[str, Any]]\n",
        "    metrics: Dict[str, float]\n",
        "\n",
        "class SimResponse(BaseModel):\n",
        "    final_state: Dict[str, Any]\n",
        "    snapshots: List[SimSnapshot]\n",
        "    laws_applied: List[str]\n",
        "    demo: bool\n",
        "    latency_ms: int\n",
        "\n",
        "# ---------------------------\n",
        "# Lazy-loaded model handles\n",
        "# ---------------------------\n",
        "\n",
        "class ModelHub:\n",
        "    nlp_pipe = None\n",
        "    yolo = None\n",
        "    whisper = None\n",
        "\n",
        "HUB = ModelHub()\n",
        "\n",
        "def load_nlp():\n",
        "    if HUB.nlp_pipe is not None:\n",
        "        return HUB.nlp_pipe\n",
        "    from transformers import pipeline\n",
        "    HUB.nlp_pipe = {\n",
        "        \"summarize\": pipeline(\"summarization\", model=settings.NLP_MODEL),\n",
        "        \"generate\": pipeline(\"text2text-generation\", model=settings.NLP_MODEL),\n",
        "        \"translate\": pipeline(\"translation_en_to_de\", model=\"t5-small\"),\n",
        "        \"classify\": pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\"),\n",
        "    }\n",
        "    return HUB.nlp_pipe\n",
        "\n",
        "def load_yolo():\n",
        "    if HUB.yolo is not None:\n",
        "        return HUB.yolo\n",
        "    from ultralytics import YOLO\n",
        "    HUB.yolo = YOLO(settings.YOLO_MODEL)\n",
        "    return HUB.yolo\n",
        "\n",
        "def load_whisper():\n",
        "    if HUB.whisper is not None:\n",
        "        return HUB.whisper\n",
        "    import whisper\n",
        "    HUB.whisper = whisper.load_model(settings.WHISPER_MODEL)\n",
        "    return HUB.whisper\n",
        "\n",
        "# ---------------------------\n",
        "# Demo implementations\n",
        "# ---------------------------\n",
        "\n",
        "def demo_summarize(text: str) -> str:\n",
        "    words = text.split()\n",
        "    if len(words) <= 30:\n",
        "        return text\n",
        "    return \" \".join(words[:25]) + \" ...\"\n",
        "\n",
        "def demo_generate(text: str) -> str:\n",
        "    return f\"{text.strip()} — and therefore, the system evolves.\"\n",
        "\n",
        "def demo_translate_en_de(text: str) -> str:\n",
        "    # naive fake\n",
        "    return f\"[DEMO-DE] {text}\"\n",
        "\n",
        "def demo_classify(text: str) -> str:\n",
        "    return \"POSITIVE\" if any(w in text.lower() for w in [\"good\", \"great\", \"love\", \"excellent\"]) else \"NEUTRAL\"\n",
        "\n",
        "def demo_yolo(img: Image.Image) -> List[Dict[str, Any]]:\n",
        "    # Simple color-block heuristic\n",
        "    arr = np.array(img.resize((64, 64)))\n",
        "    mean = arr.mean(axis=(0,1)).tolist()\n",
        "    return [{\"label\": \"scene\", \"confidence\": 0.42, \"box\": [0,0,img.width,img.height], \"mean_rgb\": mean}]\n",
        "\n",
        "def demo_whisper_dummy() -> str:\n",
        "    return \"Transcription unavailable in demo. This is a placeholder.\"\n",
        "\n",
        "# ---------------------------\n",
        "# Γ-universe simulation engine\n",
        "# ---------------------------\n",
        "\n",
        "# Laws Λ1–Λ9 are expressed as functions over state and provenance.\n",
        "# We keep a compact but expressive model.\n",
        "\n",
        "def coherence_score(state: Dict[str, Any]) -> float:\n",
        "    # Heuristic: fewer contradictions and tighter value ranges -> higher score\n",
        "    contradictions = len(state.get(\"_contradictions\", []))\n",
        "    spread = 0.0\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, (int, float)):\n",
        "            spread += abs(float(v))\n",
        "    base = 1.0 / (1.0 + contradictions + 0.01 * spread)\n",
        "    return min(1.0, base)\n",
        "\n",
        "def novelty_distance(prev: Dict[str, Any], nxt: Dict[str, Any]) -> float:\n",
        "    keys = set(prev.keys()) | set(nxt.keys())\n",
        "    dist = 0.0\n",
        "    for k in keys:\n",
        "        a = prev.get(k)\n",
        "        b = nxt.get(k)\n",
        "        if a == b:\n",
        "            continue\n",
        "        if isinstance(a, (int,float)) and isinstance(b, (int,float)):\n",
        "            dist += min(1.0, abs(float(a)-float(b))/ (abs(float(a))+1e-6 + abs(float(b))+1e-6))\n",
        "        else:\n",
        "            dist += 0.5\n",
        "    return min(1.0, dist / max(1, len(keys)))\n",
        "\n",
        "def dialectic(a, b):\n",
        "    # Simple synthesis: prefer specific over general, numbers averaged, text concatenated\n",
        "    if isinstance(a, (int,float)) and isinstance(b, (int,float)):\n",
        "        return (a + b) / 2.0\n",
        "    if isinstance(a, str) and isinstance(b, str):\n",
        "        if a in b:\n",
        "            return b\n",
        "        if b in a:\n",
        "            return a\n",
        "        return f\"{a} | {b}\"\n",
        "    if isinstance(a, list) and isinstance(b, list):\n",
        "        return list({json.dumps(x, sort_keys=True) for x in (a+b)})\n",
        "    if isinstance(a, dict) and isinstance(b, dict):\n",
        "        out = dict(a)\n",
        "        for k, v in b.items():\n",
        "            out[k] = dialectic(out.get(k), v) if k in out else v\n",
        "        return out\n",
        "    return b if b is not None else a\n",
        "\n",
        "def apply_laws(state: Dict[str, Any], step: int, prov: List[Dict[str, Any]],\n",
        "               novelty_limit: float, coherence_floor: float) -> Tuple[Dict[str, Any], List[str], Dict[str, float]]:\n",
        "    applied = []\n",
        "    s_prev = json.loads(json.dumps(state))  # deep copy\n",
        "\n",
        "    # Λ1 Identity persistence: copy forward baseline\n",
        "    s_next = {k: v for k, v in state.items() if not k.startswith(\"_\")}\n",
        "    applied.append(\"Λ1\")\n",
        "\n",
        "    # Λ2 Locality: propose local evolutions\n",
        "    proposals = {}\n",
        "    for k, v in s_next.items():\n",
        "        if isinstance(v, (int, float)):\n",
        "            proposals[k] = v + (0.1 if step % 2 == 0 else -0.08)\n",
        "        elif isinstance(v, str) and len(v) < 120:\n",
        "            proposals[k] = v if step % 3 else v + \"·\"\n",
        "        else:\n",
        "            proposals[k] = v\n",
        "    applied.append(\"Λ2\")\n",
        "\n",
        "    # Λ3 Provenance conservation\n",
        "    prov.append({\"step\": step, \"from\": s_prev, \"proposal\": proposals, \"at\": now_iso()})\n",
        "    s_prop = proposals\n",
        "    applied.append(\"Λ3\")\n",
        "\n",
        "    # Λ4 Dialectic synthesis for conflicts\n",
        "    s_syn = {}\n",
        "    for k in set(s_next.keys()) | set(s_prop.keys()):\n",
        "        if k in s_next and k in s_prop:\n",
        "            s_syn[k] = dialectic(s_next[k], s_prop[k])\n",
        "        else:\n",
        "            s_syn[k] = s_next.get(k, s_prop.get(k))\n",
        "    applied.append(\"Λ4\")\n",
        "\n",
        "    # Λ5 Novelty constraint\n",
        "    nov = novelty_distance(s_prev, s_syn)\n",
        "    if nov > novelty_limit:\n",
        "        # damp changes\n",
        "        for k, v in s_syn.items():\n",
        "            if isinstance(v, (int,float)) and isinstance(s_prev.get(k), (int,float)):\n",
        "                s_syn[k] = (s_prev[k] + v) / 2.0\n",
        "        applied.append(\"Λ5-clamped\")\n",
        "    else:\n",
        "        applied.append(\"Λ5-ok\")\n",
        "\n",
        "    # Λ6 Coherence check\n",
        "    coh = coherence_score(s_syn)\n",
        "    if coh < coherence_floor:\n",
        "        # revert risky keys\n",
        "        for k in list(s_syn.keys()):\n",
        "            s_syn[k] = s_prev.get(k, s_syn[k])\n",
        "        applied.append(\"Λ6-revert\")\n",
        "    else:\n",
        "        applied.append(\"Λ6-ok\")\n",
        "\n",
        "    # Λ7 Contradiction handling\n",
        "    contradictions = []\n",
        "    for k, v in s_syn.items():\n",
        "        if isinstance(v, (int, float)) and abs(float(v)) > 1e6:\n",
        "            contradictions.append({\"k\": k, \"v\": v, \"reason\": \"magnitude\"})\n",
        "    if contradictions:\n",
        "        s_syn[\"_contradictions\"] = s_syn.get(\"_contradictions\", []) + contradictions\n",
        "    applied.append(\"Λ7\")\n",
        "\n",
        "    # Λ8 Echo archive flagging handled by caller via snapshots\n",
        "    applied.append(\"Λ8\")\n",
        "\n",
        "    # Λ9 Law-of-laws tuning marker (no-ops here, but record meta)\n",
        "    metrics = {\"novelty\": nov, \"coherence\": coherence_score(s_syn)}\n",
        "    applied.append(\"Λ9\")\n",
        "\n",
        "    return s_syn, applied, metrics\n",
        "\n",
        "def run_simulation(req: SimRequest) -> Tuple[Dict[str, Any], List[SimSnapshot], List[str]]:\n",
        "    start = time.time()\n",
        "    state = dict(req.seed)\n",
        "    provenance: List[Dict[str, Any]] = []\n",
        "    snapshots: List[SimSnapshot] = []\n",
        "    laws_union: List[str] = []\n",
        "    for step in range(1, req.steps + 1):\n",
        "        state, laws, metrics = apply_laws(state, step, provenance,\n",
        "                                          novelty_limit=req.novelty_limit,\n",
        "                                          coherence_floor=req.coherence_floor)\n",
        "        laws_union.extend(laws)\n",
        "        if step % max(1, req.snapshot_every) == 0 or step == req.steps:\n",
        "            snapshots.append(SimSnapshot(step=step, state=state, provenance=list(provenance), metrics=metrics))\n",
        "    METRICS[\"sim_runs\"] += 1\n",
        "    record(\"sim.run\", {\"steps\": req.steps, \"laws\": list(dict.fromkeys(laws_union))})\n",
        "    latency = int((time.time() - start) * 1000)\n",
        "    return state, snapshots, list(dict.fromkeys(laws_union))\n",
        "\n",
        "# ---------------------------\n",
        "# Middlewares and hooks\n",
        "# ---------------------------\n",
        "\n",
        "@app.middleware(\"http\")\n",
        "async def metrics_mw(request: Request, call_next):\n",
        "    METRICS[\"requests_total\"] += 1\n",
        "    try:\n",
        "        response = await call_next(request)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        METRICS[\"errors_total\"] += 1\n",
        "        log.exception(\"Unhandled error\")\n",
        "        return JSONResponse({\"error\": str(e)}, status_code=500)\n",
        "\n",
        "# ---------------------------\n",
        "# HTML dashboard template\n",
        "# ---------------------------\n",
        "\n",
        "DASHBOARD_HTML = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"utf-8\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
        "<title>Multimodal AI + Γ-Universe</title>\n",
        "<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" />\n",
        "<link href=\"https://fonts.googleapis.com/css2?family=Montserrat:wght@600;700&family=Open+Sans:wght@400;600&display=swap\" rel=\"stylesheet\" />\n",
        "<style>\n",
        "  :root {\n",
        "    --bg1: #0f1020; --bg2: #141834;\n",
        "    --fg: #eaeaf2; --muted: #aab; --accent: #7c4dff; --accent2: #24c8db;\n",
        "  }\n",
        "  * { box-sizing: border-box; }\n",
        "  body {\n",
        "    margin: 0; font-family: \"Open Sans\", system-ui, -apple-system, Segoe UI, Roboto, sans-serif;\n",
        "    color: var(--fg); background: linear-gradient(135deg, var(--bg1), var(--bg2));\n",
        "  }\n",
        "  header {\n",
        "    padding: 24px; display: flex; align-items: baseline; justify-content: space-between;\n",
        "  }\n",
        "  .brand { font-family: \"Montserrat\"; font-weight: 700; font-size: 20px; letter-spacing: 0.5px; }\n",
        "  .grid {\n",
        "    display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 16px; padding: 16px; max-width: 1200px; margin: 0 auto;\n",
        "  }\n",
        "  .card {\n",
        "    background: rgba(255,255,255,0.05); border: 1px solid rgba(255,255,255,0.08);\n",
        "    border-radius: 12px; padding: 16px; backdrop-filter: blur(4px);\n",
        "  }\n",
        "  .chip { display: inline-block; padding: 4px 8px; border-radius: 999px; font-size: 12px; border: 1px solid rgba(255,255,255,0.2); margin-right: 6px;}\n",
        "  button, .btn {\n",
        "    background: linear-gradient(90deg, var(--accent), var(--accent2)); color: #fff; border: none; padding: 10px 14px; border-radius: 8px; font-weight: 600; cursor: pointer;\n",
        "  }\n",
        "  input, textarea, select {\n",
        "    width: 100%; padding: 10px; border-radius: 8px; background: rgba(255,255,255,0.06); color: var(--fg); border: 1px solid rgba(255,255,255,0.12); outline: none;\n",
        "  }\n",
        "  .muted { color: var(--muted); font-size: 12px; }\n",
        "  .row { display: flex; gap: 10px; align-items: center; flex-wrap: wrap; }\n",
        "  .title { font-family: \"Montserrat\"; font-weight: 700; font-size: 16px; margin-bottom: 8px; }\n",
        "  .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace; }\n",
        "  .kv { display: grid; grid-template-columns: auto 1fr; gap: 6px 12px; font-size: 13px; }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "<header>\n",
        "  <div class=\"brand\">Multimodal AI + Γ-Universe</div>\n",
        "  <div>\n",
        "    <a class=\"chip\" href=\"/auth/google\" title=\"Google\">Google</a>\n",
        "    <a class=\"chip\" href=\"/auth/github\" title=\"GitHub\">GitHub</a>\n",
        "    <a class=\"chip\" href=\"/auth/microsoft\" title=\"Microsoft\">Microsoft</a>\n",
        "    <a class=\"chip\" href=\"/logout\">Logout</a>\n",
        "  </div>\n",
        "</header>\n",
        "\n",
        "<div class=\"grid\">\n",
        "  <div class=\"card\">\n",
        "    <div class=\"title\">System status</div>\n",
        "    <div class=\"kv\" id=\"status\"></div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"card\">\n",
        "    <div class=\"title\">Activity</div>\n",
        "    <div id=\"activity\" class=\"mono\" style=\"font-size:12px; max-height: 220px; overflow:auto;\"></div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"card\">\n",
        "    <div class=\"title\">NLP playground</div>\n",
        "    <div class=\"row\">\n",
        "      <select id=\"nlpTask\">\n",
        "        <option value=\"summarize\">summarize</option>\n",
        "        <option value=\"generate\">generate</option>\n",
        "        <option value=\"translate\">translate</option>\n",
        "        <option value=\"classify\">classify</option>\n",
        "      </select>\n",
        "      <button onclick=\"runNLP()\">Run</button>\n",
        "    </div>\n",
        "    <textarea id=\"nlpInput\" rows=\"5\" placeholder=\"Enter text...\"></textarea>\n",
        "    <div class=\"muted\">Output</div>\n",
        "    <pre class=\"mono\" id=\"nlpOut\" style=\"white-space:pre-wrap;\"></pre>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"card\">\n",
        "    <div class=\"title\">Vision detection</div>\n",
        "    <input id=\"visionFile\" type=\"file\" accept=\"image/*\" />\n",
        "    <div class=\"row\"><button onclick=\"runVision()\">Detect</button></div>\n",
        "    <pre class=\"mono\" id=\"visionOut\" style=\"white-space:pre-wrap;\"></pre>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"card\">\n",
        "    <div class=\"title\">Speech transcription</div>\n",
        "    <input id=\"speechFile\" type=\"file\" accept=\"audio/*\" />\n",
        "    <div class=\"row\"><button onclick=\"runSpeech()\">Transcribe</button></div>\n",
        "    <pre class=\"mono\" id=\"speechOut\" style=\"white-space:pre-wrap;\"></pre>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"card\">\n",
        "    <div class=\"title\">Γ-universe simulation</div>\n",
        "    <textarea id=\"seed\" rows=\"5\" class=\"mono\">{ \"energy\": 1.0, \"mode\": \"proto\", \"memo\": \"seed\" }</textarea>\n",
        "    <div class=\"row\">\n",
        "      <input id=\"steps\" type=\"number\" value=\"10\" />\n",
        "      <input id=\"novelty\" type=\"number\" step=\"0.05\" value=\"0.3\" />\n",
        "      <input id=\"coherence\" type=\"number\" step=\"0.05\" value=\"0.5\" />\n",
        "      <button onclick=\"runSim()\">Simulate</button>    </div>\n",
        "    <pre class=\"mono\" id=\"simOut\" style=\"white-space:pre-wrap; max-height:200px; overflow:auto;\"></pre>\n",
        "  </div>\n",
        "</div>\n",
        "\n",
        "<script>\n",
        "async function fetchJSON(url) {\n",
        "  const res = await fetch(url);\n",
        "  return await res.json();\n",
        "}\n",
        "function kv(el, data) {\n",
        "  el.innerHTML = Object.entries(data).map(([k,v]) => <div class=\"muted\">${k}</div><div>${typeof v===\"number\"? v.toFixed? v.toFixed(2):v : v}</div>).join(\"\");\n",
        "}\n",
        "async function refresh() {\n",
        "  const h = await fetchJSON(\"/health\");\n",
        "  kv(document.getElementById(\"status\"), h);\n",
        "  const acts = await fetchJSON(\"/api/activity\");\n",
        "  document.getElementById(\"activity\").innerText = acts.map(a => ${a.ts}  ${a.event}  ${JSON.stringify(a.detail)}).reverse().slice(0,50).join(\"\\\\n\");\n",
        "}\n",
        "setInterval(refresh, 1500); refresh();\n",
        "\n",
        "async function runNLP() {\n",
        "  const input_text = document.getElementById(\"nlpInput\").value;\n",
        "  const task = document.getElementById(\"nlpTask\").value;\n",
        "  const res = await fetch(\"/api/nlp\", { method: \"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify({task, input_text})});\n",
        "  document.getElementById(\"nlpOut\").innerText = JSON.stringify(await res.json(), null, 2);\n",
        "}\n",
        "\n",
        "async function runVision() {\n",
        "  const file = document.getElementById(\"visionFile\").files[0];\n",
        "  if (!file) return alert(\"Choose an image\");\n",
        "  const fd = new FormData();\n",
        "  fd.append(\"image\", file);\n",
        "  const res = await fetch(\"/api/vision\", {method:\"POST\", body: fd});\n",
        "  document.getElementById(\"visionOut\").innerText = JSON.stringify(await res.json(), null, 2);\n",
        "}\n",
        "\n",
        "async function runSpeech() {\n",
        "  const file = document.getElementById(\"speechFile\").files[0];\n",
        "  if (!file) return alert(\"Choose audio\");\n",
        "  const fd = new FormData();\n",
        "  fd.append(\"audio\", file);\n",
        "  const res = await fetch(\"/api/speech\", {method:\"POST\", body: fd});\n",
        "  document.getElementById(\"speechOut\").innerText = JSON.stringify(await res.json(), null, 2);\n",
        "}\n",
        "\n",
        "async function runSim() {\n",
        "  let seed;\n",
        "  try { seed = JSON.parse(document.getElementById(\"seed\").value); } catch(e) { return alert(\"Invalid seed JSON\"); }\n",
        "  const steps = parseInt(document.getElementById(\"steps\").value, 10);\n",
        "  const novelty = parseFloat(document.getElementById(\"novelty\").value);\n",
        "  const coherence = parseFloat(document.getElementById(\"coherence\").value);\n",
        "  const res = await fetch(\"/api/simulate\", { method:\"POST\", headers: {\"Content-Type\":\"application/json\"}, body: JSON.stringify({seed, steps, noveltylimit:novelty, coherencefloor:coherence, snapshot_every: Math.max(1, Math.floor(steps/2))}) });\n",
        "  document.getElementById(\"simOut\").innerText = JSON.stringify(await res.json(), null, 2);\n",
        "}\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# ---------------------------\n",
        "# Routes\n",
        "# ---------------------------\n",
        "\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def dashboard(request: Request):\n",
        "    return HTMLResponse(DASHBOARD_HTML)\n",
        "\n",
        "@app.get(\"/health\", response_model=Health)\n",
        "async def health():\n",
        "    uptime = time.time() - METRICS[\"start_time\"]\n",
        "    return Health(status=\"ok\", uptimeseconds=uptime, demomode=settings.DEMO_MODE, version=\"1.0.0\")\n",
        "\n",
        "@app.get(\"/api/activity\")\n",
        "async def activity():\n",
        "    return ACTIVITY[-200:]\n",
        "\n",
        "OAuth routes\n",
        "\n",
        "@app.get(\"/auth/{provider}\")\n",
        "async def oauth_start(provider: str, request: Request):\n",
        "    if provider not in OAUTH_PROVIDERS:\n",
        "        raise HTTPException(404, \"Unknown provider\")\n",
        "    if not oauth_enabled(provider):\n",
        "        record(\"auth.demo-login\", {\"provider\": provider})\n",
        "        # Demo mode: create a synthetic user\n",
        "        request.session[\"user\"] = {\"name\": \"Demo User\", \"provider\": provider, \"sub\": f\"demo-{provider}-{secrets.token_hex(4)}\"}\n",
        "        return RedirectResponse(\"/\")\n",
        "    cfg = OAUTH_PROVIDERS[provider]\n",
        "    state = secrets.token_urlsafe(16)\n",
        "    request.session[\"oauth_state\"] = state\n",
        "    redirecturi = f\"{settings.OAUTHREDIRECT_BASE}/auth/{provider}/callback\"\n",
        "    params = {\n",
        "        \"clientid\": cfg[\"clientid\"],\n",
        "        \"redirecturi\": redirecturi,\n",
        "        \"response_type\": \"code\",\n",
        "        \"scope\": cfg[\"scope\"],\n",
        "        \"state\": state,\n",
        "    }\n",
        "    return RedirectResponse(f\"{cfg['auth_url']}?{urlencode(params)}\")\n",
        "\n",
        "@app.get(\"/auth/{provider}/callback\")\n",
        "async def oauth_callback(provider: str, request: Request, code: Optional[str] = None, state: Optional[str] = None):\n",
        "    if provider not in OAUTH_PROVIDERS:\n",
        "        raise HTTPException(404, \"Unknown provider\")\n",
        "    expect = request.session.get(\"oauth_state\")\n",
        "    request.session.pop(\"oauth_state\", None)\n",
        "    if not code or not state or state != expect:\n",
        "        raise HTTPException(400, \"Invalid OAuth state\")\n",
        "    cfg = OAUTH_PROVIDERS[provider]\n",
        "    redirecturi = f\"{settings.OAUTHREDIRECT_BASE}/auth/{provider}/callback\"\n",
        "    data = {\n",
        "        \"clientid\": cfg[\"clientid\"], \"clientsecret\": cfg[\"clientsecret\"],\n",
        "        \"code\": code, \"redirecturi\": redirecturi, \"granttype\": \"authorizationcode\",\n",
        "    }\n",
        "    headers = {\"Accept\": \"application/json\"}\n",
        "    async with httpx.AsyncClient(timeout=30) as client:\n",
        "        tokenres = await client.post(cfg[\"tokenurl\"], data=data, headers=headers)\n",
        "        tokenres.raisefor_status()\n",
        "        token = token_res.json()\n",
        "        accesstoken = token.get(\"accesstoken\")\n",
        "        if not access_token:\n",
        "            raise HTTPException(400, \"No access token\")\n",
        "        uiheaders = {\"Authorization\": f\"Bearer {accesstoken}\"}\n",
        "        userinfores = await client.get(cfg[\"userinfourl\"], headers=ui_headers)\n",
        "        userinfores.raisefor_status()\n",
        "        profile = userinfo_res.json()\n",
        "    # Normalize\n",
        "    user = {\n",
        "        \"provider\": provider,\n",
        "        \"sub\": profile.get(\"sub\") or str(profile.get(\"id\")),\n",
        "        \"name\": profile.get(\"name\") or profile.get(\"login\") or profile.get(\"email\") or \"user\",\n",
        "        \"email\": profile.get(\"email\"),\n",
        "        \"avatar\": profile.get(\"picture\") or profile.get(\"avatar_url\"),\n",
        "    }\n",
        "    request.session[\"user\"] = user\n",
        "    record(\"auth.login\", {\"provider\": provider, \"sub\": user[\"sub\"]}, user=user[\"name\"])\n",
        "    return RedirectResponse(\"/\")\n",
        "\n",
        "@app.get(\"/logout\")\n",
        "async def logout(request: Request):\n",
        "    request.session.pop(\"user\", None)\n",
        "    return RedirectResponse(\"/\")\n",
        "\n",
        "NLP\n",
        "\n",
        "@app.post(\"/api/nlp\", response_model=NLPResponse)\n",
        "async def api_nlp(req: NLPRequest, request: Request):\n",
        "    start = time.time()\n",
        "    METRICS[\"nlp_calls\"] += 1\n",
        "    task = req.task.lower()\n",
        "    text = req.input_text\n",
        "    out = \"\"\n",
        "    model_used = \"demo\"\n",
        "    if not settings.DEMO_MODE:\n",
        "        try:\n",
        "            pipes = load_nlp()\n",
        "            if task == \"summarize\":\n",
        "                out = pipes\"summarize\"[0][\"summarytext\"]\n",
        "                modelused = settings.NLPMODEL\n",
        "            elif task == \"generate\":\n",
        "                out = pipes\"generate\"[0][\"generated_text\"]\n",
        "                modelused = settings.NLPMODEL\n",
        "            elif task == \"translate\":\n",
        "                out = pipes\"translate\"[0][\"translationtext\"]\n",
        "                model_used = \"t5-small en->de\"\n",
        "            elif task == \"classify\":\n",
        "                out = pipes\"classify\"[0][\"label\"]\n",
        "                model_used = \"distilbert-sst2\"\n",
        "            else:\n",
        "                raise HTTPException(400, \"Unknown task\")\n",
        "        except Exception as e:\n",
        "            log.warning(f\"NLP fallback: {e}\")\n",
        "            settings.DEMO_MODE = True  # soft flip to demo on failure\n",
        "    if settings.DEMO_MODE:\n",
        "        if task == \"summarize\":\n",
        "            out = demo_summarize(text)\n",
        "        elif task == \"generate\":\n",
        "            out = demo_generate(text)\n",
        "        elif task == \"translate\":\n",
        "            out = demotranslateen_de(text)\n",
        "        elif task == \"classify\":\n",
        "            out = demo_classify(text)\n",
        "        else:\n",
        "            raise HTTPException(400, \"Unknown task\")\n",
        "    latency = int((time.time() - start) * 1000)\n",
        "    record(\"nlp.run\", {\"task\": task, \"latency_ms\": latency})\n",
        "    return NLPResponse(task=task, outputtext=out, model=modelused, demo=settings.DEMOMODE, latencyms=latency)\n",
        "\n",
        "Vision\n",
        "\n",
        "@app.post(\"/api/vision\", response_model=VisionResponse)\n",
        "async def api_vision(image: UploadFile = File(...)):\n",
        "    start = time.time()\n",
        "    METRICS[\"vision_calls\"] += 1\n",
        "    content = await image.read()\n",
        "    if Image is None or np is None:\n",
        "        raise HTTPException(500, \"Pillow/numpy not installed\")\n",
        "    img = Image.open(io.BytesIO(content)).convert(\"RGB\")\n",
        "    model_used = \"demo\"\n",
        "    detections: List[Dict[str, Any]] = []\n",
        "    if not settings.DEMO_MODE:\n",
        "        try:\n",
        "            yolo = load_yolo()\n",
        "            res = yolo.predict(img, verbose=False)[0]\n",
        "            for b in res.boxes:\n",
        "                xyxy = b.xyxy[0].tolist()\n",
        "                conf = float(b.conf[0])\n",
        "                cls_idx = int(b.cls[0])\n",
        "                label = yolo.names.get(clsidx, str(clsidx))\n",
        "                detections.append({\"label\": label, \"confidence\": conf, \"box\": [float(x) for x in xyxy]})\n",
        "            modelused = settings.YOLOMODEL\n",
        "        except Exception as e:\n",
        "            log.warning(f\"YOLO fallback: {e}\")\n",
        "            settings.DEMO_MODE = True\n",
        "    if settings.DEMO_MODE:\n",
        "        detections = demo_yolo(img)\n",
        "    latency = int((time.time() - start) * 1000)\n",
        "    record(\"vision.run\", {\"latency_ms\": latency, \"count\": len(detections)})\n",
        "    return VisionResponse(detections=detections, model=modelused, demo=settings.DEMOMODE, latency_ms=latency)\n",
        "\n",
        "Speech\n",
        "\n",
        "@app.post(\"/api/speech\", response_model=SpeechResponse)\n",
        "async def api_speech(audio: UploadFile = File(...)):\n",
        "    start = time.time()\n",
        "    METRICS[\"speech_calls\"] += 1\n",
        "    content = await audio.read()\n",
        "    model_used = \"demo\"\n",
        "    text = \"\"\n",
        "    if not settings.DEMO_MODE:\n",
        "        try:\n",
        "            whisper = load_whisper()\n",
        "            # Write to tmp buffer for whisper\n",
        "            tmppath = os.path.join(settings.BLOBDIR, f\"tmp-{secrets.token_hex(8)}.wav\")\n",
        "            with open(tmp_path, \"wb\") as f:\n",
        "                f.write(content)\n",
        "            result = whisper.transcribe(tmp_path)\n",
        "            os.remove(tmp_path)\n",
        "            text = result.get(\"text\", \"\")\n",
        "            modelused = settings.WHISPERMODEL\n",
        "        except Exception as e:\n",
        "            log.warning(f\"Whisper fallback: {e}\")\n",
        "            settings.DEMO_MODE = True\n",
        "    if settings.DEMO_MODE:\n",
        "        text = demowhisperdummy()\n",
        "    latency = int((time.time() - start) * 1000)\n",
        "    record(\"speech.run\", {\"latency_ms\": latency})\n",
        "    return SpeechResponse(text=text, model=modelused, demo=settings.DEMOMODE, latency_ms=latency)\n",
        "\n",
        "Blob storage\n",
        "\n",
        "@app.post(\"/api/blob/upload\", response_model=BlobUploadResponse)\n",
        "async def blob_upload(file: UploadFile = File(...)):\n",
        "    if not filesizeok(file):\n",
        "        raise HTTPException(413, \"File too large\")\n",
        "    data = await file.read()\n",
        "    name = f\"{int(time.time())}-{secrets.token_hex(8)}-{file.filename}\"\n",
        "    path = os.path.join(settings.BLOB_DIR, name)\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(data)\n",
        "    token = signer.dumps({\"name\": name, \"ts\": time.time()})\n",
        "    url = f\"/api/blob/get?token={token}\"\n",
        "    METRICS[\"blob_uploads\"] += 1\n",
        "    record(\"blob.upload\", {\"name\": name, \"bytes\": len(data)})\n",
        "    return BlobUploadResponse(name=name, size=len(data), url=url, demo=settings.DEMO_MODE)\n",
        "\n",
        "@app.get(\"/api/blob/get\")\n",
        "async def blob_get(token: str):\n",
        "    try:\n",
        "        payload = signer.loads(token, max_age=3600 * 24)\n",
        "        name = payload[\"name\"]\n",
        "    except Exception:\n",
        "        raise HTTPException(400, \"Invalid token\")\n",
        "    path = os.path.join(settings.BLOB_DIR, name)\n",
        "    if not os.path.exists(path):\n",
        "        raise HTTPException(404, \"Not found\")\n",
        "    with open(path, \"rb\") as f:\n",
        "        data = f.read()\n",
        "    return Response(content=data, media_type=\"application/octet-stream\",\n",
        "                    headers={\"Content-Disposition\": f'attachment; filename=\"{os.path.basename(path)}\"'})\n",
        "\n",
        "Simulation\n",
        "\n",
        "@app.post(\"/api/simulate\", response_model=SimResponse)\n",
        "async def api_simulate(req: SimRequest):\n",
        "    start = time.time()\n",
        "    finalstate, snaps, laws = runsimulation(req)\n",
        "    latency = int((time.time() - start) * 1000)\n",
        "    return SimResponse(finalstate=finalstate, snapshots=snaps, lawsapplied=laws, demo=settings.DEMOMODE, latency_ms=latency)\n",
        "\n",
        "Metrics detail\n",
        "\n",
        "@app.get(\"/metrics\")\n",
        "async def metrics():\n",
        "    up = time.time() - METRICS[\"start_time\"]\n",
        "    out = dict(METRICS)\n",
        "    out[\"uptime_seconds\"] = up\n",
        "    return out\n",
        "\n",
        "# ---------------------------\n",
        "# Typed client\n",
        "# ---------------------------\n",
        "\n",
        "class TypedClient:\n",
        "    def init(self, base_url: str, timeout: float = 30.0, token: Optional[str] = None):\n",
        "        self.baseurl = baseurl.rstrip(\"/\")\n",
        "        self.timeout = timeout\n",
        "        self.token = token\n",
        "\n",
        "    def _headers(self):\n",
        "        h = {\"Accept\": \"application/json\"}\n",
        "        if self.token:\n",
        "            h[\"Authorization\"] = f\"Bearer {self.token}\"\n",
        "        return h\n",
        "\n",
        "    async def health(self) -> Health:\n",
        "        async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "            r = await client.get(f\"{self.baseurl}/health\", headers=self.headers())\n",
        "            r.raiseforstatus()\n",
        "            return Health(r.json())\n",
        "\n",
        "    async def nlp(self, task: str, input_text: str) -> NLPResponse:\n",
        "        async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "            r = await client.post(f\"{self.baseurl}/api/nlp\", json={\"task\": task, \"inputtext\": inputtext}, headers=self.headers())\n",
        "            r.raiseforstatus()\n",
        "            return NLPResponse(r.json())\n",
        "\n",
        "    async def vision(self, image_bytes: bytes, filename: str = \"image.png\") -> VisionResponse:\n",
        "        files = {\"image\": (filename, image_bytes, \"application/octet-stream\")}\n",
        "        async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "            r = await client.post(f\"{self.baseurl}/api/vision\", files=files, headers=self.headers())\n",
        "            r.raiseforstatus()\n",
        "            return VisionResponse(r.json())\n",
        "\n",
        "    async def speech(self, audio_bytes: bytes, filename: str = \"audio.wav\") -> SpeechResponse:\n",
        "        files = {\"audio\": (filename, audio_bytes, \"application/octet-stream\")}\n",
        "        async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "            r = await client.post(f\"{self.baseurl}/api/speech\", files=files, headers=self.headers())\n",
        "            r.raiseforstatus()\n",
        "            return SpeechResponse(r.json())\n",
        "\n",
        "    async def simulate(self, seed: Dict[str, Any], steps: int = 10) -> SimResponse:\n",
        "        payload = {\"seed\": seed, \"steps\": steps}\n",
        "        async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "            r = await client.post(f\"{self.baseurl}/api/simulate\", json=payload, headers=self.headers())\n",
        "            r.raiseforstatus()\n",
        "            return SimResponse(r.json())\n",
        "\n",
        "# ---------------------------\n",
        "# Entrypoint\n",
        "# ---------------------------\n",
        "\n",
        "if name == \"main\":\n",
        "    import uvicorn\n",
        "    host = os.getenv(\"HOST\", \"127.0.0.1\")\n",
        "    port = int(os.getenv(\"PORT\", \"8000\"))\n",
        "    log.info(f\"Starting server on http://{host}:{port}  demo={settings.DEMO_MODE}\")\n",
        "    uvicorn.run(\"app_single:app\", host=host, port=port, reload=False)"
      ]
    }
  ]
}
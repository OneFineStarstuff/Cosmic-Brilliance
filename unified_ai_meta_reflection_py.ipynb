{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOcaWWQA1Xf7lK2blaJlhmy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Cosmic-Brilliance/blob/main/unified_ai_meta_reflection_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVEFBskiN3FD"
      },
      "outputs": [],
      "source": [
        "# unified_ai/meta/reflection.py\n",
        "from __future__ import annotations\n",
        "from typing import Callable, Dict, Any\n",
        "\n",
        "def reflect_on_episode(\n",
        "    agent_log: str,\n",
        "    prompt_template: str,\n",
        "    llm_fn: Callable[[str], str] | None = None,\n",
        "    parse_fn: Callable[[str], Dict[str, Any]] | None = None,\n",
        ") -> Dict[str, Any]:\n",
        "    if \"{log}\" not in prompt_template:\n",
        "        raise ValueError(\"prompt_template must contain '{log}'\")\n",
        "\n",
        "    prompt = prompt_template.format(log=agent_log)\n",
        "\n",
        "    def _default_llm(p: str) -> str:\n",
        "        lines = [ln.strip() for ln in p.splitlines() if ln.strip()]\n",
        "        failures = [ln for ln in lines if any(w in ln.lower() for w in [\"fail\", \"error\", \"dead-end\", \"stale\"])]\n",
        "        if not failures:\n",
        "            failures = [\"No explicit failure lines detected; reward curve suggests suboptimal exploration.\"]\n",
        "        hyp = [\n",
        "            \"Insufficient situational memory caused plan drift.\",\n",
        "            \"Under-exploration due to premature exploitation.\"\n",
        "        ]\n",
        "        imps = [\n",
        "            \"Increase retrieval top-k and apply recency weighting in writes.\",\n",
        "            \"Boost epsilon temporarily after failures; decay when success stabilizes.\"\n",
        "        ]\n",
        "        return (\n",
        "            \"Failures:\\n- \" + \"\\n- \".join(failures[:3]) + \"\\n\\n\"\n",
        "            \"Hypotheses:\\n- \" + \"\\n- \".join(hyp) + \"\\n\\n\"\n",
        "            \"Improvements:\\n- \" + \"\\n- \".join(imps)\n",
        "        )\n",
        "\n",
        "    def _default_parse(s: str) -> Dict[str, Any]:\n",
        "        out = {\"failures\": [], \"hypotheses\": [], \"improvements\": [], \"raw\": s}\n",
        "        sec, buf = None, []\n",
        "        def _flush():\n",
        "            nonlocal sec, buf\n",
        "            if sec and buf:\n",
        "                out[sec] = [b.lstrip(\"- \").strip() for b in buf if b.strip()]\n",
        "                buf = []\n",
        "        for ln in s.splitlines():\n",
        "            l = ln.strip()\n",
        "            if not l: continue\n",
        "            low = l.lower()\n",
        "            if low.startswith(\"failures:\"):\n",
        "                _flush(); sec = \"failures\"\n",
        "            elif low.startswith(\"hypotheses:\"):\n",
        "                _flush(); sec = \"hypotheses\"\n",
        "            elif low.startswith(\"improvements:\"):\n",
        "                _flush(); sec = \"improvements\"\n",
        "            else:\n",
        "                buf.append(l)\n",
        "        _flush()\n",
        "        return out\n",
        "\n",
        "    raw = (_default_llm if llm_fn is None else llm_fn)(prompt)\n",
        "    return (_default_parse if parse_fn is None else parse_fn)(raw)\n",
        "\n",
        "REFLECT_PROMPT = \"\"\"You are a meta-cognitive agent.\n",
        "\n",
        "Below is a transcript of your actions, states, and outcomes during the task.\n",
        "\n",
        "Please:\n",
        "1. Identify at least 2 failure points or suboptimal decisions.\n",
        "2. Hypothesize why these failures occurred.\n",
        "3. Propose improvements to policy, memory use, or planning strategy.\n",
        "\n",
        "Transcript:\n",
        "{log}\n",
        "\"\"\""
      ]
    }
  ]
}